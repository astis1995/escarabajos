{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a93b37",
   "metadata": {},
   "source": [
    "# Batch Lamda1050 jump correction script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c2a45",
   "metadata": {},
   "source": [
    "### Author: Vinicio Soto, CICIMA\n",
    "### This script works with raw Lambdas1050's ASC files in batch. It corrects Lambdas1050's detector jump between 857 nm and 858 nm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b228f4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee75e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15a06d",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "Write your archive folder's path in file_folder_data_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e843aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CICIMAUCR0001-1.Sample.ASC', 'CICIMAUCR0006-1.Sample.ASC']\n"
     ]
    }
   ],
   "source": [
    "#Lists all archives in folder\n",
    "file_folder_data_path = r\"E:\\CICIMA\\VINICIO\\VINICIO\\2023-03-CICIMAUCR-2-REFLECTANCE\"\n",
    "file_list = os.listdir(file_folder_data_path)\n",
    "\n",
    "#file extension\n",
    "file_extension = \".ASC\"\n",
    "\n",
    "# filters a list of strings to create a new list containing only the elements that end with \".ASC\"\n",
    "\n",
    "def filter_substring_elements(path_strings, substring):\n",
    "    filtered_paths = [path for path in path_strings if substring in path]\n",
    "    return filtered_paths\n",
    "\n",
    "# Filtering elements ending with \".ASC\"\n",
    "filtered_list = filter_substring_elements(file_list, file_extension)\n",
    "\n",
    "# Displaying the filtered list\n",
    "print(filtered_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92718787",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafcea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(file_location):\n",
    "    \n",
    "    #definitions\n",
    "    #Logic to read ASCII data\n",
    "    import pandas as pd\n",
    "    import re\n",
    "\n",
    "    def responses(str):\n",
    "        re1 = \"\\d+/(\\d+,\\d+) \\d+,\\d+/(\\d+,\\d+)\"\n",
    "        p = re.compile(re1)\n",
    "        m= p.match(str)\n",
    "        if m:\n",
    "            return m.group(1),m.group(2)    \n",
    "        else:\n",
    "            return \"\",\"\"\n",
    "    def attenuator_settings(str):\n",
    "        re1 = \"S:(\\d+,\\d+) R:(\\d+,\\d+)\"\n",
    "        p = re.compile(re1)\n",
    "        m= p.match(str)\n",
    "        if m:\n",
    "            return m.group(1),m.group(2)    \n",
    "        else:\n",
    "            return \"\",\"\"\n",
    "    def slit_pmt_aperture(str):\n",
    "        re1 = \"\\d+/servo \\d+,\\d+/(\\d+,\\d+)\"\n",
    "        p = re.compile(re1)\n",
    "        m= p.match(str)\n",
    "        if m:\n",
    "            return m.group(1)    \n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    f = open(file_location)\n",
    "    metadata = {}\n",
    "    df = pd.DataFrame()\n",
    "    with f as data_file:\n",
    "        for index, row in enumerate(data_file): #0-89\n",
    "\n",
    "            row_str = row.strip()\n",
    "            if index +1 == 3: #Filename and extension\n",
    "                metadata[\"filename\"]= row_str\n",
    "            if index + 1 == 4: #date DD/MM/YYYY\n",
    "                metadata[\"date\"]= row_str\n",
    "            if index + 1 == 5:#Time HH:MM:SS.SS\n",
    "                metadata[\"time\"]= row_str\n",
    "            if index + 1 == 8:#user\n",
    "                metadata[\"user\"]= row_str\n",
    "            if index + 1 == 9:#description\n",
    "                metadata[\"description\"]= row_str\n",
    "            if index + 1 == 10:#minimum wavelength\n",
    "                metadata[\"minimum_wavelength\"]= row_str\n",
    "            if index + 1 == 12:#equipment name\n",
    "                metadata[\"equipment\"]= row_str\n",
    "            if index + 1 == 13:#equipment series\n",
    "                metadata[\"series\"]= row_str\n",
    "            if index + 1 == 14:#data visualizer version, equipment version, date and time\n",
    "                metadata[\"software\"]= row_str\n",
    "            if index + 1 == 21:#Operating mode\n",
    "                metadata[\"operating_mode\"]= row_str\n",
    "            if index + 1 == 22: #Number of cycles\n",
    "                metadata[\"cycles\"]= row_str\n",
    "            if index + 1 == 32: #range/servo\n",
    "                metadata[\"slit_pmt\"]= slit_pmt_aperture(row_str)\n",
    "            if index + 1 == 33:\n",
    "                metadata[\"response_ingaas\"], metadata[\"response_pmt\"]= responses(row_str)\n",
    "            if index + 1 == 35: #pmt gain, if 0 is automatic\n",
    "                metadata[\"pmt_gain\"]= row_str\n",
    "            if index + 1 == 36: #InGaAs detector gain\n",
    "                metadata[\"ingaas_gain\"]= row_str\n",
    "            if index + 1 == 42:#monochromator wavelength nm\n",
    "                metadata[\"monochromator_change\"]= row_str\n",
    "            if index + 1 == 43:#lamp change wavelength\n",
    "                metadata[\"lamp_change\"]= row_str\n",
    "            if index + 1 == 44:#pmt wavelength\n",
    "                metadata[\"pmt_change\"]= row_str\n",
    "            if index + 1 == 45:#beam selector\n",
    "                metadata[\"beam_selector\"]= row_str\n",
    "            if index + 1 == 46:\n",
    "                metadata[\"cbm\"]= row_str\n",
    "            if index + 1 == 47: #cbd status, on/off\n",
    "                metadata[\"cbd_status\"]= row_str\n",
    "            if index + 1 == 48: #attenuator percentage\n",
    "                metadata[\"attenuator_sample\"], metadata[\"attenuator_reference\"]= attenuator_settings(row_str)\n",
    "            if index + 1 == 49:\n",
    "                metadata[\"polarizer\"]= row_str\n",
    "            if index + 1 == 80:\n",
    "                metadata[\"units\"]= row_str\n",
    "            if index + 1 == 81:\n",
    "                metadata[\"measuring_mode\"]= row_str\n",
    "            if index + 1 == 84:\n",
    "                metadata[\"maximum_wavelength\"]= row_str\n",
    "            if index + 1 == 85:\n",
    "                metadata[\"step\"]= row_str\n",
    "            if index + 1 == 86:\n",
    "                metadata[\"number_of_datapoints\"]= row_str\n",
    "            if index + 1 == 88:\n",
    "                metadata[\"maximum_measurement\"]= row_str\n",
    "            if index + 1 == 89:\n",
    "                metadata[\"minimum_measurement\"]= row_str\n",
    "            if index +1 == 90:\n",
    "                break\n",
    "        df = pd.read_csv(f, sep=\"\\t\", decimal =\",\", names=[\"wavelength\", metadata[\"measuring_mode\"]])\n",
    "        f.close()\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685fc25",
   "metadata": {},
   "source": [
    "### Correction process function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b4b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_correction(file_folder_data_path, filename, metadata):\n",
    "    #measuring_mode\n",
    "    measuring_mode = metadata[\"measuring_mode\"]\n",
    "    \n",
    "    #constants\n",
    "    markersize = 1 #Marker size for plots\n",
    "\n",
    "    # read text file into pandas DataFrame \n",
    "    full_path= file_folder_data_path + \"\\\\\" + filename\n",
    "    \n",
    "    #Read header\n",
    "    lines = []\n",
    "    with open(full_path) as myfile:\n",
    "        lines = myfile.readlines()[0:90] \n",
    "    header = \"\".join(lines)\n",
    "\n",
    "    #read body\n",
    "    f = open(full_path)\n",
    "    df = pd.read_csv(f, sep=\"\\t\", decimal = \",\", skiprows=90,  \n",
    "                     names=[\"wavelength\", measuring_mode])\n",
    "    \n",
    "    #convert columns to float\n",
    "    df['wavelength'] = df['wavelength'].astype(float)\n",
    "    df[measuring_mode] = df[measuring_mode].astype(float)\n",
    "    \n",
    "\n",
    "    #This code finds the rows before and after the detector change\n",
    "    #freq1 is the frequency before the change and freq2 is the frequency after the change\n",
    "    wavelenght1 = 857.000000 #857\n",
    "    wavelenght2 = 858.000000 #858\n",
    "    \n",
    "    #print(\"Loc\")\n",
    "    row1 = df.loc[ df['wavelength'] == wavelenght1]\n",
    "    row2 = df.loc[ df['wavelength'] == wavelenght2]\n",
    "    row22 = df.loc[ df['wavelength'] == wavelenght2 +1]\n",
    "    row23 = df.loc[ df['wavelength'] == wavelenght2+2]\n",
    "    row24 = df.loc[ df['wavelength'] == wavelenght2+3]\n",
    "    row25 = df.loc[ df['wavelength'] == wavelenght2+4]\n",
    "    \n",
    "    #This code finds the values corresponding to those frequencies and creates a correction factor\n",
    "    \n",
    "    try:\n",
    "        data1 = row1.iat[0,1]\n",
    "        data2 = row2.iat[0,1]\n",
    "        data22 = row22.iat[0,1]\n",
    "        data23 = row23.iat[0,1]\n",
    "        data24 = row23.iat[0,1]\n",
    "        data25 = row23.iat[0,1]\n",
    "    \n",
    "        data2_avg = (data2 + data22+data23+data24+data25)/5\n",
    "    \n",
    "        correction_factor= data2_avg/data1 *0.98\n",
    "    \n",
    "        #Multiply all frequencies equal or greater than freq2 by correction_factor\n",
    "        df2 = df\n",
    "        df2.loc[df2[\"wavelength\"] <= wavelenght2, [measuring_mode]] *= correction_factor\n",
    "\n",
    "        #SAVE FILES\n",
    "        #convert dataframe to numpy\n",
    "        my_numpy_df_data = df.to_numpy()\n",
    "        \n",
    "        #Create new folder\n",
    "        corrected_path = file_folder_data_path + \"\\\\jump_corrected_files\\\\\"\n",
    "        if not os.path.exists(corrected_path):\n",
    "            os.mkdir(corrected_path)\n",
    "            \n",
    "        #saves file, removes .ASC and removes .SAMPLE\n",
    "        unnecessary_text = [\".Sample\", \".Cycle1\"]\n",
    "        temp_text = filename.replace('.ASC', ''+'.txt')\n",
    "        for text in unnecessary_text:\n",
    "            print(temp_text)\n",
    "            temp_text = temp_text.replace(text, \"\")\n",
    "        \n",
    "        new_archive_name = corrected_path + temp_text\n",
    "        \n",
    "        with open(new_archive_name, 'wb') as f:\n",
    "            np.savetxt(new_archive_name, my_numpy_df_data,fmt = \"%.6f\", delimiter=\"\\t\", header=header, comments='', )\n",
    "        with open(new_archive_name, \"r\") as f:\n",
    "            data = f.read()\n",
    "        with open(new_archive_name, \"w\") as f:\n",
    "            f.write(data.replace(\"#DATA\\n\",\"#DATA\"))\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126deb7",
   "metadata": {},
   "source": [
    "### Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ceb73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIMAUCR0001-1.Sample.txt\n",
      "CICIMAUCR0001-1.txt\n",
      "CICIMAUCR0006-1.Sample.txt\n",
      "CICIMAUCR0006-1.txt\n"
     ]
    }
   ],
   "source": [
    "for file in filtered_list:\n",
    "\n",
    "    #obtain metadata\n",
    "    metadata = get_metadata(file_folder_data_path + \"//\"+file)\n",
    "    \n",
    "    #print(metadata)\n",
    "    \n",
    "    #Fix jump correction\n",
    "    jump_correction(file_folder_data_path, file, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404e23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bc25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
