{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef220a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Specimen_Collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3d9bf933a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSpecimen_Collection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpecimen_Collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSpectrum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectrum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Specimen_Collection'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from Specimen_Collection import Specimen_Collection\n",
    "from Spectrum import Spectrum\n",
    "\n",
    "sys.path.append('/home/juanca/Desktop/escarabajo/escarabajos/L1050_data')\n",
    "\n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Decorator to measure execution time of a function\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time of {{func.__name__}}: {{end_time - start_time:.2f}} seconds\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7021c4a",
   "metadata": {},
   "source": [
    "# Batch Spectroscopy File Parsing Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d722b6",
   "metadata": {},
   "source": [
    "### Author: Vinicio Soto, CICIMA\n",
    "### This script works with raw Lambdas1050's ASC files in batch. It corrects Lambdas1050's detector jump between 857 nm and 858 nm and performs a Savitzky-Golay filtering on the corrected data\n",
    "\n",
    "#### exclusion_list.txt: You can add a file with this name to the folder with the data to exclude any file with that name\n",
    "\n",
    "This script reads every l1050 file in folder and its subfolders and create a unique average, jump_corrected_files, report and std_dev folders\n",
    "It creates sections for each folder with its information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24254f0e",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Data analysis\n",
    "import numpy as np  #Array and numeric methods\n",
    "from matplotlib.backends.backend_pdf import PdfPages #pri*nt PDFS\n",
    "import matplotlib #pri*nt graphs\n",
    "import matplotlib.pyplot as plt #pri*nt graphs\n",
    "import os #operating system\n",
    "import re #regular expression manipulation\n",
    "from datetime import datetime #date and time methods\n",
    "import logging #to log errors\n",
    "\n",
    "#import spectraltools\n",
    "#This script requires the file spectraltools.py to work\n",
    "import sys\n",
    "# Add the external folder to the system path\n",
    "current_dir = os.getcwd()\n",
    "external_folder_path = os.path.abspath(os.path.join(current_dir, '../libraries'))\n",
    "sys.path.append(external_folder_path)\n",
    "\n",
    "#This line of code allow us to access data in colab\n",
    "#functionality to reload modules\n",
    "\n",
    "import importlib\n",
    "import spectraltools\n",
    "import metrics\n",
    "import datapath_selector\n",
    "\n",
    "# clear the import cache\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(spectraltools)\n",
    "importlib.reload(datapath_selector)\n",
    "# now you can import my_class and it'll be updated\n",
    "from metrics import *\n",
    "from spectraltools import *\n",
    "from datapath_selector import get_paths\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36150b",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "Write your archive folders' path in file_folder_data_path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent folder path\n",
    "date = str(datetime.today().date())\n",
    "\n",
    "#file_folder_data_path =[ #r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\\L1050_data\\CICIMA-2024-05-REFLECTANCE\\DORSAL\",\n",
    "                         #r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\\L1050_data\\CICIMA-2024-05-REFLECTANCE\\VENTRAL\",\n",
    "                         #r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\\L1050_data\\CICIMA-2024-03-REFLECTANCE\\without iris nor lens\",\n",
    "                         #r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\\L1050_data\\2024-04-INBUCR-REFLECTANCE\",\n",
    "                         #r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\\L1050_data\\2023-03-CICIMAUCR-2-REFLECTANCE\",\n",
    "                         #r\"C:\\Users\\esteb\\cicima\\escarabajos\\L1050_data\\CICIMA-2024-05-REFLECTANCE\\DORSAL\"\n",
    "                       #]\n",
    "parent_folder_data_path = Path(r\"E:\\Estudio-espectral-escarabajos\") \n",
    "\n",
    "#create a subfolder called report with the correction process info  \n",
    "report_path = ((parent_folder_data_path.parent / \"reports\" )/ f\"{date}\") / (parent_folder_data_path.name)\n",
    "#pri*nt(report_path)\n",
    "report_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#create a subfolder called corrected_files\n",
    "corrected_files_path = ((parent_folder_data_path.parent / f\"corrected_files_{date}\" )/ f\"{date}\") / parent_folder_data_path.name\n",
    "#pri*nt(corrected_files_path)\n",
    "corrected_files_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#create a subfolder called average and std\n",
    "\n",
    "average_files_path = ((parent_folder_data_path.parent / f\"average\" )/ f\"{date}\") / parent_folder_data_path.name\n",
    "#pri*nt(average_files_path)\n",
    "average_files_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "std_files_path = ((parent_folder_data_path.parent / f\"std\" )/ f\"{date}\") / parent_folder_data_path.name\n",
    "#pri*nt(std_files_path)\n",
    "std_files_path.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afc7d5-f3aa-4546-bce2-3b1edc7bcd60",
   "metadata": {},
   "source": [
    "#### Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83243179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OPTIONS: cicima_laptop, colaboratory, wfh, cicima_desktop\n",
    "    \"\"\"\n",
    "collection_paths = get_paths()\n",
    "#pri*nt(collection_paths)\n",
    "\n",
    "inbio_2018_2019_collection = Specimen_Collection(\"INBIO\", collection_paths[\"2018_2019_inbio_collection_path\"] , collection_paths[\"2018_2019_inbio_collection_metadata\"] , \"HIGH\")\n",
    "angsol_collection = Specimen_Collection(\"ANGSOL\", collection_paths[\"angsol_collection_path\"] , collection_paths[\"angsol_collection_metadata\"] , \"HIGH\")\n",
    "angsol_collection.set_description(\"ANGSOL collection has specimens that belong to Angel Sol√≠s. The confidence that we have about specimen identification is high.\")\n",
    "\n",
    "cicimaucr_collection = Specimen_Collection(\"CICIMAUCR1\", collection_paths[\"cicimaucr_collection_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "cicimaucr_collection_2 = Specimen_Collection(\"CICIMAUCR2\", collection_paths[\"cicimaucr_collection_2_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "cicimaucr_collection_3 = Specimen_Collection(\"CICIMAUCR3\", collection_paths[\"cicimaucr_collection_3_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "inbucr_collection = Specimen_Collection(\"INBUCR\", collection_paths[\"inbucr_collection_path\"] , collection_paths[\"inbucr_metadata\"] , \"HIGH\")\n",
    "bioucr_collection = Specimen_Collection(\"BIOUCR\", collection_paths[\"bioucr_collection_path\"] , collection_paths[\"bioucr_metadata\"] , \"LOW\")\n",
    "\n",
    "collection_list = [\n",
    "                    inbio_2018_2019_collection,\n",
    "                    angsol_collection,\n",
    "                    cicimaucr_collection,\n",
    "                    cicimaucr_collection_2,\n",
    "                    cicimaucr_collection_3,\n",
    "                    inbucr_collection,\n",
    "                    bioucr_collection,\n",
    "                    ]\n",
    "codes_in_collection = []\n",
    "for collection in collection_list:\n",
    "    codes_in_collection += collection.get_codes()\n",
    "print(codes_in_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9906ebe",
   "metadata": {},
   "source": [
    "### Constants\n",
    "Define your constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95112007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine \n",
    "markersize = 1\n",
    "#date\n",
    "\n",
    "\n",
    "correction_file_path = Path(r\"..\\test\\data\\test_step_jump_correction\\corrections\\aluminum_mirror_reflectance.txt\")\n",
    "correction_df = pd.read_csv(correction_file_path, sep=\"\\t\",decimal=\",\", names = [\"wavelength\",\"reflectance\"], skiprows=1)\n",
    "correction_df\n",
    "\n",
    "def integer_generator(start=0):\n",
    "    if(start%100==0):\n",
    "        print(f\"{start=}\")\n",
    "    while True:\n",
    "        yield start\n",
    "        start += 1\n",
    "gen = integer_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8fdd61",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b68b9-f317-4e7c-8471-7cd7112c8934",
   "metadata": {},
   "source": [
    "#### Check if it is a L1050 file or a CRAIC file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddca9f",
   "metadata": {},
   "source": [
    "### Correction process function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaac62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_correction(Spectrum):\n",
    "    \"\"\"Receives a l1050 spectrum and corrects its detector jump\"\"\"\n",
    "    metadata = Spectrum.get_metadata()\n",
    "    df = Spectrum.get_dataframe()\n",
    "    \n",
    "    #measuring_mode\n",
    "    measuring_mode = metadata[\"measuring_mode\"]\n",
    "    \n",
    "    #convert columns to float\n",
    "    df['wavelength'] = df['wavelength'].astype(float)\n",
    "    df[measuring_mode] = df[measuring_mode].astype(float)\n",
    "    \n",
    "\n",
    "    #This code finds the rows before and after the detector change\n",
    "    #freq1 is the frequency before the change and freq2 is the frequency after the change\n",
    "    wavelenght1 = 857.000000 #857\n",
    "    wavelenght2 = 858.000000 #858\n",
    "    \n",
    "    #pri*nt(\"Loc\")\n",
    "    row1 = df.loc[ df['wavelength'] == wavelenght1]\n",
    "    row2 = df.loc[ df['wavelength'] == wavelenght2]\n",
    "    row12 = df.loc[ df['wavelength'] == wavelenght1-1]\n",
    "    row13 = df.loc[ df['wavelength'] == wavelenght1-2]\n",
    "    row14 = df.loc[ df['wavelength'] == wavelenght1-3]\n",
    "    row15 = df.loc[ df['wavelength'] == wavelenght1-4]\n",
    "    \n",
    "    #This code finds the values corresponding to those frequencies and creates a correction factor\n",
    "    \n",
    "    try:\n",
    "        data1 = row1.iat[0,1]\n",
    "        data2 = row2.iat[0,1]\n",
    "        data22 = row12.iat[0,1]\n",
    "        data23 = row13.iat[0,1]\n",
    "        data24 = row14.iat[0,1]\n",
    "        data25 = row15.iat[0,1]\n",
    "    \n",
    "        data1_avg = (data1 + data22+data23)/3 #+data24+data25)/5\n",
    "        data2_avg = (data2)\n",
    "        correction_factor= data1_avg/data2_avg  \n",
    "    \n",
    "        #Multiply all frequencies equal or greater than freq2 by correction_factor\n",
    "        df2 = df\n",
    "        df2.loc[df2[\"wavelength\"] >= wavelenght2 , [measuring_mode]] *= correction_factor\n",
    "        \n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        \n",
    "        #pri*nt(e)\n",
    "        return pd.DataFrame([])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b04539-e690-4372-bc86-3f64421cf5b2",
   "metadata": {},
   "source": [
    "### Define Savitzky-Golay Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def savitzky_golay_filter(metadata, df) -> pd.DataFrame:\n",
    "    \"\"\"Defines a Savitzky Golay Filter: Basically, smooths out the function. https://es.wikipedia.org/wiki/Filtro_de_Savitzky%E2%80%93Golay\"\"\"\n",
    "    measuring_mode = metadata[\"measuring_mode\"]\n",
    "    y = df[measuring_mode] = df[measuring_mode].astype(float)\n",
    "    \n",
    "    # Apply Savitzky-Golay filter\n",
    "    window_length = 21  # Window length (odd number)\n",
    "    polyorder = 2  # Polynomial order\n",
    "    y_smooth = savgol_filter(y, window_length, polyorder)\n",
    "    \n",
    "    #create new dataframe\n",
    "    df_smooth = pd.DataFrame([])\n",
    "    df_smooth[\"wavelength\"] =df[\"wavelength\"]\n",
    "    df_smooth[measuring_mode] = y_smooth\n",
    "    \n",
    "    return df_smooth\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1212b1-8865-4b9b-b772-4ed0aa1e2b45",
   "metadata": {},
   "source": [
    "### Define function that filters selected extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_filepaths(parent_folder):\n",
    "    filepaths = []\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(parent_folder):\n",
    "        for file in files:\n",
    "            # Combine the root directory with the file name to get the full path\n",
    "            filepath = os.path.join(root, file)\n",
    "            filepaths.append(filepath)\n",
    "    \n",
    "    return filepaths\n",
    "file_list = list_all_filepaths(parent_folder_data_path)\n",
    "#pri*nt(f\"{file_list=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclusion_list(file_list):\n",
    "        \"\"\"Only files whose name is in the exclusion list\"\"\"\n",
    "        #file extension\n",
    "        file_extension = \"exclusion_list\"\n",
    "    \n",
    "        # filters a list of strings to create a new list containing only the elements that have exclusion_list\"\n",
    "    \n",
    "        def filter_substring_elements(path_strings, substring):\n",
    "            filtered_paths = [path for path in path_strings if substring in path]\n",
    "            return filtered_paths\n",
    "    \n",
    "        # Filter elements\n",
    "        filtered_list = filter_substring_elements(file_list, file_extension)\n",
    "    \n",
    "        # Displaying the filtered list\n",
    "        #pri*nt(filtered_list)\n",
    "        \n",
    "        return filtered_list\n",
    "exclusion_list = get_exclusion_list(file_list)\n",
    "#pri*nt(f\"{exclusion_list=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list_CRAIC_and_l1050(path_list):\n",
    "    \"\"\"Only l1050 files and CRAIC files are read\"\"\"\n",
    "    filtered_list = []\n",
    "\n",
    "    filtered_list += [path for path in path_list if (check_CRAIC_file(path) or check_l1050_file(path))]\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "filtered_list = filter_list_CRAIC_and_l1050(file_list)\n",
    "\n",
    "#pri*nt(f\"{filtered_list=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_failed_runs(filtered_list):\n",
    "    \"\"\"Filter runs that failed\"\"\"\n",
    "    #file extension\n",
    "    fail_strings = [\"fail\"]\n",
    "\n",
    "    # filters a list of strings to create a new list containing only the elements that end with \".ASC\"\n",
    "\n",
    "    def filter_substring_elements(path_strings, substring):\n",
    "        filtered_paths = [path for path in path_strings if substring not in path]\n",
    "        return filtered_paths\n",
    "\n",
    "    # Filtering elements with any of the fail strings\n",
    "    for string in fail_strings: \n",
    "        filtered_list = filter_substring_elements(filtered_list, string)\n",
    "\n",
    "    # Displaying the filtered list\n",
    "    #pri*nt(filtered_list)\n",
    "    \n",
    "    return filtered_list\n",
    "\n",
    "successful_list = filter_failed_runs(filtered_list)\n",
    "#pri*nt(f\"{successful_list=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592545f",
   "metadata": {},
   "source": [
    "### Logic: Remove jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb32614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this list we will make a set of codes.\n",
    "#pri*nt(filenames)\n",
    " \n",
    "codes = []\n",
    "for path in successful_list:\n",
    "    code = get_code_from_filename(path)\n",
    "    if code: \n",
    "        codes.append(code)\n",
    "codes = set(codes)\n",
    "codes = sorted(codes)\n",
    "codes = [code for code in codes if (code in codes_in_collection)] #only codes that are in a collection\n",
    "#pri*nt(f\"codes {codes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f43515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each file in the exclusion list\n",
    "exclusion_list_df = pd.DataFrame()\n",
    "for file in exclusion_list:\n",
    "    df = pd.read_csv(file, header = 0, names=[\"filename\", \"reason\"], delimiter = \"\\t\")\n",
    "    exclusion_list_df = pd.concat([exclusion_list_df, df], ignore_index = True)\n",
    "#pri*nt(exclusion_list_df)\n",
    "#pri*nt(f\"{exclusion_list_df=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove excluded files\n",
    "def remove_excluded_files(successful_list, exclusion_list_df):\n",
    "    filtered_list = []\n",
    "\n",
    "    #if the file is not empty it gets all files that are not in that list\n",
    "    if not exclusion_list_df.empty:\n",
    "        #gets a exclusion list\n",
    "        exclusion_list = exclusion_list_df[\"filename\"].values\n",
    "        for excluded_file in exclusion_list:\n",
    "                    filtered_list = [filename for filename in successful_list if excluded_file not in filename ]\n",
    "    filtered_list = successful_list\n",
    "    return filtered_list\n",
    "    \n",
    "successful_list_without_excluded_files = remove_excluded_files(successful_list, exclusion_list_df)\n",
    "#pri*nt(f\"{successful_list_without_excluded_files=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_files(successful_list_without_excluded_files):\n",
    "    non_empty_files = [filename for filename in successful_list_without_excluded_files if ((not check_empty_CRAIC_file(filename)) and (not check_empty_l1050_file(filename)))]\n",
    "    return non_empty_files\n",
    "\n",
    "non_empty_files = remove_empty_files(successful_list_without_excluded_files)\n",
    "#non_empty_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_plot(folder, basename, metadata, dataframe, label = None):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \n",
    "    \"\"\"\n",
    "    #\n",
    "    #pri*nt(f\"save_corrected_df: {folder=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {basename=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {metadata=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {dataframe=}\")\n",
    "    \n",
    "    plt.plot(dataframe[\"wavelength\"], dataframe[metadata[\"measuring_mode\"]], label = label, color= get_contrasting_color())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d33878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_df(folder, basename, metadata, dataframe):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \n",
    "    \"\"\"\n",
    "    #\n",
    "    #pri*nt(f\"save_corrected_df: {folder=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {basename=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {metadata=}\")\n",
    "    #pri*nt(f\"save_corrected_df: {dataframe=}\")\n",
    "    \n",
    "    #get only wavelength and metadata[\"measuring_mode\"]\n",
    "    dataframe = dataframe[[\"wavelength\", metadata[\"measuring_mode\"]]]\n",
    "    #variables\n",
    "    header = metadata[\"header\"]\n",
    "    \n",
    "    #convert dataframe to numpy\n",
    "    my_numpy_df_data = dataframe.to_numpy()\n",
    "\n",
    "    #create folder\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    #saves file, removes .ASC and removes .SAMPLE\n",
    "    unnecessary_text = [\".Sample\", \".Cycle1\"]\n",
    "    replace_text = basename\n",
    "    \n",
    "    for text in unnecessary_text:\n",
    "        #pri*nt(temp_text)\n",
    "        replace_text = replace_text.replace(text, \"\")\n",
    "\n",
    "    #new_archive_name\n",
    "    new_archive_name = folder / replace_text\n",
    "\n",
    "    #saves info\n",
    "    with open(new_archive_name, 'wb') as f:\n",
    "        np.savetxt(new_archive_name, my_numpy_df_data,fmt = \"%.6f\", delimiter=\"\\t\", header=header, comments='', )\n",
    "    with open(new_archive_name, \"r\") as f:\n",
    "        data = f.read()\n",
    "    with open(new_archive_name, \"w\") as f:\n",
    "        f.write(data.replace(\"#DATA\\n\",\"#DATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_CRAIC_spectrum(pdf, code, spectrum, folder):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \n",
    "    \"\"\"\n",
    "    df, filename,metadata = spectrum.get_dataframe(), spectrum.get_filename(), spectrum.get_metadata()\n",
    "    #variables\n",
    "    header = metadata[\"header\"]\n",
    "    \n",
    "    #convert dataframe to numpy\n",
    "    my_numpy_df_data = df.to_numpy()\n",
    "    \n",
    "    #get basename\n",
    "    basename = code + \".csv\"\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    #new_archive_name\n",
    "    new_archive_name = folder / basename\n",
    "\n",
    "    #saves info\n",
    "    with open(new_archive_name, 'wb') as f:\n",
    "        np.savetxt(new_archive_name, my_numpy_df_data,fmt = \"%.6f\", delimiter=\"\\t\", header=header, comments='', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a814c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_l1050_spectrum(pdf, code, spectrum, folder):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    df, filename,metadata = spectrum.get_dataframe(), spectrum.get_filename(), spectrum.get_metadata()\n",
    "    #variables\n",
    "    header = metadata[\"header\"]\n",
    "    \n",
    "    #convert dataframe to numpy\n",
    "    my_numpy_df_data = df.to_numpy()\n",
    "    \n",
    "    #get basename\n",
    "    basename = code + \".csv\"\n",
    "\n",
    "    if not os.path.exists(corrected_path):\n",
    "        os.mkdir(corrected_path)\n",
    "\n",
    "    #new_archive_name\n",
    "    new_archive_name = folder / basename\n",
    "\n",
    "    #saves info\n",
    "    with open(new_archive_name, 'wb') as f:\n",
    "        np.savetxt(new_archive_name, my_numpy_df_data,fmt = \"%.6f\", delimiter=\"\\t\", header=header, comments='', )\n",
    "    with open(new_archive_name, \"r\") as f:\n",
    "        data = f.read()\n",
    "    with open(new_archive_name, \"w\") as f:\n",
    "        f.write(data.replace(\"#DATA\\n\",\"#DATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corrected_spectrum(pdf, code, spectrum, folder):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \n",
    "    \"\"\"\n",
    "    df, filename,metadata = spectrum.get_dataframe(), spectrum.get_filename(), spectrum.get_metadata()\n",
    "    #variables\n",
    "    header = metadata[\"header\"]\n",
    "    \n",
    "    #convert dataframe to numpy\n",
    "    my_numpy_df_data = df.to_numpy()\n",
    "    \n",
    "    #Create new folder to save the corrected dataframes\n",
    "    corrected_path = Path(parent_folder_data_path)\n",
    "    \n",
    "    #get basename\n",
    "    basename = Path(filename).name\n",
    "\n",
    "    if not os.path.exists(corrected_path):\n",
    "        os.mkdir(corrected_path)\n",
    "\n",
    "    #saves file, removes .ASC and removes .SAMPLE\n",
    "    unnecessary_text = [\".Sample\", \".Cycle1\"]\n",
    "    temp_text = basename\n",
    "    \n",
    "    for text in unnecessary_text:\n",
    "        #pri*nt(temp_text)\n",
    "        temp_text = temp_text.replace(text, \"\")\n",
    "\n",
    "    #new_archive_name\n",
    "    new_archive_name = corrected_path / temp_text\n",
    "\n",
    "    #saves info\n",
    "    with open(new_archive_name, 'wb') as f:\n",
    "        np.savetxt(new_archive_name, my_numpy_df_data,fmt = \"%.6f\", delimiter=\"\\t\", header=header, comments='', )\n",
    "    with open(new_archive_name, \"r\") as f:\n",
    "        data = f.read()\n",
    "    with open(new_archive_name, \"w\") as f:\n",
    "        f.write(data.replace(\"#DATA\\n\",\"#DATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc320b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corrected_spectrum(pdf, code, spectrum, folder, label = None):\n",
    "    \"\"\"\n",
    "    Saves the dataframe into a file\n",
    "    Inputs: A dataframe, the filename of the file from which the dataframe comes from and its metadata\n",
    "    Output: None\n",
    "    \n",
    "    \"\"\"\n",
    "    df, filename,metadata = spectrum.get_dataframe(), spectrum.get_filename(), spectrum.get_metadata()\n",
    "    equipment = metadata[\"equipment\"]\n",
    "    polarization = metadata[\"polarization\"]\n",
    "    genus = metadata[\"genus\"]\n",
    "    species = metadata[\"species\"]\n",
    "    species_text = species\n",
    "    if species == \"na\":\n",
    "        species_text = \"sp.\"\n",
    "    #creates a figure to plot \n",
    "    \n",
    "    \n",
    "    #plots\n",
    "    #title = (f'1. Corrected {equipment} spectrum. Code: {code}. {genus} {species_text}. {polarization} pol.')\n",
    "    \n",
    "    plt.plot(df[\"wavelength\"], df[metadata[\"measuring_mode\"]], label = label, color= get_contrasting_color())\n",
    "    #plt.show()\n",
    "    #save figure\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46473276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_and_color(spectrum, code_file_counter):\n",
    "    metadata, df = spectrum.get_metadata(), spectrum.get_dataframe()\n",
    "    filename = spectrum.get_filename()\n",
    "    basename = Path(filename).name\n",
    "\n",
    "    #After that we will average the spectra\n",
    "    #create figure\n",
    "    color = get_contrasting_color()\n",
    "    #correct the label to only show the code \n",
    "    label_corrected = basename.replace(\".csv\", \"\").replace(\".ASC\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "    return label_corrected, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aea580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1050_get_corrected_dataframe_and_info(file, code, collection_list, code_file_counter):\n",
    "                #create a spectrum object\n",
    "                spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "                label, color = get_label_and_color(spectrum, code_file_counter)\n",
    "    \n",
    "                #Fix jump correction\n",
    "                \n",
    "                df_corrected = jump_correction(spectrum)\n",
    "                \n",
    "                corrected_dict = {\"df\":df_corrected, \"complete_path\": file, \"metadata\": metadata, \"code\":code}\n",
    "\n",
    "                return corrected_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrum_from_file(file, code, collection_list):\n",
    "            #pri*nt(\"Create spectrum from file\")\n",
    "            collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "            #pri*nt(f\"{collection=}\")\n",
    "            #pri*nt(f\"{file=}\")\n",
    "            spectrum = Spectrum(file, collection)\n",
    "            \n",
    "            #plt.figure()\n",
    "            #spectrum.get_dataframe().plot()\n",
    "            #plt.show()\n",
    "            #pri*nt(f\"{spectrum=}\")\n",
    "            return spectrum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf52b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_CRAIC_df(file_list, code, collection_list):\n",
    "    #pri*nt(f\"Average Craic\")\n",
    "    print(f\"Suspicious code {code=}\")\n",
    "    spectra = []\n",
    "    #create a spectrum for each file\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            \n",
    "            spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "            spectra.append(spectrum)\n",
    "            #pri*nt(f\"{spectra=}\")\n",
    "        except Exception as e: \n",
    "            pass\n",
    "            #pri*nt(e)\n",
    "    \n",
    "    #initialize\n",
    "    std_df = pd.DataFrame([])\n",
    "    std_df[\"wavelength\"] = []\n",
    "    std_df[\"%R\"] = []\n",
    "    #get each dataframe\n",
    "    dfs = [spectrum.get_dataframe() for spectrum in spectra]\n",
    "    dfs = [df for df in dfs if not df.empty]\n",
    "    #print(dfs)\n",
    "    #average each dataframe\n",
    "    if dfs:\n",
    "        grouped_df = pd.concat(dfs).groupby('wavelength')\n",
    "    std_df = grouped_df.std().reset_index()\n",
    "    \n",
    "    #return average dataframe\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a807ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_CRAIC_df(file_list, code, collection_list):\n",
    "    #pri*nt(f\"Average Craic\")\n",
    "    print(f\"Susp. {code}\")\n",
    "    spectra = []\n",
    "    #create a spectrum for each file\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "            spectra.append(spectrum)\n",
    "            #pri*nt(f\"{spectra=}\")\n",
    "        except Exception as e: \n",
    "            \n",
    "            print(e)\n",
    "    #init average_df\n",
    "    average_df = pd.DataFrame([])\n",
    "    average_df[\"wavelength\"] = []\n",
    "    average_df[\"%R\"] = []\n",
    "    #get each dataframe\n",
    "    #print(f\"{spectra=}\")\n",
    "    dfs = [spectrum.get_dataframe() for spectrum in spectra]\n",
    "    dfs = [df for df in dfs if not df.empty]\n",
    "    #print(f\"{dfs=}\")\n",
    "    #average each dataframe\n",
    "    if dfs:\n",
    "        grouped_df = pd.concat(dfs).groupby('wavelength')\n",
    "        average_df = grouped_df.mean().reset_index()\n",
    "    \n",
    "    #return average dataframe\n",
    "    return average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_get_average_polarizations(files_with_code, code):\n",
    "    #pri*nt(f\"{files_with_code=}\")\n",
    "    #pri*nt(f\"{code=}\")\n",
    "    #get right and left polarization \n",
    "    right_pol= [file for file in files_with_code if \"R\" in Path(file).name ]\n",
    "    left_pol= [file for file in files_with_code if \"L\" in Path(file).name ]\n",
    "    #no_polarization = [file for file in files_with_code if \"O\" in Path(file).name]\n",
    "    no_polarization_average_df = None\n",
    "    #pri*nt(f\"{right_pol=}\")\n",
    "    #pri*nt(f\"{left_pol=}\")\n",
    "    #pri*nt(f\"{no_polarization=}\")\n",
    "    #average each polarization\n",
    "    #pri*nt(\"4. right average_CRAIC_df\")\n",
    "    right_average_df = average_CRAIC_df(right_pol, code, collection_list)\n",
    "    right_average_df[\"%R\"] = right_average_df[\"%R\"] *0.5 #TODO spectral factor for filter correction  \n",
    "    #pri*nt(\"4. left average_CRAIC_df\")\n",
    "    left_average_df = average_CRAIC_df(left_pol, code, collection_list)\n",
    "    left_average_df[\"%R\"] = left_average_df[\"%R\"] *0.5 #TODO spectral factor for filter correction  \n",
    "    #pri*nt(f\"{right_average_df=}\")\n",
    "    #pri*nt(f\"{left_average_df=}\")\n",
    "    return right_average_df, left_average_df, no_polarization_average_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7793c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_get_dataframe_and_info(file, code, collection_list):\n",
    "                #create a spectrum object\n",
    "                spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "                #no correction needed\n",
    "                df_corrected = spectrum.get_dataframe()\n",
    "                metadata = spectrum.get_metadata()\n",
    "                corrected_dict = {\"df\":df_corrected, \"complete_path\": file, \"metadata\": metadata, \"code\":code}\n",
    "    \n",
    "                return corrected_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataframe_before_changes(pdf, file, code, collection_list, code_file_counter):\n",
    "\n",
    "    #create a spectrum object\n",
    "    spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "    label, color = get_label_and_color(spectrum, code_file_counter)\n",
    "    \n",
    "    #get df and metadata\n",
    "    df = spectrum.get_dataframe()\n",
    "    metadata = spectrum.get_metadata()\n",
    "    species = spectrum.get_species()\n",
    "    genus = spectrum.get_genus()\n",
    "    polarization = spectrum.get_polarization()\n",
    "    \n",
    "    if species == \"na\":\n",
    "        species_text = \"sp.\"\n",
    "    else:\n",
    "        species_text = species\n",
    "    \n",
    "    #pri*nt(f\"{species=}\")\n",
    "    #pri*nt(f\"{genus=}\")\n",
    "    #creates a figure to plot \n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    #plots before changes\n",
    "    plot_wavelength_intensity(metadata, df, kind = None, s=None, alpha = None, color = None, label = label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_mirror_reflectance(df):\n",
    "    \"\"\"real_reflectance = measured_reflectance/100*actual_reflectance\"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    #pri*nt(f\"{df_copy =}\")\n",
    "    def actual_reflectance(wavelength):\n",
    "        actual_reflectance = np.interp(wavelength, correction_df['wavelength'].astype(float), correction_df['reflectance'].astype(float))\n",
    "        return actual_reflectance\n",
    "\n",
    "    # Use the interpolation method\n",
    "    df_copy[\"actual_reflectance\"] = df[\"%R\"].apply(actual_reflectance)\n",
    "    #pri*nt(f\"{df_copy[\"actual_reflectance\"] =}\")\n",
    "    df_copy[\"%R\"] = df[\"%R\"] /100* df_copy[\"actual_reflectance\"]\n",
    "    #pri*nt(f\"{df_copy[\"%R\"]=}\")\n",
    "        \n",
    "    return df_copy.drop(\"actual_reflectance\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bde1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_get_total_average_dataframe(right_average_df, left_average_df):\n",
    "    \n",
    "    # Ensure the DataFrames have the same structure\n",
    "    if right_average_df.shape != left_average_df.shape:\n",
    "        print(f\"{right_average_df=}\")\n",
    "        print(f\"{left_average_df=}\")\n",
    "        raise ValueError(\"DataFrames must have the same shape to compute total averages.\")\n",
    "    \n",
    "    # Calculate the total average DataFrame\n",
    "    total_average_df = right_average_df\n",
    "    total_average_df[\"%R\"] = (right_average_df[\"%R\"] + left_average_df[\"%R\"])\n",
    "    \n",
    "    return total_average_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3402b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_correct_total_average(total_average_df):\n",
    "    \"\"\"Corrects the reflectance for each wavelength using interpolate_mirror_reflectance.\"\"\"\n",
    "   \n",
    "    corrected_df = total_average_df.copy()\n",
    "    corrected_df = interpolate_mirror_reflectance(total_average_df)\n",
    "                \n",
    "    return corrected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create report\n",
    "def create_correction_report(filtered_list): #1\n",
    "    \n",
    "    #pri*nt(f\"1: Create correction report\")\n",
    "    \"\"\"This function creates a report with the corrected dataframes\"\"\"\n",
    "    file_counter = 0\n",
    "    genus, species_text, polarization, title = \"\", \"\", \"\", \"\"\n",
    "    \n",
    "    #make a list of all files with code\n",
    "    files_with_code = []\n",
    "    for code in codes:\n",
    "        files_with_code += [file for file in filtered_list if code in file]\n",
    "\n",
    "    #print(f\"{files_with_code=}\")\n",
    "    \n",
    "    #create a report in pdf with the original files\n",
    "    \n",
    "    #create report name\n",
    "    original_data_file = os.path.join( report_path , f'original_data_{date}.pdf')\n",
    "\n",
    "    with matplotlib.backends.backend_pdf.PdfPages(original_data_file) as pdf:\n",
    "        \n",
    "        for code in codes: \n",
    "            #Code by code we will plot all the spectra with the wsame name\n",
    "            code_file_counter = 1\n",
    "\n",
    "            #filters each file if the code is in its basename\n",
    "            files_with_code = [file for file in filtered_list if code in file]\n",
    "            \n",
    "            #no results: continue\n",
    "            if not files_with_code:\n",
    "                continue\n",
    "            #print(f\"{files_with_code=}\")\n",
    "            \n",
    "            #separates the files between l1050 files and CRAIC files\n",
    "            CRAIC_files = [file for file in files_with_code if check_CRAIC_file(file)]\n",
    "            #print(f\"{CRAIC_files=}\")\n",
    "            \n",
    "            l1050_files = [file for file in files_with_code if check_l1050_file(file)]\n",
    "            #print(f\"{l1050_files=}\")\n",
    "\n",
    "            #no spectroscopy files: continue\n",
    "            if (not CRAIC_files) and (not l1050_files):\n",
    "                continue\n",
    "                \n",
    "            x_label =\"wavelength [nm]\"\n",
    "            y_label = \"%R\"\n",
    "\n",
    "            if l1050_files: \n",
    "                \n",
    "                plt.figure(figsize=(10, 4))\n",
    "                # Create the figure and axes\n",
    "                fig, ax = plt.subplots()\n",
    "                draw_rainbow_background()\n",
    "                \n",
    "                for file in l1050_files:\n",
    "                    \n",
    "                    \n",
    "                    #create spectrum\n",
    "                    collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "                    genus,species = Specimen_Collection.genus_species_lookup(code, collection_list)\n",
    "                    spectrum = Spectrum(file, collection_list,genus,species)\n",
    "                    metadata = spectrum.get_metadata()\n",
    "                    \n",
    "                    \n",
    "                    code_file_counter += 1\n",
    "                    file_counter += 1\n",
    "                    \n",
    "                    label = str(Path(file).name).replace(\".ASC\",\"\").replace(\".txt\",\"\").replace(\".csv\",\"\")\n",
    "                    \n",
    "                    #get df and metadata\n",
    "                    df = spectrum.get_dataframe()\n",
    "                    metadata = spectrum.get_metadata()\n",
    "                    species = spectrum.get_species()\n",
    "                    genus = spectrum.get_genus()\n",
    "                    polarization = spectrum.get_polarization()\n",
    "                    \n",
    "                    if species == \"na\":\n",
    "                        species_text = \"sp.\"\n",
    "                    else:\n",
    "                        species_text = species\n",
    "                        \n",
    "                    #plots before changes\n",
    "                    plt.plot(df[\"wavelength\"], df[metadata[\"measuring_mode\"]], color=get_contrasting_color(), label=label)\n",
    "                    \n",
    "                    \n",
    "                    ### end for\n",
    "    \n",
    "                    # Labels and title\n",
    "\n",
    "                if polarization == \"na\":\n",
    "                    polarization = \"O\"\n",
    "                title = f'1. L1050 raw. Code: {code}. {genus} {species_text}. {polarization} pol.'\n",
    "                plt.xlabel(x_label)\n",
    "                plt.ylabel(y_label)\n",
    "                plt.title(title)\n",
    "                plt.ylim(0,120)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                #plt.show()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "            \n",
    "            ########################################################################################################################\n",
    "            #CRAIC files \n",
    "            \n",
    "            \n",
    "            R_files = [file for file in CRAIC_files if \"R\" in file]\n",
    "            L_files = [file for file in CRAIC_files if \"L\" in file]\n",
    "            O_files = [file for file in CRAIC_files if (\"L\" not in file) & (\"R\" not in file)]\n",
    "\n",
    "            CRAIC_pols = [R_files,L_files,O_files]\n",
    "\n",
    "            \n",
    "            \n",
    "            for i, pol_file in enumerate(CRAIC_pols):\n",
    "                \n",
    "                plt.figure(figsize=(10, 4))\n",
    "                # Create the figure and axes\n",
    "                fig, ax = plt.subplots()\n",
    "                draw_rainbow_background()\n",
    "\n",
    "                pol = \"\"\n",
    "                \n",
    "                for file in pol_file:\n",
    "                    #create spectrum\n",
    "                    collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "                    genus,species = Specimen_Collection.genus_species_lookup(code, collection_list)\n",
    "\n",
    "                    #print(f\"{genus=} {species=}\")\n",
    "                    spectrum = Spectrum(file, collection_list,genus,species)\n",
    "                    metadata = spectrum.get_metadata()\n",
    "                    pol = metadata[\"polarization\"]\n",
    "                    label = code +\" \"+ pol\n",
    "                    code_file_counter += 1\n",
    "                    file_counter += 1\n",
    "        \n",
    "                    #get df and metadata\n",
    "                    df = spectrum.get_dataframe()\n",
    "                    metadata = spectrum.get_metadata()\n",
    "                    species = spectrum.get_species()\n",
    "                    genus = spectrum.get_genus()\n",
    "                    polarization = spectrum.get_polarization()\n",
    "                    \n",
    "                    if species == \"na\":\n",
    "                        species_text = \"sp\"\n",
    "                    else:\n",
    "                        species_text = species\n",
    "                        \n",
    "                    #plots before changes\n",
    "                    plt.plot(df[\"wavelength\"], df[metadata[\"measuring_mode\"]], color=get_contrasting_color(), label=label)\n",
    "                    \n",
    "                    ### end for\n",
    "                if polarization == \"na\":\n",
    "                    polarization = \"O\"\n",
    "                title = f'1. CRAIC raw. Code: {code}. {genus} {species_text}. {pol} pol.'\n",
    "                plt.xlabel(x_label)\n",
    "                plt.ylabel(y_label)\n",
    "                plt.title(title)\n",
    "                plt.ylim(0,120)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                #plt.show()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "                \n",
    "        #end for code in codes: \n",
    "            \n",
    "    ####################################################################################################################################}\n",
    "    #CORRECTIONS\n",
    "    \n",
    "    #create report name\n",
    "    file_counter = 0\n",
    "    corrected_data_file = os.path.join( report_path , f'corrected_data_{date}.pdf')\n",
    "    jump_corrected_dict = []\n",
    "    average_polarized_dict = []\n",
    "    #pri*nt(f\"1: Create corrected_data_file report\")\n",
    "\n",
    "    with matplotlib.backends.backend_pdf.PdfPages(corrected_data_file) as pdf:\n",
    "        \n",
    "        for code in codes:\n",
    "            \n",
    "            \n",
    "            #pri*nt(f\"{codes=}\")\n",
    "            #Code by code we will plot all the spectra with the wsame name\n",
    "            code_file_counter = 1\n",
    "            #constants\n",
    "            x_label =\"wavelength [nm]\"\n",
    "            y_label = \"%R\"\n",
    "\n",
    "            #filters each file if the code is in its basename\n",
    "            files_with_code = [file for file in filtered_list if code in file]\n",
    "            #print(f\"{files_with_code=}\")\n",
    "            \n",
    "            #separates the files between l1050 files and CRAIC files\n",
    "            CRAIC_files = [file for file in files_with_code if check_CRAIC_file(file)]\n",
    "            #print(f\"{CRAIC_files=}\")\n",
    "            \n",
    "            l1050_files = [file for file in files_with_code if check_l1050_file(file)]\n",
    "            #print(f\"{l1050_files=}\")\n",
    "            \n",
    "            if l1050_files:\n",
    "                \n",
    "                #creates a figure to plot \n",
    "                plt.figure(figsize=(10, 4))\n",
    "                # Create the figure and axes\n",
    "                fig, ax = plt.subplots()\n",
    "                draw_rainbow_background()\n",
    "                #for each l1050 file \n",
    "                \n",
    "                for file in l1050_files:\n",
    "\n",
    "                    #Get info for each file\n",
    "                    file = CRAIC_files[0]\n",
    "                    collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "                    genus,species = Specimen_Collection.genus_species_lookup(code, collection_list)\n",
    "                    spectrum = Spectrum(file, collection_list,genus,species)\n",
    "                    metadata = spectrum.get_metadata()\n",
    "\n",
    "                    #get df and metadata\n",
    "                    df = spectrum.get_dataframe()\n",
    "                    metadata = spectrum.get_metadata()\n",
    "                    species = spectrum.get_species()\n",
    "                    genus = spectrum.get_genus()\n",
    "                    polarization = spectrum.get_polarization()\n",
    "                    \n",
    "                    #Initialize corrected_dict\n",
    "                    corrected_dict = {}\n",
    "                    \n",
    "                    corrected_dict = l1050_get_corrected_dataframe_and_info(file, code, collection_list, code_file_counter)\n",
    "    \n",
    "                    #append files to the jump_corrected_dict to be used later\n",
    "                    jump_corrected_dict.append(corrected_dict) #declared at the beginning of this method\n",
    "    \n",
    "                    #pri*nt(f\"{corrected_dict[\"df_corrected\"]=}\")\n",
    "                    #saves the corrected file \n",
    "                    basename = corrected_dict[\"file\"]\n",
    "                    label = str(Path(file).name).replace(\".ASC\",\"\").replace(\".txt\",\"\").replace(\".csv\",\"\")\n",
    "                    \n",
    "                    #pri*nt(f\"{corrected_dict[\"df\"]}\")\n",
    "                    save_corrected_df(folder=corrected_files, basename = Path(file).name, metadata=corrected_dict[\"metadata\"], dataframe=corrected_dict[\"df\"])\n",
    "                    save_corrected_plot(folder = corrected_files, basename = Path(file).name,metadata = dict[\"metadata\"], dataframe=corrected_dict[\"df\"], label = label )\n",
    "                    \n",
    "                    ### end for\n",
    "                plt.title(f'1. L1050. Jump Correction. {code}')\n",
    "                plt.xlabel(x_label)\n",
    "                plt.ylabel(y_label)\n",
    "                plt.ylim(0,120)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                #plt.show()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            \n",
    "            #Now for CRAIC files, these are separated between R, L and O polarization\n",
    "            #and these are not corrected for jumps, only pri*nted\n",
    "            code_file_counter = 1\n",
    "            \n",
    "            #creates a figure to plot\n",
    "            if CRAIC_files:\n",
    "                code_file_counter += 1\n",
    "                \n",
    "                #Get info for each file\n",
    "                file = CRAIC_files[0]\n",
    "                collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "                genus,species = Specimen_Collection.genus_species_lookup(code, collection_list)\n",
    "                spectrum = Spectrum(file, collection_list,genus,species)\n",
    "                metadata = spectrum.get_metadata()\n",
    "\n",
    "                #check polarizations\n",
    "                right_pol= [file for file in files_with_code if \"R\" in Path(file).name ]\n",
    "                left_pol= [file for file in files_with_code if \"L\" in Path(file).name ]\n",
    "                no_polarization = [file for file in files_with_code if \"O\" in Path(file).name]\n",
    "\n",
    "                if (not right_pol) or (not left_pol):\n",
    "                    continue\n",
    "                #pri*nt(\"2. CRAIC_get_average_polarizations\")\n",
    "                \n",
    "                right_average_df, left_average_df, no_polarization_average_df = CRAIC_get_average_polarizations(CRAIC_files, code)\n",
    "                #print(f\"{right_average_df=}\")\n",
    "                #print(f\"{left_average_df=}\")\n",
    "                right_pol_path = corrected_files_path / \"R\"\n",
    "                left_pol_path = corrected_files_path / \"L\"\n",
    "\n",
    "                plt.figure(figsize=(10, 4))\n",
    "                # Create the figure and axes\n",
    "                \n",
    "                draw_rainbow_background()\n",
    "\n",
    "                #set polarization to R and save\n",
    "                metadata[\"polarization\"] = \"R\"\n",
    "                basename = code+ \"_R.csv\"\n",
    "                \n",
    "                save_corrected_df(folder = right_pol_path, basename = basename ,metadata = metadata,dataframe = right_average_df )\n",
    "                \n",
    "                label = code + \"_R\"\n",
    "                \n",
    "                save_corrected_plot(folder = right_pol_path, basename = basename,metadata = metadata,dataframe = right_average_df, label = label )\n",
    "                \n",
    "\n",
    "                #set polarization to L and save\n",
    "                metadata[\"polarization\"] = \"L\"\n",
    "                basename = code+ \"_L.csv\"\n",
    "                save_corrected_df(folder = left_pol_path, basename = basename ,metadata = metadata,dataframe = left_average_df )\n",
    "\n",
    "                label = (code + \"_L\")\n",
    "                save_corrected_plot(folder = left_pol_path, basename = basename ,metadata = metadata,dataframe = left_average_df, label = label )\n",
    "\n",
    "                \n",
    "                #get average polarizations\n",
    "                    \n",
    "                    \n",
    "                #get total average_df\n",
    "                #pri*nt(\"2. CRAIC_get_total_average_dataframe\")\n",
    "                total_average_df = pd.DataFrame([])\n",
    "                try:\n",
    "                    total_average_df = CRAIC_get_total_average_dataframe(right_average_df, left_average_df)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                #get corrected total average\n",
    "                #pri*nt(\"2. CRAIC_correct_total_average\")\n",
    "                \n",
    "                corrected_total_average_df = CRAIC_correct_total_average(total_average_df)\n",
    "\n",
    "                #p*rint(f\"{corrected_total_average_df=}\")\n",
    "                \n",
    "\n",
    "                basename = code + \".csv\"\n",
    "\n",
    "                \n",
    "                \n",
    "                #saves the corrected file save_corrected_df(folder, basename, metadata, dataframe)\n",
    "                #pri*nt(\"2. save_corrected_df\")\n",
    "                #set polarization to O and save\n",
    "                metadata[\"polarization\"] = \"O\"\n",
    "                basename = code +\".csv\"\n",
    "                save_corrected_df(folder = corrected_files_path, basename = basename,metadata = metadata,dataframe = corrected_total_average_df )\n",
    "                label = (code) + \"_O\"\n",
    "                save_corrected_plot(folder = corrected_files_path, basename = basename,metadata = metadata,dataframe = corrected_total_average_df, label = label )\n",
    "                \n",
    "                plt.title(f'1. CRAIC. R, L and total. Code {code}. {genus} {species}')\n",
    "                plt.xlabel(x_label)\n",
    "                plt.ylabel(y_label)\n",
    "                plt.ylim(0,120)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                #plt.show()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "                ### end for\n",
    "                \n",
    "           \n",
    "create_correction_report(non_empty_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dataframes = None\n",
    "def average_l1050_files(file_list, code_set, directory, pdf):\n",
    "\n",
    "    #parent directory and save_directory\n",
    "    jump_corrected_path = os.path.join( directory , \"jump_corrected_files\")\n",
    "    save_directory = os.path.dirname(jump_corrected_path)\n",
    "    \n",
    "    #p*rint(f\"{save_directory=}\")\n",
    "    file_counter = 0\n",
    "\n",
    "    #Look for every available code in the folder\n",
    "    for code in code_set:\n",
    "        #pr*int(f\"{code=}\") \n",
    "        \n",
    "        dataframes = []\n",
    "        files_with_code =[file for file in file_list if code in Path(file).name] #gets each file that starts with the code provided\n",
    "        #pri*nt(files_with_code)\n",
    "        metadata, df = None, None\n",
    "        \n",
    "        # Read each file, create dataframes, and plot them\n",
    "        for file_path in file_list:\n",
    "            #pri*nt(f\"{file_path=}\")\n",
    "            #create spectrum object\n",
    "            collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "            spectrum = Spectrum(file_path, collection_list)\n",
    "            \n",
    "            #get metadata and dataframe\n",
    "            #pri*nt(\"Reading file...\")\n",
    "            #pri*nt(\"Getting metadata and dataframe...\")\n",
    "            metadata, df = spectrum.get_metadata(), spectrum.get_dataframe()\n",
    "\n",
    "            #metadata info\n",
    "            measuring_mode = metadata[\"measuring_mode\"]\n",
    "            sample_name = metadata[\"code\"] \n",
    "\n",
    "            # Read the file into a pandas DataFrame\n",
    "            #convert columns to float\n",
    "            #pri*nt(\"Converting columns to float...\")\n",
    "            df['wavelength'] = df['wavelength'].astype(float)\n",
    "            df[measuring_mode] = df[measuring_mode].astype(float)\n",
    "            \n",
    "            #pri*nt(\"Dropping index...\")\n",
    "            try:\n",
    "                df = df.drop(\"index\", axis = 1)\n",
    "            except Exception as e:\n",
    "                #pri*nt (e)\n",
    "                pass\n",
    "            #pri*nt(\"pri*nting head...\")\n",
    "            \n",
    "            #pri*nt(df.head())\n",
    "            # Append the dataframe to the list if not empty\n",
    "            if not df.empty and not None and len(df) != 0:\n",
    "                dataframes.append(df) \n",
    "            \n",
    "        # Calculate the average of all dataframes ignore empty ones\n",
    "        # average l1050 files and polarization_sum CRAIC files\n",
    "        #pri*nt(\"elements\")\n",
    "        \n",
    "        #pri*nt(dataframes)\n",
    "        #pri*nt(f\"{len(dataframes)=}\")\n",
    "\n",
    "        #If there are no dataframes, continue\n",
    "        if len(dataframes) == 0:\n",
    "            continue\n",
    "        #If there is only one \n",
    "        elif len(dataframes) == 1:\n",
    "            average_df = dataframes[0]\n",
    "            std_dev_df = pd.DataFrame([])\n",
    "            std_dev_df[\"wavelength\"] = []\n",
    "            std_dev_df[\"%R\"] =[]\n",
    "        #If there are many\n",
    "        else:\n",
    "            average_df = pd.concat(dataframes).groupby('wavelength').mean().reset_index()\n",
    "            std_dev_df = pd.concat(dataframes).groupby('wavelength').std().reset_index()\n",
    "\n",
    "        try: \n",
    "            #pri*nt(f\"{average_df=}\")\n",
    "            \n",
    "            #average plot\n",
    "            \n",
    "            plot_wavelength_intensity(metadata = metadata, dataframe = average_df,kind='scatter', s=markersize, label = sample_name + \" avg\" )\n",
    "            #save figures\n",
    "            plt.title(f\"Average. Code {code}\")\n",
    "            plt.ylim(0,y.max()*1.1)\n",
    "            pdf.savefig()\n",
    "            #close plot\n",
    "            plt.close()\n",
    "            \n",
    "            # #standard deviation plot\n",
    "            # std_plot = std_dev_df.plot(x='wavelength', y=measuring_mode, color = \"r\", kind='scatter', s=markersize, title = sample_name + \" std dev\", figsize = (10,4), grid=True)\n",
    "            # #save figures\n",
    "            # pdf.savefig()\n",
    "            # #close plot\n",
    "            # plt.close()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            #pri*nt(e)\n",
    "            \n",
    "        #SAVE FILE\n",
    "        #Convert to numpy\n",
    "        average_np = average_df.to_numpy()\n",
    "        std_dev_np = std_dev_df.to_numpy()\n",
    "        \n",
    "        #Create new folder\n",
    "      \n",
    "        avg_new_path = os.path.join(save_directory , \"average\")\n",
    "        std_dev_new_path = os.path.join(save_directory , \"std_dev\") \n",
    "\n",
    "        \n",
    "        if not os.path.exists(avg_new_path):\n",
    "            os.mkdir(avg_new_path)\n",
    "        if not os.path.exists(std_dev_new_path):\n",
    "            os.mkdir(std_dev_new_path)\n",
    "\n",
    "        #creates new filename\n",
    "        #pri*nt(f\"sample name: {sample_name}\")\n",
    "\n",
    "        new_avg_archive_name = os.path.join(avg_new_path, sample_name+'.txt')\n",
    "        new_std_dev_archive_name = os.path.join( std_dev_new_path , sample_name+'.txt')\n",
    "\n",
    "        #pri*nt(new_avg_archive_name)\n",
    "        #saves files\n",
    "        np.savetxt(new_avg_archive_name, average_np,fmt = \"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n",
    "        np.savetxt(new_std_dev_archive_name, std_dev_np,fmt = \"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n",
    "        #pri*nt(\"fin de la iteracion\")\n",
    "\n",
    "        def delete_blank_row(archive_name):\n",
    "            with open(archive_name, \"r\") as f:\n",
    "                data = f.read()\n",
    "            with open(archive_name, \"w\") as f:\n",
    "                f.write(data.replace(\"#DATA\\n\",\"#DATA\"))\n",
    "\n",
    "        delete_blank_row(new_avg_archive_name)\n",
    "        delete_blank_row(new_std_dev_archive_name)\n",
    "                         \n",
    "        file_counter = file_counter +1\n",
    "        \n",
    "    #pri*nt(f\"{file_counter} averages were calculated\")\n",
    "    #pri*nt(f\"Report file is located in {save_directory}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timer\n",
    "def std_l1050_files_parallel(file_list, code_set, directory, pdf, max_workers=4):\n",
    "    jump_corrected_path = os.path.join(directory, \"jump_corrected_files\")\n",
    "    save_directory = os.path.dirname(jump_corrected_path)\n",
    "    file_counter = 0\n",
    "\n",
    "    # Define a helper function to process individual codes\n",
    "    def process_code(code):\n",
    "        dataframes = []\n",
    "        files_with_code = [file for file in file_list if code in Path(file).name]\n",
    "\n",
    "        for file_path in file_list:\n",
    "            collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "            spectrum = Spectrum(file_path, collection_list)\n",
    "            metadata, df = spectrum.get_metadata(), spectrum.get_dataframe()\n",
    "\n",
    "            df['wavelength'] = df['wavelength'].astype(float)\n",
    "            df[metadata[\"measuring_mode\"]] = df[metadata[\"measuring_mode\"]].astype(float)\n",
    "\n",
    "            if not df.empty and df is not None and len(df) != 0:\n",
    "                dataframes.append(df)\n",
    "\n",
    "        if len(dataframes) == 0:\n",
    "            return None\n",
    "\n",
    "        elif len(dataframes) == 1:\n",
    "            average_df = dataframes[0]\n",
    "            std_dev_df = pd.DataFrame([])\n",
    "            std_dev_df[\"wavelength\"], std_dev_df[\"%R\"] = [], []\n",
    "\n",
    "        else:\n",
    "            average_df = pd.concat(dataframes).groupby('wavelength').mean().reset_index()\n",
    "            std_dev_df = pd.concat(dataframes).groupby('wavelength').std().reset_index()\n",
    "\n",
    "        return average_df, std_dev_df, metadata, code\n",
    "\n",
    "    # Use parallel processing for each code\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_code, code): code for code in code_set}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "    # Save results and generate plots\n",
    "    for average_df, std_dev_df, metadata, code in results:\n",
    "        save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf)\n",
    "        file_counter += 1\n",
    "\n",
    "def save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf):\n",
    "    avg_new_path = os.path.join(save_directory, \"average\")\n",
    "    std_dev_new_path = os.path.join(save_directory, \"std_dev\")\n",
    "    os.makedirs(avg_new_path, exist_ok=True)\n",
    "    os.makedirs(std_dev_new_path, exist_ok=True)\n",
    "\n",
    "    new_avg_archive_name = os.path.join(avg_new_path, f\"{code}.txt\")\n",
    "    new_std_dev_archive_name = os.path.join(std_dev_new_path, f\"{code}.txt\")\n",
    "\n",
    "    np.savetxt(new_avg_archive_name, average_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n",
    "    np.savetxt(new_std_dev_archive_name, std_dev_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56785661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_CRAIC_files(file_list, code, directory, pdf):\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        #pri*nt(\"3. CRAIC_get_average_polarizations\")\n",
    "        right_average_df, left_average_df, no_pol_average_df = CRAIC_get_average_polarizations(files_with_code= file_list, code = code)\n",
    "        #pri*nt(f\"{right_average_df=}\")\n",
    "        #pri*nt(f\"{left_average_df=}\")\n",
    "        total_average_df = pd.DataFrame([])\n",
    "        if right_average_df.empty or not left_average_df.empty:\n",
    "            raise Exception(\"These dfs can't be empty\")\n",
    "        #return average dataframe\n",
    "        if not right_average_df.empty and not left_average_df.empty:\n",
    "            total_average_df = CRAIC_get_total_average_dataframe(right_average_df, left_average_df)\n",
    "        if total_average_df.empty:\n",
    "            total_average_df = no_pol_average_df\n",
    "        #pri*nt(f\"{total_average_df=}\")\n",
    "        #correct it \n",
    "        corrected_df = CRAIC_correct_total_average(total_average_df)\n",
    "        #pri*nt(f\"{corrected_df=}\")\n",
    "        #create spectrum with that df\n",
    "\n",
    "        return corrected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_CRAIC_df(file_list, code, collection_list):\n",
    "    #pri*nt(f\"Average Craic\")\n",
    "    spectra = []\n",
    "    #create a spectrum for each file\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            \n",
    "            spectrum = create_spectrum_from_file(file, code, collection_list)\n",
    "            spectra.append(spectrum)\n",
    "            #pri*nt(f\"{spectra=}\")\n",
    "        except Exception as e: \n",
    "            pass\n",
    "            #pri*nt(e)\n",
    "            \n",
    "    #get each dataframe\n",
    "    dfs = [spectrum.get_dataframe() for spectrum in spectra]\n",
    "    dfs = [df for df in dfs if not df.empty]\n",
    "    #print(dfs)\n",
    "    #average each dataframe\n",
    "    grouped_df = pd.concat(dfs).groupby('wavelength')\n",
    "    std_df = grouped_df.std().reset_index()\n",
    "    \n",
    "    #return average dataframe\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_get_std_polarizations(files_with_code= file_list, code = code):\n",
    "    #pri*nt(f\"{files_with_code=}\")\n",
    "    #pri*nt(f\"{code=}\")\n",
    "    #get right and left polarization \n",
    "    right_pol= [file for file in files_with_code if \"R\" in Path(file).name ]\n",
    "    left_pol= [file for file in files_with_code if \"L\" in Path(file).name ]\n",
    "    #no_polarization = [file for file in files_with_code if \"O\" in Path(file).name]\n",
    "    no_polarization_std_df = None\n",
    "    #pri*nt(f\"{right_pol=}\")\n",
    "    #pri*nt(f\"{left_pol=}\")\n",
    "    #pri*nt(f\"{no_polarization=}\")\n",
    "    #average each polarization\n",
    "    #pri*nt(\"4. right average_CRAIC_df\")\n",
    "    right_std_df = std_CRAIC_df(right_pol, code, collection_list)\n",
    "    right_std_df[\"%R\"] = right_std_df[\"%R\"] *0.5 #TODO spectral factor for filter correction  \n",
    "    #pri*nt(\"4. left average_CRAIC_df\")\n",
    "    left_std_df = std_CRAIC_df(left_pol, code, collection_list)\n",
    "    left_std_df[\"%R\"] = left_std_df[\"%R\"] *0.5 #TODO spectral factor for filter correction  \n",
    "    #pri*nt(f\"{right_average_df=}\")\n",
    "    #pri*nt(f\"{left_average_df=}\")\n",
    "    return right_std_df, left_std_df, no_polarization_std_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a25cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRAIC_get_total_std_dataframe(right_std_df, left_std_df):\n",
    "    \n",
    "    # Ensure the DataFrames have the same structure\n",
    "    if right_std_df.shape != left_std_df.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape to compute total averages.\")\n",
    "    \n",
    "    # Calculate the total average DataFrame\n",
    "    total_std_df = right_std_df\n",
    "    #sigma_Z = np.sqrt(sigma_X**2 + sigma_Y**2)\n",
    "    total_std_df[\"%R\"] = (right_std_df[\"%R\"]*right_std_df[\"%R\"] + left_std_df[\"%R\"]*left_std_df[\"%R\"])**(1/2)\n",
    "    \n",
    "    return total_std_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39084ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_CRAIC_files(file_list, code, directory, pdf):\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        #pri*nt(\"3. CRAIC_get_average_polarizations\")\n",
    "        right_average_df, left_average_df, no_pol_average_df = CRAIC_get_average_polarizations(files_with_code= file_list, code = code)\n",
    "        right_std_df, left_std_df, no_pol_std_df = CRAIC_get_std_polarizations(files_with_code= file_list, code = code)\n",
    "        #pri*nt(f\"{right_average_df=}\")\n",
    "        #pri*nt(f\"{left_average_df=}\")\n",
    "      \n",
    "        #return average dataframe\n",
    "        total_std_df = CRAIC_get_total_std_dataframe(right_std_df, left_std_df)\n",
    "        \n",
    "        #pri*nt(f\"{total_average_df=}\")\n",
    "        #correct it \n",
    "        #pri*nt(f\"{corrected_df=}\")\n",
    "        #create spectrum with that df\n",
    "\n",
    "        return total_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this list we will make a set of codes.\n",
    "#pri*nt(filenames)\n",
    "codes_2 = codes\n",
    "#pri*nt(f\"codes {codes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timer\n",
    "def std_l1050_files_parallel(file_list, code_set, directory, pdf, max_workers=4):\n",
    "    jump_corrected_path = os.path.join(directory, \"jump_corrected_files\")\n",
    "    save_directory = os.path.dirname(jump_corrected_path)\n",
    "    file_counter = 0\n",
    "\n",
    "    # Define a helper function to process individual codes\n",
    "    def process_code(code):\n",
    "        dataframes = []\n",
    "        files_with_code = [file for file in file_list if code in Path(file).name]\n",
    "\n",
    "        for file_path in file_list:\n",
    "            collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "            spectrum = Spectrum(file_path, collection_list)\n",
    "            metadata, df = spectrum.get_metadata(), spectrum.get_dataframe()\n",
    "\n",
    "            df['wavelength'] = df['wavelength'].astype(float)\n",
    "            df[metadata[\"measuring_mode\"]] = df[metadata[\"measuring_mode\"]].astype(float)\n",
    "\n",
    "            if not df.empty and df is not None and len(df) != 0:\n",
    "                dataframes.append(df)\n",
    "\n",
    "        if len(dataframes) == 0:\n",
    "            return None\n",
    "\n",
    "        elif len(dataframes) == 1:\n",
    "            average_df = dataframes[0]\n",
    "            std_dev_df = pd.DataFrame([])\n",
    "            std_dev_df[\"wavelength\"], std_dev_df[\"%R\"] = [], []\n",
    "\n",
    "        else:\n",
    "            average_df = pd.concat(dataframes).groupby('wavelength').mean().reset_index()\n",
    "            std_dev_df = pd.concat(dataframes).groupby('wavelength').std().reset_index()\n",
    "\n",
    "        return average_df, std_dev_df, metadata, code\n",
    "\n",
    "    # Use parallel processing for each code\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_code, code): code for code in code_set}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "    # Save results and generate plots\n",
    "    for average_df, std_dev_df, metadata, code in results:\n",
    "        save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf)\n",
    "        file_counter += 1\n",
    "\n",
    "def save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf):\n",
    "    avg_new_path = os.path.join(save_directory, \"average\")\n",
    "    std_dev_new_path = os.path.join(save_directory, \"std_dev\")\n",
    "    os.makedirs(avg_new_path, exist_ok=True)\n",
    "    os.makedirs(std_dev_new_path, exist_ok=True)\n",
    "\n",
    "    new_avg_archive_name = os.path.join(avg_new_path, f\"{code}.txt\")\n",
    "    new_std_dev_archive_name = os.path.join(std_dev_new_path, f\"{code}.txt\")\n",
    "\n",
    "    np.savetxt(new_avg_archive_name, average_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n",
    "    np.savetxt(new_std_dev_archive_name, std_dev_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@timer\n",
    "def std_l1050_files_parallel(file_list, code_set, directory, pdf, max_workers=4):\n",
    "    jump_corrected_path = os.path.join(directory, \"jump_corrected_files\")\n",
    "    save_directory = os.path.dirname(jump_corrected_path)\n",
    "    file_counter = 0\n",
    "\n",
    "    # Define a helper function to process individual codes\n",
    "    def process_code(code):\n",
    "        dataframes = []\n",
    "        files_with_code = [file for file in file_list if code in Path(file).name]\n",
    "\n",
    "        for file_path in file_list:\n",
    "            collection = Specimen_Collection.collection_lookup(code, collection_list)\n",
    "            spectrum = Spectrum(file_path, collection_list)\n",
    "            metadata, df = spectrum.get_metadata(), spectrum.get_dataframe()\n",
    "\n",
    "            df['wavelength'] = df['wavelength'].astype(float)\n",
    "            df[metadata[\"measuring_mode\"]] = df[metadata[\"measuring_mode\"]].astype(float)\n",
    "\n",
    "            if not df.empty and df is not None and len(df) != 0:\n",
    "                dataframes.append(df)\n",
    "\n",
    "        if len(dataframes) == 0:\n",
    "            return None\n",
    "\n",
    "        elif len(dataframes) == 1:\n",
    "            average_df = dataframes[0]\n",
    "            std_dev_df = pd.DataFrame([])\n",
    "            std_dev_df[\"wavelength\"], std_dev_df[\"%R\"] = [], []\n",
    "\n",
    "        else:\n",
    "            average_df = pd.concat(dataframes).groupby('wavelength').mean().reset_index()\n",
    "            std_dev_df = pd.concat(dataframes).groupby('wavelength').std().reset_index()\n",
    "\n",
    "        return average_df, std_dev_df, metadata, code\n",
    "\n",
    "    # Use parallel processing for each code\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_code, code): code for code in code_set}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "    # Save results and generate plots\n",
    "    for average_df, std_dev_df, metadata, code in results:\n",
    "        save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf)\n",
    "        file_counter += 1\n",
    "\n",
    "def save_dataframes(average_df, std_dev_df, save_directory, code, metadata, pdf):\n",
    "    avg_new_path = os.path.join(save_directory, \"average\")\n",
    "    std_dev_new_path = os.path.join(save_directory, \"std_dev\")\n",
    "    os.makedirs(avg_new_path, exist_ok=True)\n",
    "    os.makedirs(std_dev_new_path, exist_ok=True)\n",
    "\n",
    "    new_avg_archive_name = os.path.join(avg_new_path, f\"{code}.txt\")\n",
    "    new_std_dev_archive_name = os.path.join(std_dev_new_path, f\"{code}.txt\")\n",
    "\n",
    "    np.savetxt(new_avg_archive_name, average_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n",
    "    np.savetxt(new_std_dev_archive_name, std_dev_df.to_numpy(), fmt=\"%.6f\", delimiter=\"\\t\", header=metadata[\"header\"], comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708d44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18009713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060f306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018f901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb4f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d8fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
