{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036c2631-ff5b-43de-8b0a-b0b3659cbfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:125: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:125: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\esteb\\AppData\\Local\\Temp\\ipykernel_20712\\2310357367.py:125: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  plt.ylabel(f\"{column} [$\\mu$m]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded from metric_image.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage  # Correct import for PIL Image\n",
    "\n",
    "# ReportLab imports\n",
    "#from reportlab.lib.pagesizes import letter\n",
    "#from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "#from reportlab.platypus import Paragraph, Spacer, Image, PageBreak, SimpleDocTemplate\n",
    "import datetime\n",
    "\n",
    "# Counter\n",
    "global figure_counter \n",
    "figure_counter = 1\n",
    "\n",
    "# Methods\n",
    "def createTextObject(text, style, centered=False):\n",
    "    \"\"\"\n",
    "    Creates a Paragraph with optional centered alignment.\n",
    "    \"\"\"\n",
    "    if centered:\n",
    "        style = ParagraphStyle(name=\"Centered\", parent=style, alignment=1)  # 1 = TA_CENTER\n",
    "    return Paragraph(text, style)\n",
    "\n",
    "def generate_violin_plot(df, column, group_by=None):\n",
    "    \"\"\"\n",
    "    Generates a violin plot for a given column of a DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    if group_by:\n",
    "        sns.violinplot(data=df, x=group_by, y=column)\n",
    "    else:\n",
    "        sns.violinplot(data=df[column])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format=\"PNG\")\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def generate_boxplot_with_stripplot(df, column, group_by=\"species\", output_filename = None):\n",
    "    \"\"\"\n",
    "    Generates a boxplot with stripplot (points for each data point) where outliers\n",
    "    (those falling outside 1.5 times the IQR) are shown as red points and the rest as black.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column (str): The column to plot.\n",
    "        group_by (str, optional): The column to group by. If None, no grouping is applied.\n",
    "\n",
    "    Returns:\n",
    "        BytesIO: A buffer containing the plot image in PNG format.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    #check if ratio\n",
    "\n",
    "    is_ratio = \"÷\" in column\n",
    "    \n",
    "    \n",
    "    if group_by:\n",
    "        # Draw the boxplot without fliers\n",
    "        sns.boxplot(data=df, x=group_by, y=column, hue=group_by, palette=\"Set2\", legend=False, showfliers=False)\n",
    "        \n",
    "        # For each group, compute the IQR-based bounds and plot points accordingly\n",
    "        groups = df[group_by].unique()\n",
    "        for grp in groups:\n",
    "            # Select data for this group\n",
    "            grp_data = df[df[group_by] == grp][column]\n",
    "            Q1 = grp_data.quantile(0.25)\n",
    "            Q3 = grp_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Classify the points as non-outliers and outliers\n",
    "            non_outliers = grp_data[(grp_data >= lower_bound) & (grp_data <= upper_bound)]\n",
    "            outliers = grp_data[(grp_data < lower_bound) | (grp_data > upper_bound)]\n",
    "            \n",
    "            # Plot non-outliers (black)\n",
    "            sns.stripplot(x=[grp] * len(non_outliers), y=non_outliers, color=\"black\", alpha=0.5, jitter=True)\n",
    "            # Plot outliers (red)\n",
    "            sns.stripplot(x=[grp] * len(outliers), y=outliers, color=\"red\", alpha=0.5, jitter=True)\n",
    "        \n",
    "        plt.xlabel(\"\")  # No x-axis label needed when not grouped\n",
    "        plt.title(f\"Boxplot with Stripplot of {column} grouped by {group_by}\")\n",
    "    else:\n",
    "        # Draw the boxplot without fliers for the whole column\n",
    "        sns.boxplot(data=df, y=column, color=\"lightblue\", showfliers=False)\n",
    "        \n",
    "        # Compute bounds for the overall data\n",
    "        data = df[column]\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Classify the points\n",
    "        non_outliers = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "        outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "        \n",
    "        # When no grouping, use a constant x value (e.g., 0) for all points\n",
    "        sns.stripplot(x=[0] * len(non_outliers), y=non_outliers, color=\"black\", alpha=0.5, jitter=True)\n",
    "        sns.stripplot(x=[0] * len(outliers), y=outliers, color=\"red\", alpha=0.5, jitter=True)\n",
    "        plt.title(f\"Boxplot with Stripplot of {column}\")\n",
    "        plt.xlabel(\"\")  # No x-axis label needed when not grouped\n",
    "\n",
    "    \n",
    "    if not is_ratio:\n",
    "        plt.ylabel(f\"{column} [$\\mu$m]\")\n",
    "    else:\n",
    "        plt.ylabel(column)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot into a BytesIO buffer in PNG format\n",
    "    buffer = BytesIO()\n",
    "    print(f\"Saving as {output_filename}\")\n",
    "    plt.savefig(output_filename, format=\"png\")\n",
    "    plt.savefig(buffer, format=\"PNG\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "global metric_image\n",
    "metric_image = {\n",
    "    \"A1\": \"Head_A1.png\",\n",
    "    \"A2\": \"Head_A2.png\",\n",
    "    \"A3\": \"Head_A3.png\",\n",
    "    \"A4\": \"Head_A4.png\",\n",
    "    \"A5\": \"Head_A5.png\",\n",
    "    \"B1\": \"Pronotum_B1.png\",\n",
    "    \"B2\": \"Pronotum_B2.png\",\n",
    "    \"B3\": \"Pronotum_B3.png\",\n",
    "    \"B4\": \"Pronotum_B4.png\",\n",
    "    \"B5\": \"Pronotum_B5.png\",\n",
    "    \"C1\": \"Lateral_C1.png\",\n",
    "    \"D1\": \"Mesosternal_process_D1.png\",\n",
    "    \"D2\": \"Mesosternal_process_D2.png\",\n",
    "    \"D3\": \"Mesosternal_process_D3.png\",\n",
    "    \"D4\": \"Mesosternal_process_D4.png\",\n",
    "    \"E1\": \"Prosternal_process_E1.png\",\n",
    "    \"E2\": \"Prosternal_process_E2.png\",\n",
    "    \"F1\": \"Ventral.png\",\n",
    "    \"F2\": \"Ventral.png\",\n",
    "    \"F3\": \"Ventral.png\",\n",
    "    \"F4\": \"Ventral.png\",\n",
    "    \"F5\": \"Ventral.png\",\n",
    "    \"A1÷A3\": \"Head.png\",\n",
    "    \"A4÷A3\": \"Head.png\",\n",
    "    \"A5÷A3\": \"Head.png\",\n",
    "    \"B4÷B1\": \"Pronotum.png\",\n",
    "    \"B4÷B2\": \"Pronotum.png\",\n",
    "    \"B4÷B3\": \"Pronotum.png\",\n",
    "    \"D2÷D1\": \"Mesosternal_process_D4.png\",\n",
    "    \"D2÷D3\": \"Mesosternal_process_D4.png\",\n",
    "    \"E1÷E2\": \"Prosternal_process.png\",\n",
    "}\n",
    "\n",
    "                     \n",
    "# Location of images\n",
    "global protocol_image_location\n",
    "protocol_image_location = Path(r\"C:\\Users\\esteb\\escarabajos\\biometry\\report_output\\images\\protocol\")\n",
    "\n",
    "# --- Saving and Loading the Dictionary ---\n",
    "\n",
    "def save_dictionary_to_json(dictionary, filepath):\n",
    "    \"\"\"\n",
    "    Saves the metric_image dictionary to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        dictionary (dict): The dictionary to save.\n",
    "        filepath (str or Path): The path to the file where the dictionary will be saved.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        json.dump(dictionary, file, indent=4)\n",
    "    print(f\"Dictionary saved to {filepath}\")\n",
    "\n",
    "def load_json_to_dictionary(filepath):\n",
    "    \"\"\"\n",
    "    Loads the metric_image dictionary from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str or Path): The path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The loaded dictionary.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        loaded_dict = json.load(file)\n",
    "    print(f\"Dictionary loaded from {filepath}\")\n",
    "    return loaded_dict\n",
    "\n",
    "# Define the path for the JSON file\n",
    "metric_image_file = Path(\"metric_image.json\")\n",
    "\n",
    "# Save the metric_image dictionary\n",
    "#save_dictionary_to_json(metric_image, metric_image_file)\n",
    "\n",
    "# Later, load the dictionary from the file\n",
    "metric_image_loaded = load_json_to_dictionary(metric_image_file)\n",
    "\n",
    "# Optional: Verify that both dictionaries are the same\n",
    "#assert metric_image == metric_image_loaded, \"The loaded dictionary does not match the original!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a920d07e-e86b-4c3a-92ed-c9e5d1c61e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "                A1           A2           A3           A4           A5  \\\n",
      "count    37.000000    37.000000    37.000000    37.000000    37.000000   \n",
      "mean   4109.505135  3697.212703  4712.424595  1812.224324  1779.767838   \n",
      "std     250.101576   177.305029   181.444406   255.782814   294.472808   \n",
      "min    3492.880000  3451.580000  4300.610000  1379.670000  1392.690000   \n",
      "25%    3977.820000  3538.610000  4569.680000  1599.460000  1517.120000   \n",
      "50%    4117.200000  3668.760000  4728.880000  1885.550000  1696.300000   \n",
      "75%    4282.460000  3814.100000  4858.170000  2039.240000  2028.420000   \n",
      "max    4594.630000  4090.030000  5058.530000  2229.410000  2363.890000   \n",
      "\n",
      "                B1           B2           B3           B4          B5  ...  \\\n",
      "count    42.000000    42.000000    42.000000    42.000000   42.000000  ...   \n",
      "mean   5553.055952  8276.477143  8737.027381  5405.136429  150.545000  ...   \n",
      "std     248.590956   508.676618   537.294658   406.046257    3.647167  ...   \n",
      "min    5058.620000  7130.950000  7709.840000  4575.510000  142.620000  ...   \n",
      "25%    5360.212500  7979.165000  8378.200000  5137.077500  148.557500  ...   \n",
      "50%    5569.105000  8327.790000  8673.935000  5456.745000  150.010000  ...   \n",
      "75%    5729.685000  8651.952500  9067.397500  5746.220000  153.162500  ...   \n",
      "max    6054.120000  9158.450000  9670.860000  6014.860000  158.790000  ...   \n",
      "\n",
      "                F5         W2         W3         W4         W5         W6  \\\n",
      "count    41.000000  37.000000  37.000000  37.000000  41.000000  42.000000   \n",
      "mean   1629.735122   0.872775   0.385022   0.369311   0.972209   0.652947   \n",
      "std     279.159370   0.054441   0.056062   0.084211   0.048292   0.024734   \n",
      "min     943.280000   0.729411   0.300123   0.003030   0.826178   0.542044   \n",
      "25%    1460.690000   0.841366   0.328575   0.324615   0.933689   0.641627   \n",
      "50%    1639.360000   0.880972   0.403127   0.376002   0.990057   0.654028   \n",
      "75%    1815.100000   0.904939   0.431742   0.429507   1.008680   0.667849   \n",
      "max    2485.280000   0.995780   0.475367   0.476106   1.048357   0.700467   \n",
      "\n",
      "              W7         W9        W10        W13  \n",
      "count  41.000000  42.000000  42.000000  42.000000  \n",
      "mean    0.618188   0.539430   0.310475   0.658788  \n",
      "std     0.023528   0.060508   0.032462   0.102396  \n",
      "min     0.512999   0.375515   0.251513   0.488846  \n",
      "25%     0.606547   0.500790   0.283833   0.585027  \n",
      "50%     0.623922   0.534747   0.313714   0.663592  \n",
      "75%     0.633544   0.570944   0.330516   0.703840  \n",
      "max     0.648031   0.663984   0.362840   0.975501  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "['A1÷A3', 'A4÷A3', 'A5÷A3', 'B4÷B1', 'B4÷B2', 'B4÷B3', 'D2÷D1', 'D3÷D1', 'D4÷D2', 'E1÷E2']\n",
      "New metrics saved to metrics.csv\n"
     ]
    }
   ],
   "source": [
    "relative_metrics = []\n",
    "absolute_metrics = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"C1\", \"D1\", \"D2\", \"D3\", \"D4\", \"E1\", \"E2\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\"]\n",
    "required_columns = absolute_metrics + [\"code\"]\n",
    "\n",
    "def feature_engineering(measurement_df):\n",
    "    # Ensure the required columns are present in the DataFrame\n",
    "    # Check if all required columns are available in the DataFrame\n",
    "    for column in required_columns:\n",
    "        if column not in measurement_df.columns:\n",
    "            print(f\"Warning: Missing column {column} in the DataFrame.\")\n",
    "    \n",
    "    # --- Statistics: Descriptive statistics for the measurements ---\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(measurement_df.describe())  # Basic statistics (mean, std, min, 25%, 50%, 75%, max)\n",
    "    \n",
    "    # --- Absolute Metrics ---\n",
    "    # Example: Metric for A1 (could be specific characteristics or formulae for these metrics)\n",
    "    #measurement_df[\"W1\"] = measurement_df[\"A1\"]  # Example, assuming A1 is a numeric column\n",
    "\n",
    "    # --- Relative Metrics ---\n",
    "   \n",
    "    measurement_df[\"A1÷A3\"] = measurement_df[\"A1\"] / measurement_df[\"A3\"]\n",
    "    measurement_df[\"A4÷A3\"] = measurement_df[\"A4\"] / measurement_df[\"A3\"]\n",
    "    measurement_df[\"A5÷A3\"] = measurement_df[\"A5\"] / measurement_df[\"A3\"]\n",
    "\n",
    "    # --- Pronoto: Kalinini has a longer pronoto compared to its width ---\n",
    "    # Example: Calculating relative metric B4/B1, B4/B2, B4/B3\n",
    "    measurement_df[\"B4÷B1\"] = measurement_df[\"B4\"] / measurement_df[\"B1\"]\n",
    "    measurement_df[\"B4÷B2\"] = measurement_df[\"B4\"] / measurement_df[\"B2\"]\n",
    "    measurement_df[\"B4÷B3\"] = measurement_df[\"B4\"] / measurement_df[\"B3\"]\n",
    "\n",
    "    # --- Mesosternal Process: Example of a metric based on \"más brillante\" (more shiny) ---\n",
    "    # Let's assume we have a measure for brightness or some characteristic that corresponds to this.\n",
    "    # Using D2 as an example for being \"more short\" (assumed metric), you could add a new metric:\n",
    "    \n",
    "    # --- More Width (D1/D2, D3/D2) ---\n",
    "    measurement_df[\"D2÷D1\"] = measurement_df[\"D2\"] / measurement_df[\"D1\"]\n",
    "    measurement_df[\"D3÷D1\"] = measurement_df[\"D3\"] / measurement_df[\"D1\"]\n",
    "    measurement_df[\"D4÷D2\"] = measurement_df[\"D4\"] / measurement_df[\"D2\"]\n",
    "    \n",
    "    # --- Relative Metric: E1/E2 ---\n",
    "    measurement_df[\"E1÷E2\"] = measurement_df[\"E1\"] / measurement_df[\"E2\"]\n",
    "\n",
    "    relative_metrics = [\"A1÷A3\", \"A4÷A3\", \"A5÷A3\", \"B4÷B1\", \"B4÷B2\", \"B4÷B3\", \"D2÷D1\", \"D3÷D1\", \"D4÷D2\", \"E1÷E2\"]\n",
    "    # --- Return the updated DataFrame ---\n",
    "    return measurement_df, relative_metrics\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "#date = datetime.date.today()\n",
    "#file_path = f'summary just png files {date}.csv'  # Path to your saved file\n",
    "file_path = f\"summary just png files 2025-02-16.csv\"\n",
    "measurement_df = pd.read_csv(file_path, sep='\\t', decimal='.', header=0)\n",
    "\n",
    "\n",
    "# Print the first few rows to verify it worked\n",
    "#print(measurement_df.head())\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `measurement_df` contains the extracted measurements from OCR.\n",
    "# You can now apply the feature engineering function to the DataFrame.\n",
    "measurement_df_2, relative_metrics = feature_engineering(measurement_df)\n",
    "print(relative_metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame([])\n",
    "metrics_df[\"code\"] = measurement_df_2[\"code\"]\n",
    "columns = [col for col in measurement_df_2.columns if col != \"code\"]\n",
    "for col in columns:\n",
    "    metrics_df[col] = measurement_df_2[col]\n",
    "# Print the final DataFrame to check the new features\n",
    "#print(measurement_df_2)\n",
    "\n",
    "#save the df into a file\n",
    "filename = \"metrics.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(filename, index=False, sep = \"\\t\", decimal = \".\" )\n",
    "print(f\"New metrics saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a251104-ce16-4e66-bd27-2e51fb844270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>column</th>\n",
       "      <th>outlier_value</th>\n",
       "      <th>median</th>\n",
       "      <th>lower_whisker</th>\n",
       "      <th>upper_whisker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CICIMAUCR0232</td>\n",
       "      <td>A1</td>\n",
       "      <td>3492.880000</td>\n",
       "      <td>4117.200000</td>\n",
       "      <td>3520.860000</td>\n",
       "      <td>4739.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CICIMAUCR0252</td>\n",
       "      <td>C1</td>\n",
       "      <td>164.380000</td>\n",
       "      <td>151.140000</td>\n",
       "      <td>140.220000</td>\n",
       "      <td>162.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CICIMAUCR0233</td>\n",
       "      <td>D2</td>\n",
       "      <td>884.710000</td>\n",
       "      <td>671.405000</td>\n",
       "      <td>456.335000</td>\n",
       "      <td>882.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>D3</td>\n",
       "      <td>1554.090000</td>\n",
       "      <td>2282.120000</td>\n",
       "      <td>1619.626250</td>\n",
       "      <td>2881.936250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CICIMAUCR0242</td>\n",
       "      <td>D3</td>\n",
       "      <td>1495.300000</td>\n",
       "      <td>2282.120000</td>\n",
       "      <td>1619.626250</td>\n",
       "      <td>2881.936250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CICIMAUCR0261</td>\n",
       "      <td>F5</td>\n",
       "      <td>2485.280000</td>\n",
       "      <td>1639.360000</td>\n",
       "      <td>929.075000</td>\n",
       "      <td>2346.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CICIMAUCR0232</td>\n",
       "      <td>W2</td>\n",
       "      <td>0.729411</td>\n",
       "      <td>0.880972</td>\n",
       "      <td>0.746008</td>\n",
       "      <td>1.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CICIMAUCR0204</td>\n",
       "      <td>W4</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.376002</td>\n",
       "      <td>0.167276</td>\n",
       "      <td>0.586846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>W6</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.654028</td>\n",
       "      <td>0.602293</td>\n",
       "      <td>0.707183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>W7</td>\n",
       "      <td>0.512999</td>\n",
       "      <td>0.623922</td>\n",
       "      <td>0.566053</td>\n",
       "      <td>0.674038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>W9</td>\n",
       "      <td>0.375515</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.395560</td>\n",
       "      <td>0.676174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CICIMAUCR0247</td>\n",
       "      <td>W13</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.663592</td>\n",
       "      <td>0.406807</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CICIMAUCR0232</td>\n",
       "      <td>A1÷A3</td>\n",
       "      <td>0.729411</td>\n",
       "      <td>0.880972</td>\n",
       "      <td>0.746008</td>\n",
       "      <td>1.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>B4÷B2</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.654028</td>\n",
       "      <td>0.602293</td>\n",
       "      <td>0.707183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>B4÷B3</td>\n",
       "      <td>0.512999</td>\n",
       "      <td>0.624126</td>\n",
       "      <td>0.568588</td>\n",
       "      <td>0.671957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>D2÷D1</td>\n",
       "      <td>0.375515</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.395560</td>\n",
       "      <td>0.676174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>D3÷D1</td>\n",
       "      <td>1.150419</td>\n",
       "      <td>1.748780</td>\n",
       "      <td>1.162962</td>\n",
       "      <td>2.400468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CICIMAUCR0247</td>\n",
       "      <td>E1÷E2</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.663592</td>\n",
       "      <td>0.406807</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             code column  outlier_value       median  lower_whisker  \\\n",
       "0   CICIMAUCR0232     A1    3492.880000  4117.200000    3520.860000   \n",
       "1   CICIMAUCR0252     C1     164.380000   151.140000     140.220000   \n",
       "2   CICIMAUCR0233     D2     884.710000   671.405000     456.335000   \n",
       "3   CICIMAUCR0215     D3    1554.090000  2282.120000    1619.626250   \n",
       "4   CICIMAUCR0242     D3    1495.300000  2282.120000    1619.626250   \n",
       "5   CICIMAUCR0261     F5    2485.280000  1639.360000     929.075000   \n",
       "6   CICIMAUCR0232     W2       0.729411     0.880972       0.746008   \n",
       "7   CICIMAUCR0204     W4       0.003030     0.376002       0.167276   \n",
       "8   CICIMAUCR0248     W6       0.542044     0.654028       0.602293   \n",
       "9   CICIMAUCR0248     W7       0.512999     0.623922       0.566053   \n",
       "10  CICIMAUCR0215     W9       0.375515     0.534747       0.395560   \n",
       "11  CICIMAUCR0247    W13       0.975501     0.663592       0.406807   \n",
       "12  CICIMAUCR0232  A1÷A3       0.729411     0.880972       0.746008   \n",
       "13  CICIMAUCR0248  B4÷B2       0.542044     0.654028       0.602293   \n",
       "14  CICIMAUCR0248  B4÷B3       0.512999     0.624126       0.568588   \n",
       "15  CICIMAUCR0215  D2÷D1       0.375515     0.534747       0.395560   \n",
       "16  CICIMAUCR0215  D3÷D1       1.150419     1.748780       1.162962   \n",
       "17  CICIMAUCR0247  E1÷E2       0.975501     0.663592       0.406807   \n",
       "\n",
       "    upper_whisker  \n",
       "0     4739.420000  \n",
       "1      162.780000  \n",
       "2      882.875000  \n",
       "3     2881.936250  \n",
       "4     2881.936250  \n",
       "5     2346.715000  \n",
       "6        1.000297  \n",
       "7        0.586846  \n",
       "8        0.707183  \n",
       "9        0.674038  \n",
       "10       0.676174  \n",
       "11       0.882059  \n",
       "12       1.000297  \n",
       "13       0.707183  \n",
       "14       0.671957  \n",
       "15       0.676174  \n",
       "16       2.400468  \n",
       "17       0.882059  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_outliers(df):\n",
    "    \"\"\"\n",
    "    Scans the DataFrame for outliers in all numeric columns (excluding the 'code' column).\n",
    "    Returns a DataFrame with rows that have outliers, including:\n",
    "      - the value of the 'code' column,\n",
    "      - the column name where the outlier occurred,\n",
    "      - the outlier value,\n",
    "      - the median, lower whisker, and upper whisker for that column.\n",
    "    \"\"\"\n",
    "    outlier_records = []\n",
    "    \n",
    "    # Identify numeric columns.\n",
    "    # Exclude the 'code' column (assuming it is not to be analyzed as numeric data).\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    if 'code' in numeric_cols:\n",
    "        numeric_cols.remove('code')\n",
    "    \n",
    "    # Process each numeric column\n",
    "    for col in numeric_cols:\n",
    "        # Compute statistics for the column.\n",
    "        median = df[col].median()\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_whisker = Q1 - 1.5 * IQR\n",
    "        upper_whisker = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Identify outlier rows for this column.\n",
    "        # You can do this with a vectorized boolean condition:\n",
    "        is_outlier = (df[col] < lower_whisker) | (df[col] > upper_whisker)\n",
    "        \n",
    "        # For every row that is an outlier, record the required details.\n",
    "        for idx, row in df[is_outlier].iterrows():\n",
    "            outlier_records.append({\n",
    "                'code': row['code'],       # the value from the \"code\" column\n",
    "                'column': col,             # the column where the outlier was found\n",
    "                'outlier_value': row[col],\n",
    "                'median': median,\n",
    "                'lower_whisker': lower_whisker,\n",
    "                'upper_whisker': upper_whisker\n",
    "            })\n",
    "    \n",
    "    # Convert the list of records into a DataFrame to return.\n",
    "    return pd.DataFrame(outlier_records)\n",
    "\n",
    "detect_outliers(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65dd462c-a54a-4502-8529-9f164da1cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esteb\\AppData\\Local\\Temp\\ipykernel_20712\\2835075765.py:46: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'M' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  result_df.loc[result_df[\"code\"] == code, column] = new_columns_df.loc[new_columns_df[\"code\"] == code, column].values[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_df=             code       A1       A2       A3       A4       A5       B1  \\\n",
      "0   CICIMAUCR0001  4120.58  3511.41  4674.61  1430.02  1958.09  5525.11   \n",
      "1   CICIMAUCR0002  4117.20  3529.93  4475.22  1462.50  1922.14  5352.33   \n",
      "2   CICIMAUCR0003  3971.18  3584.00  4563.49  1402.85  1924.31  5360.70   \n",
      "3   CICIMAUCR0004  3627.85  3538.61  4585.22  1475.45  2028.42  5328.44   \n",
      "4   CICIMAUCR0006      NaN      NaN      NaN      NaN      NaN  5326.82   \n",
      "5   CICIMAUCR0008      NaN      NaN      NaN      NaN      NaN  5471.34   \n",
      "6   CICIMAUCR0009      NaN      NaN      NaN      NaN      NaN  5989.42   \n",
      "7   CICIMAUCR0097  4006.44  3685.78  4546.28  2076.73  1707.97  5380.23   \n",
      "8   CICIMAUCR0105  4172.69  3806.58  4804.80  2101.69  1587.15  5606.02   \n",
      "9   CICIMAUCR0113      NaN      NaN      NaN      NaN      NaN  5623.08   \n",
      "10  CICIMAUCR0116      NaN      NaN      NaN      NaN      NaN  5434.79   \n",
      "11  CICIMAUCR0201  4292.35  3605.92  4569.68  2042.05  1535.29  5393.30   \n",
      "12  CICIMAUCR0204  3625.37  3523.25  4620.29  1966.12  1403.96  5294.75   \n",
      "13  CICIMAUCR0205  4282.46  3617.05  4300.61  2044.37  1617.04  5105.09   \n",
      "14  CICIMAUCR0209  3977.82  3630.55  4510.62  2088.38  1696.30  5515.18   \n",
      "15  CICIMAUCR0210  3908.96  3849.10  4976.72  2090.46  1635.22  5832.83   \n",
      "16  CICIMAUCR0212  4437.51  3793.03  4865.54  2032.75  1517.12  5707.65   \n",
      "17  CICIMAUCR0213  4296.25  3668.76  4705.02  2029.81  1495.22  5631.26   \n",
      "18  CICIMAUCR0214  4155.36  3626.48  4591.87  1952.57  1549.09  5360.05   \n",
      "19  CICIMAUCR0215  3932.54  3454.26  4506.32  2039.24  1509.00  5225.79   \n",
      "20  CICIMAUCR0223  4088.09  3757.84  4858.87  2097.78  1508.74  5865.71   \n",
      "21  CICIMAUCR0225  4275.07  3536.45  4624.23  1982.69  1475.26  5287.93   \n",
      "22  CICIMAUCR0232  3492.88  3654.27  4788.63  1856.41  1392.69  5566.18   \n",
      "23  CICIMAUCR0233  4363.86  3850.47  4953.46  2229.41  1653.33  5961.04   \n",
      "24  CICIMAUCR0234  4522.92  3685.04  4728.88  1986.53  1531.20  5448.04   \n",
      "25  CICIMAUCR0235  4237.33  3729.27  4858.17  1958.46  1444.04  5765.59   \n",
      "26  CICIMAUCR0236  3989.87  3506.93  4509.08  1524.21  2037.03  5378.16   \n",
      "27  CICIMAUCR0239  3993.01  3451.58  4412.92  1921.19  1460.53  5058.62   \n",
      "28  CICIMAUCR0240  3924.10  3674.20  4628.10  1520.68  1960.05  5572.03   \n",
      "29  CICIMAUCR0242  4059.67  3464.70  4548.93  1885.55  1476.65  5238.18   \n",
      "30  CICIMAUCR0245  4045.97  3735.48  4851.80  2094.74  1561.72  5714.28   \n",
      "31  CICIMAUCR0247  3862.44  3499.71  4597.01  1379.67  1750.32  5231.88   \n",
      "32  CICIMAUCR0248  4207.99  4090.03  5058.53  1651.85  2194.49  5896.09   \n",
      "33  CICIMAUCR0250  4310.11  3871.48  4836.41  1663.11  2091.39  5582.49   \n",
      "34  CICIMAUCR0251  4477.21  4020.76  4969.25  1830.78  2363.89  6054.12   \n",
      "35  CICIMAUCR0252  4134.28  4009.18  4895.32  1702.28  2261.59  5734.82   \n",
      "36  CICIMAUCR0253  4117.55  3584.51  4739.36  1484.83  2006.04  5639.24   \n",
      "37  CICIMAUCR0254  4000.29  4037.84  4972.28  1599.46  2077.79  5779.71   \n",
      "38  CICIMAUCR0257  4505.37  3814.10  4786.94  1632.58  2174.00  5926.81   \n",
      "39  CICIMAUCR0258  3836.37  3599.31  4731.99  1470.47  1883.11  5641.74   \n",
      "40  CICIMAUCR0260  4088.12  3946.79  4836.32  1740.60  2302.60  5760.88   \n",
      "41  CICIMAUCR0261  4594.63  3852.22  4876.94  1604.03  2158.63  5660.63   \n",
      "\n",
      "         B2       B3       B4  ...     B4÷B1     B4÷B2     B4÷B3     D2÷D1  \\\n",
      "0   7967.86  8652.41  5101.49  ...  0.923328  0.640258  0.589603  0.652524   \n",
      "1   8099.20  8615.37  5225.63  ...  0.976328  0.645203  0.606547  0.548089   \n",
      "2   8185.66  8495.90  5436.72  ...  1.014181  0.664176  0.639923  0.624912   \n",
      "3   8139.54  8178.22  5299.74  ...  0.994614  0.651111  0.648031  0.499221   \n",
      "4   7841.55  8184.22  5172.77  ...  0.971080  0.659662  0.632042  0.574212   \n",
      "5   8279.86  8642.64  5445.43  ...  0.995264  0.657672  0.630066  0.657315   \n",
      "6   8721.56  9409.23  5938.63  ...  0.991520  0.680914  0.631149  0.566016   \n",
      "7   8422.95  8922.97  5502.10  ...  1.022651  0.653227  0.616622  0.530823   \n",
      "8   8648.11  9122.30  5654.68  ...  1.008680  0.653863  0.619874  0.517631   \n",
      "9   8291.05  9072.48  5807.61  ...  1.032817  0.700467  0.640135  0.487839   \n",
      "10  8023.60  8608.36  5457.58  ...  1.004193  0.680191  0.633986  0.534173   \n",
      "11  7735.71  8334.01  4970.78  ...  0.921658  0.642576  0.596445  0.468899   \n",
      "12  7291.75  7843.09  4606.50  ...  0.870013  0.631741  0.587332  0.447006   \n",
      "13  7426.82  7709.84  4575.51  ...  0.896264  0.616079  0.593464  0.531453   \n",
      "14  8013.08  8641.03  5125.18  ...  0.929286  0.639602  0.593121  0.519059   \n",
      "15  9158.45  9559.65  5864.23  ...  1.005383  0.640308  0.613436  0.605104   \n",
      "16  8711.56  9021.34  5774.05  ...  1.011634  0.662803  0.640043  0.471159   \n",
      "17  8436.10  8695.46  5468.85  ...  0.971159  0.648268  0.628932  0.535321   \n",
      "18  7748.28  8312.47  4969.85  ...  0.927202  0.641413  0.597879  0.557167   \n",
      "19  7510.98  7996.26  4824.06  ...  0.923125  0.642268  0.603290  0.375515   \n",
      "20  8650.40  9249.71  5807.39  ...  0.990057  0.671344  0.627846  0.572586   \n",
      "21  7857.52  7956.65  4937.28  ...  0.933689  0.628351  0.620522  0.565181   \n",
      "22  8546.45  8616.36  5517.99  ...  0.991342  0.645647  0.640408  0.544388   \n",
      "23  8936.57  9479.12  6014.86  ...  1.009029  0.673061  0.634538  0.554073   \n",
      "24  8252.06  8421.82  5323.80  ...  0.977195  0.645148  0.632144  0.651225   \n",
      "25  8652.47  8898.34  5537.96  ...  0.960519  0.640044  0.622359  0.507312   \n",
      "26  8063.84  8445.92  5275.30  ...  0.980874  0.654192  0.624597  0.663984   \n",
      "27  7130.95  7786.21  4749.16  ...  0.938825  0.665993  0.609945  0.573699   \n",
      "28  8504.85  8645.80  5370.97  ...  0.963916  0.631518  0.621223  0.498266   \n",
      "29  7222.69  7782.68  4678.65  ...  0.893182  0.647771  0.601162  0.513325   \n",
      "30  8678.80  8890.30  5692.37  ...  0.996166  0.655894  0.640290  0.505499   \n",
      "31  7912.14  8363.66  5284.65  ...  1.010086  0.667917  0.631859  0.518322   \n",
      "32  8986.76  9495.57  4871.22  ...  0.826178  0.542044  0.512999  0.497005   \n",
      "33  8371.27  8923.75  5567.72  ...  0.997354  0.665099  0.623922  0.564420   \n",
      "34  8994.20  9478.35  6004.95  ...  0.991878  0.667647  0.633544  0.594204   \n",
      "35  8794.98  9392.86  6012.14  ...  1.048357  0.683588  0.640076  0.455127   \n",
      "36  8186.13  8953.10  5483.97  ...  0.972466  0.669910  0.612522  0.483385   \n",
      "37  8880.82  9416.34  5878.90  ...  1.017162  0.661977  0.624330  0.586536   \n",
      "38  8621.43  9022.05  5455.91  ...  0.920547  0.632831  0.604731  0.479003   \n",
      "39  8537.50  8996.30  5764.17  ...  1.021701  0.675159  0.640727  0.560598   \n",
      "40  8812.01  9670.86  5896.94  ...  1.023618  0.669194  0.609764  0.552420   \n",
      "41  8364.53  9052.15  5668.04  ...  1.001309  0.677628  0.626154  0.512053   \n",
      "\n",
      "       D3÷D1     D4÷D2     E1÷E2          species  location_code  sex_code  \n",
      "0   1.893143  0.925360  0.812048         kalinini             AM       NaN  \n",
      "1   2.000158  1.041976  0.597514         kalinini             AM         M  \n",
      "2   1.995213  1.162874  0.488846         kalinini             AM         M  \n",
      "3   1.642313  0.957518  0.577308         kalinini             AM         M  \n",
      "4   2.075859  0.969237  0.693946         kalinini             AM       NaN  \n",
      "5   2.043285  1.007729  0.675432         kalinini             AM       NaN  \n",
      "6   1.789978  1.282293  0.566546         kalinini             AM       NaN  \n",
      "7   1.950781  1.083536  0.573013         kalinini             AM       NaN  \n",
      "8   1.687759  1.081919  0.646249         kalinini             AM       NaN  \n",
      "9   1.791455  1.054259  0.601480         kalinini            NaN       NaN  \n",
      "10  1.621689  1.120277  0.502280         kalinini             AM         M  \n",
      "11  1.302838  1.122743  0.673038  cupreomarginata             MV         F  \n",
      "12  1.396962  1.059182  0.663536  cupreomarginata             MV         M  \n",
      "13  1.480479  1.207741  0.667518  cupreomarginata             MV         F  \n",
      "14  1.448817  1.092063  0.541874  cupreomarginata             MV         F  \n",
      "15  1.830754  1.166656  0.624935      resplendens             MV         F  \n",
      "16  1.608583  1.503363  0.580864      resplendens             MV         F  \n",
      "17  1.888897  1.518341  0.663648      resplendens             MV         M  \n",
      "18  1.656289  1.245736  0.670607  cupreomarginata             MV         M  \n",
      "19  1.150419  1.273005  0.679975  cupreomarginata             MV         M  \n",
      "20  2.126733  1.410422  0.517243      resplendens             MV         M  \n",
      "21  1.726640  1.144252  0.600241      resplendens             MV         F  \n",
      "22  1.733387  1.141660  0.607118      resplendens             MV         M  \n",
      "23  1.527043  1.114116  0.836128      resplendens             MV         F  \n",
      "24  1.872762  1.468502  0.616060      resplendens             MV         M  \n",
      "25  1.974255  1.077609  0.489270      resplendens             MV         M  \n",
      "26  2.041221  0.835042  0.751497      resplendens             MV         M  \n",
      "27  1.621931  1.332099  0.558059  cupreomarginata             MV         M  \n",
      "28  1.669918  1.135701  0.791135      resplendens             MV         M  \n",
      "29  1.420618  1.294220  0.637857  cupreomarginata             MV         M  \n",
      "30  1.647961  1.158794  0.562600      resplendens             MV         M  \n",
      "31  2.060819  1.332079  0.975501      resplendens             MV         M  \n",
      "32  1.586013  0.873179  0.800595      resplendens             MV         F  \n",
      "33  1.939472  1.329477  0.668255      resplendens             MV         M  \n",
      "34  1.798970  0.932866  0.706880      resplendens             MV         F  \n",
      "35  1.659664  1.189713  0.642668      resplendens             MV         F  \n",
      "36  1.834377  1.493650  0.692178      resplendens             MV         M  \n",
      "37  1.764174  1.275311  0.762472      resplendens             MV         F  \n",
      "38  1.680003  1.313492  0.707687      resplendens             MV         F  \n",
      "39  1.927198  1.227851  0.694719      resplendens             MV         M  \n",
      "40  1.671473  1.189847  0.785322      resplendens             MV         F  \n",
      "41  2.002257  1.384470  0.764963      resplendens             MV         M  \n",
      "\n",
      "[42 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# add species data\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory containing datapath_selector.py to the system path\n",
    "library_path = r\"C:\\Users\\esteb\\escarabajos\\libraries\"\n",
    "sys.path.append(library_path)\n",
    "\n",
    "# Now you can import datapath_selector.py as a module\n",
    "import datapath_selector\n",
    "import spectraltools\n",
    "from datapath_selector import get_paths\n",
    "from collection_tools import *\n",
    "from datetime import datetime\n",
    "collections_list = get_collections_list()\n",
    "collections_dict = get_collections_dict()\n",
    "\n",
    "# Define a function to apply species_lookup to each code\n",
    "def get_species_for_code(code):\n",
    "    # Use the species_lookup method from the relevant collection in collections_dict\n",
    "    return collections_dict[\"CICIMAUCR1\"].species_lookup(code=code, collection_list=collections_list)\n",
    "\n",
    "\n",
    "# Apply the function to the 'code' column of your DataFrame\n",
    "#convert codes into list\n",
    "code_list = measurement_df_2[\"code\"].tolist()\n",
    "result_df = pd.DataFrame([])\n",
    "result_df = pd.concat([measurement_df_2, result_df], axis=1)\n",
    "\n",
    "#print(f\"{result_df=}\")\n",
    "\n",
    "for code in code_list:\n",
    "    info_df = get_specimen_info(code)  # Fetch information for the given code\n",
    "    columns_of_interest = [\"code\", \"species\", \"location_code\", \"sex_code\"]\n",
    "    new_columns_df = info_df[columns_of_interest]\n",
    "\n",
    "    # Merge the new columns into result_df by \"code\"\n",
    "    if result_df.empty:\n",
    "        # If result_df is empty, initialize it with the first new_columns_df\n",
    "        result_df = new_columns_df\n",
    "    else:\n",
    "        # Update or add information for the specific \"code\"\n",
    "        for column in columns_of_interest:\n",
    "            if column != \"code\":  # Avoid trying to overwrite the \"code\" column itself\n",
    "                result_df.loc[result_df[\"code\"] == code, column] = new_columns_df.loc[new_columns_df[\"code\"] == code, column].values[0]\n",
    "\n",
    "    \n",
    "#measurement_df_2[\"species\"] = measurement_df_2[\"code\"].apply(get_species_for_code)\n",
    "print(f\"{result_df=}\")\n",
    "\n",
    "#define information_df\n",
    "information_df = result_df\n",
    "\n",
    "# First, group the entire dataframe by 'species', and then calculate the mean of 'A1'\n",
    "metrics_under_consideration = absolute_metrics + relative_metrics\n",
    "    \n",
    "aggregated_mean = result_df.groupby(\"species\")[metrics_under_consideration].mean()\n",
    "aggregated_std = result_df.groupby(\"species\")[metrics_under_consideration].std()\n",
    "\n",
    "#aggregated_mean.columns = aggregated_mean.columns.str.replace('_', '-')\n",
    "#aggregated_std.columns = aggregated_std.columns.str.replace('_', '-')\n",
    "# Optionally, if you want to see the result:\n",
    "#print(aggregated_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fefbcb-e23c-4b31-bbcc-12a550e1dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Image, Spacer, Paragraph\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors\n",
    "### Third test: Plots on demand\n",
    "#!pip install reportlab\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655fb02f-5c80-4d4c-90cc-28017fcda199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1÷A3',\n",
       " 'A4÷A3',\n",
       " 'A5÷A3',\n",
       " 'B4÷B1',\n",
       " 'B4÷B2',\n",
       " 'B4÷B3',\n",
       " 'D2÷D1',\n",
       " 'D3÷D1',\n",
       " 'D4÷D2',\n",
       " 'E1÷E2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddc186c-8634-4fbd-a73e-43ce7d63a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeveneResult(statistic=np.float64(1.1873103588011569), pvalue=np.float64(0.2855027597681593))\n",
      "LeveneResult(statistic=np.float64(1.8463607374171744), pvalue=np.float64(0.18545128487010076))\n",
      "LeveneResult(statistic=np.float64(0.4593400301024974), pvalue=np.float64(0.5036995462867428))\n",
      "LeveneResult(statistic=np.float64(0.6912440431025132), pvalue=np.float64(0.4119027326960786))\n",
      "LeveneResult(statistic=np.float64(0.48183421153751266), pvalue=np.float64(0.4926015862846532))\n",
      "LeveneResult(statistic=np.float64(0.8836542591104996), pvalue=np.float64(0.354244960311101))\n",
      "LeveneResult(statistic=np.float64(0.05293752148541057), pvalue=np.float64(0.8194928965363276))\n",
      "LeveneResult(statistic=np.float64(0.06502109723266758), pvalue=np.float64(0.8003607435549867))\n",
      "LeveneResult(statistic=np.float64(1.535578378382783), pvalue=np.float64(0.22428930789353785))\n",
      "LeveneResult(statistic=np.float64(0.03728661028032174), pvalue=np.float64(0.8481030704447662))\n",
      "LeveneResult(statistic=np.float64(2.5025154095680486), pvalue=np.float64(0.12349950470529253))\n",
      "LeveneResult(statistic=np.float64(2.139521126376273), pvalue=np.float64(0.15329987936789333))\n",
      "LeveneResult(statistic=np.float64(7.025255346835403), pvalue=np.float64(0.012541908788938865))\n",
      "LeveneResult(statistic=np.float64(1.0554896774980815), pvalue=np.float64(0.31219617730869326))\n",
      "LeveneResult(statistic=np.float64(0.003029034670350557), pvalue=np.float64(0.9564624337961941))\n",
      "LeveneResult(statistic=np.float64(2.7396986165905357), pvalue=np.float64(0.10797395284177184))\n",
      "LeveneResult(statistic=np.float64(0.0005990199233981152), pvalue=np.float64(0.9806306890234643))\n",
      "LeveneResult(statistic=np.float64(1.502602199600253), pvalue=np.float64(0.2308562223247189))\n",
      "LeveneResult(statistic=np.float64(0.029658383020728377), pvalue=np.float64(0.8643522131660986))\n",
      "LeveneResult(statistic=np.float64(0.0008150127292543203), pvalue=np.float64(0.9774020495986707))\n",
      "LeveneResult(statistic=np.float64(3.847654678914068), pvalue=np.float64(0.058564843334476466))\n",
      "LeveneResult(statistic=np.float64(0.785855614193378), pvalue=np.float64(0.3819702106793096))\n",
      "Dictionary saved to metric_description.json\n",
      "Dictionary loaded from metric_description.json\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'measurement_df_2' is your dataframe\n",
    "# Split the data by species\n",
    "measurement_df_2 = result_df\n",
    "kalinini_data = measurement_df_2[measurement_df_2[\"species\"] == \"kalinini\"]\n",
    "resplendens_data = measurement_df_2[measurement_df_2[\"species\"] == \"resplendens\"]\n",
    "\n",
    "# List of metrics to test (assuming your dataframe contains these columns)\n",
    "metrics = metrics_under_consideration\n",
    "\n",
    "# Dictionary to store test results\n",
    "global t_test_results\n",
    "t_test_results = {}\n",
    "\n",
    "#Normality\n",
    "normality_info_dict = {\n",
    "}\n",
    "\n",
    "#statistical info dict\n",
    "statistical_info_dict = {\n",
    "}\n",
    "for metric in metrics:\n",
    "    # Extract the data for each species' metric\n",
    "    kalinini_values = kalinini_data[metric].dropna()  # Remove missing values\n",
    "    resplendens_values = resplendens_data[metric].dropna()  # Remove missing values\n",
    "    \n",
    "    # Check normality (Shapiro-Wilk test) for both species\n",
    "    kalinini_shapiro = stats.shapiro(kalinini_values)\n",
    "    resplendens_shapiro = stats.shapiro(resplendens_values)\n",
    "\n",
    "    #get statistic and p value\n",
    "    SW_statistic_kalinini = kalinini_shapiro[0]\n",
    "    SW_statistic_resplendens = resplendens_shapiro[0]\n",
    "\n",
    "    SW_pval_kalinini = kalinini_shapiro[1]\n",
    "    SW_pval_resplendens = resplendens_shapiro[1]\n",
    "    \n",
    "    kalinini_normal = SW_pval_kalinini > 0.05  # p-value > 0.05 => normal\n",
    "    resplendens_normal = SW_pval_resplendens > 0.05  # p-value > 0.05 => normal\n",
    "\n",
    "    #save info for report\n",
    "    N_kalinini = kalinini_values.count()\n",
    "    N_resplendens = resplendens_values.count()\n",
    "\n",
    "    normality_info_dict[(metric, \"N_kalinini\")] = N_kalinini\n",
    "    normality_info_dict[(metric, \"N_resplendens\")] = N_resplendens\n",
    "    \n",
    "    normality_info_dict[(metric, \"kalinini\")] = kalinini_normal\n",
    "    normality_info_dict[(metric, \"resplendens\")] = resplendens_normal\n",
    "\n",
    "    statistical_info_dict[(metric, \"SW_kalinini\")] = SW_statistic_kalinini\n",
    "    statistical_info_dict[(metric, \"SW_resplendens\")] = SW_statistic_resplendens\n",
    "    statistical_info_dict[(metric, \"SW_pvalue_kalinini\")] = SW_pval_kalinini\n",
    "    statistical_info_dict[(metric, \"SW_pvalue_resplendens\")] = SW_pval_resplendens\n",
    "    \n",
    "    if kalinini_normal and resplendens_normal:\n",
    "        # Perform Levene's test for homogeneity of variance\n",
    "        levene_test = stats.levene(kalinini_values, resplendens_values)\n",
    "        levene_statistic = levene_test.statistic\n",
    "        levene_pvalue = levene_test.pvalue\n",
    "        \n",
    "        print(levene_test)\n",
    "        #save results\n",
    "        statistical_info_dict[(metric, \"levene_statistic\")] = levene_statistic\n",
    "        statistical_info_dict[(metric, \"levene_pvalue\")]  = levene_pvalue\n",
    "        \n",
    "        # Perform Student's t-test if variances are equal (Levene's test p > 0.05)\n",
    "        if levene_test.pvalue > 0.05:\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values)\n",
    "            test_type = \"Student's t-test\"\n",
    "\n",
    "            #save info\n",
    "            statistical_info_dict[(metric, \"test_type\")]  = test_type\n",
    "            statistical_info_dict[(metric, \"student_t_stat\")]  = t_stat\n",
    "            statistical_info_dict[(metric, \"student_t_pvalue\")]  = p_value\n",
    "            \n",
    "        else:\n",
    "            # If variances are unequal, use Welch's t-test (Welch correction)\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values, equal_var=False)\n",
    "            test_type = \"Welch's t-test\"\n",
    "            \n",
    "            #save info\n",
    "            statistical_info_dict[(metric, \"test_type\")]  = test_type\n",
    "            statistical_info_dict[(metric, \"welch_t_stat\")]  = t_stat\n",
    "            statistical_info_dict[(metric, \"welch_t_pvalue\")]  = p_value\n",
    "        # Interpretation\n",
    "        interpretation = \"significant difference\" if p_value < 0.05 else \"no significant difference\"\n",
    "        \n",
    "        t_test_results[metric] = {\n",
    "            \"levene_test\": levene_test.pvalue,\n",
    "            \"test_type\": test_type,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"interpretation\": interpretation\n",
    "        }\n",
    "\n",
    "        statistical_info_dict[(metric, \"interpretation\")]  = interpretation\n",
    "    else:\n",
    "        # If normality fails, use the Mann-Whitney U test\n",
    "        u_stat, p_value = stats.mannwhitneyu(kalinini_values, resplendens_values)\n",
    "        test_type = \"Mann-Whitney U test\"\n",
    "        \n",
    "        # Interpretation\n",
    "        interpretation = \"significant difference\" if p_value < 0.05 else \"no significant difference\"\n",
    "        \n",
    "        t_test_results[metric] = {\n",
    "            \"levene_test\": levene_test.pvalue,\n",
    "            \"test_type\": test_type,\n",
    "            \"u_stat\": u_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"interpretation\": interpretation\n",
    "        } \n",
    "\n",
    "        #save info\n",
    "        statistical_info_dict[(metric, \"test_type\")]  = test_type\n",
    "        statistical_info_dict[(metric, \"Mann_Whitney_u_stat\")]  = u_stat\n",
    "        statistical_info_dict[(metric, \"Mann_Whitney_pvalue\")]  = p_value\n",
    "        statistical_info_dict[(metric, \"interpretation\")]  = interpretation\n",
    "\n",
    "# Print results\n",
    "global metric_description\n",
    "metric_description = { \"A1\": \"Vertical length of the head: measured from the center of the clipeus down to the middle of the back of the head.\",\n",
    "                      \"A2\": \"Horizontal length between the left and right sutures\",\n",
    "                      \"A3\": \"Horizontal length between the left and right eye’s canthus\",\n",
    "                      \"A4\": \"Vertical ortogonal length of the clipeus measured from the front down to A2 line\",\n",
    "                      \"A5\": \"Perpendicular vertical length of the clypeus, measured from its front edge to the $A2$ line, representing the clypeus height.\",\n",
    "                      \"B1\": \"Horizontal length between the pronotum’s frontal angles\",\n",
    "                      \"B2\": \"Horizontal length between the pronotum’s middle angles\",\n",
    "                      \"B3\": \"Horizontal length between the pronotum’s hind angles\",\n",
    "                      \"B4\": \"Vertical length of the pronotum’s measured from the middle point of its front down to the middlepoint of its rear\",\n",
    "                      \"B5\": \"Angle of its side measured between the tangent lines to its straightest sections in the front and back, as seen from the top \",\n",
    "                      \"C1\": \"Angle of its side measured between the tangent lines to its straightest sections in the front and back as seen by the side\",\n",
    "                      \"D1\": \"Mesosternal process’ horizontal length measured from the secant point of the tangents of its sides with the horizontal line used to measure D1. \",\n",
    "                      \"D2\": \"Mesosternal process’ vertical length measured from the tip of the mesosternal process down to the line that joins the two lowest curves at the sides of the mesosternal process base\",\n",
    "                      \"D3\": \"Horizontal width of the dark middle line measured from its two lower ends\",\n",
    "                      \"D4\": \"Vertical length from the tip of the mesosternal process down to the lowest point of the black patch in the middle of the mesosternal process\",\n",
    "                      \"E1\": \"Horizontal top width of the prosternal plate \",\n",
    "                      \"E2\": \"Horizontal bottom width of the prosternal plate \",\n",
    "                      \"F1\": \"Vertical length of the foremost ventral plate\",\n",
    "                      \"F2\": \"Vertical length of the second foremost ventral plate\",\n",
    "                      \"F3\": \"Vertical length of the third foremost ventral plate\",\n",
    "                      \"F4\": \"Vertical length of the fourth foremost ventral plate \",\n",
    "                      \"F5\": \"Vertical length of the fifth foremost ventral plate\",\n",
    "                      \"A1÷A3\": \"A1/A3 Measure of the vertical length of beetle's head relative to its canthuses' distance width\",\n",
    "                      \"A4÷A3\": \"A4/A3 Measure of the vertical length of beetle's clipeum relative to its canthuses' distance width\",\n",
    "                      \"A5÷A3\": \"A5/A3 Measure of the vertical length of beetle's eyes relative to its canthuses' distance width\",\n",
    "                      \"B4÷B1\": \"Measure of the vertical length of the pronotum relative to its front width. B4/B1\",\n",
    "                      \"B4÷B2\": \"Measure of the vertical length of the pronotum relative to its middle width. B4/B2\",\n",
    "                      \"B4÷B3\": \"Measure of the vertical length of the pronotum relative to its back width. B4/B3\",\n",
    "                      \"D3÷D1\": \"Measure of the total vertical length of the mesosternal process relative to its back horizontal width. D3/D1\",\n",
    "                      \"D2÷D1\": \"Measure of the middle horizontal length of the mesosternal process relative to its back horizontal width. D2/D1\",\n",
    "                      \"D4÷D2\": \"Measure of the vertical length of the mesosternal process down to the middle dark stripe  relative to its middle width. D4/D2\",\n",
    "                      \"E1÷E2\": \"Measure of how square the prosternal plate is. Front width back width ratio E1/E2\",\n",
    "                     }\n",
    "\n",
    "Analysis_text = \"\"\n",
    "\n",
    "# Define the path for the JSON file\n",
    "metric_description_file = Path(\"metric_description.json\")\n",
    "\n",
    "# Save the metric_image dictionary\n",
    "save_dictionary_to_json(metric_image, metric_description_file)\n",
    "\n",
    "# Later, load the dictionary from the file\n",
    "metric_image_loaded = load_json_to_dictionary(metric_description_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e674103a-0bac-449e-ba0a-c7152bc3607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(('A1', 'SW_kalinini'), np.float64(0.8186901827269933)), (('A1', 'SW_resplendens'), np.float64(0.9717395005500788)), (('A1', 'SW_pvalue_kalinini'), np.float64(0.08597610747193121)), (('A1', 'SW_pvalue_resplendens'), np.float64(0.7305562800193002)), (('A1', 'levene_statistic'), np.float64(1.1873103588011569)), (('A1', 'levene_pvalue'), np.float64(0.2855027597681593)), (('A1', 'test_type'), \"Student's t-test\"), (('A1', 'student_t_stat'), np.float64(-1.3595850141076393)), (('A1', 'student_t_pvalue'), np.float64(0.18520827480214286)), (('A1', 'interpretation'), 'no significant difference'), (('A2', 'SW_kalinini'), np.float64(0.8512213169996418)), (('A2', 'SW_resplendens'), np.float64(0.9646542197574192)), (('A2', 'SW_pvalue_kalinini'), np.float64(0.1610204679797393)), (('A2', 'SW_pvalue_resplendens'), np.float64(0.5633950790160998)), (('A2', 'levene_statistic'), np.float64(1.8463607374171744)), (('A2', 'levene_pvalue'), np.float64(0.18545128487010076)), (('A2', 'test_type'), \"Student's t-test\"), (('A2', 'student_t_stat'), np.float64(-2.1675791717997996)), (('A2', 'student_t_pvalue'), np.float64(0.0391763446236319)), (('A2', 'interpretation'), 'significant difference'), (('A3', 'SW_kalinini'), np.float64(0.9302510344766762)), (('A3', 'SW_resplendens'), np.float64(0.9719873123841557)), (('A3', 'SW_pvalue_kalinini'), np.float64(0.582041894268723)), (('A3', 'SW_pvalue_resplendens'), np.float64(0.7364391932088217)), (('A3', 'levene_statistic'), np.float64(0.4593400301024974)), (('A3', 'levene_pvalue'), np.float64(0.5036995462867428)), (('A3', 'test_type'), \"Student's t-test\"), (('A3', 'student_t_stat'), np.float64(-3.2973984023667313)), (('A3', 'student_t_pvalue'), np.float64(0.0027386597737501057)), (('A3', 'interpretation'), 'significant difference'), (('A4', 'SW_kalinini'), np.float64(0.7122557553980697)), (('A4', 'SW_resplendens'), np.float64(0.943176952478876)), (('A4', 'SW_pvalue_kalinini'), np.float64(0.00830105966984504)), (('A4', 'SW_pvalue_resplendens'), np.float64(0.21017062508002876)), (('A4', 'test_type'), 'Mann-Whitney U test'), (('A4', 'Mann_Whitney_u_stat'), np.float64(46.0)), (('A4', 'Mann_Whitney_pvalue'), np.float64(0.23249968422382217)), (('A4', 'interpretation'), 'no significant difference'), (('A5', 'SW_kalinini'), np.float64(0.8746748486565395)), (('A5', 'SW_resplendens'), np.float64(0.9054340963791365)), (('A5', 'SW_pvalue_kalinini'), np.float64(0.2454835740610662)), (('A5', 'SW_pvalue_resplendens'), np.float64(0.03276809918375632)), (('A5', 'test_type'), 'Mann-Whitney U test'), (('A5', 'Mann_Whitney_u_stat'), np.float64(68.0)), (('A5', 'Mann_Whitney_pvalue'), np.float64(0.9791040377247273)), (('A5', 'interpretation'), 'no significant difference'), (('B1', 'SW_kalinini'), np.float64(0.8015585126997915)), (('B1', 'SW_resplendens'), np.float64(0.9732896984729205)), (('B1', 'SW_pvalue_kalinini'), np.float64(0.009862160569517426)), (('B1', 'SW_pvalue_resplendens'), np.float64(0.7670650617246324)), (('B1', 'test_type'), 'Mann-Whitney U test'), (('B1', 'Mann_Whitney_u_stat'), np.float64(58.0)), (('B1', 'Mann_Whitney_pvalue'), np.float64(0.012305652438495884)), (('B1', 'interpretation'), 'significant difference'), (('B2', 'SW_kalinini'), np.float64(0.9557624014113372)), (('B2', 'SW_resplendens'), np.float64(0.9726656409853799)), (('B2', 'SW_pvalue_kalinini'), np.float64(0.717960481960181)), (('B2', 'SW_pvalue_resplendens'), np.float64(0.7524602976605367)), (('B2', 'levene_statistic'), np.float64(0.6912440431025132)), (('B2', 'levene_pvalue'), np.float64(0.4119027326960786)), (('B2', 'test_type'), \"Student's t-test\"), (('B2', 'student_t_stat'), np.float64(-2.709563692015915)), (('B2', 'student_t_pvalue'), np.float64(0.01073346538608283)), (('B2', 'interpretation'), 'significant difference'), (('B3', 'SW_kalinini'), np.float64(0.9464460942950564)), (('B3', 'SW_resplendens'), np.float64(0.9587263998111709)), (('B3', 'SW_pvalue_kalinini'), np.float64(0.5989422089776921)), (('B3', 'SW_pvalue_resplendens'), np.float64(0.43813735546536603)), (('B3', 'levene_statistic'), np.float64(0.48183421153751266)), (('B3', 'levene_pvalue'), np.float64(0.4926015862846532)), (('B3', 'test_type'), \"Student's t-test\"), (('B3', 'student_t_stat'), np.float64(-1.6968141028601103)), (('B3', 'student_t_pvalue'), np.float64(0.09943975558661294)), (('B3', 'interpretation'), 'no significant difference'), (('B4', 'SW_kalinini'), np.float64(0.9542230072799184)), (('B4', 'SW_resplendens'), np.float64(0.9448278450966655)), (('B4', 'SW_pvalue_kalinini'), np.float64(0.6981878782681666)), (('B4', 'SW_pvalue_resplendens'), np.float64(0.22787129622320323)), (('B4', 'levene_statistic'), np.float64(0.8836542591104996)), (('B4', 'levene_pvalue'), np.float64(0.354244960311101)), (('B4', 'test_type'), \"Student's t-test\"), (('B4', 'student_t_stat'), np.float64(-1.1546527936359354)), (('B4', 'student_t_pvalue'), np.float64(0.2567827288841031)), (('B4', 'interpretation'), 'no significant difference'), (('B5', 'SW_kalinini'), np.float64(0.785185829305904)), (('B5', 'SW_resplendens'), np.float64(0.9774046167423567)), (('B5', 'SW_pvalue_kalinini'), np.float64(0.00600654475343284)), (('B5', 'SW_pvalue_resplendens'), np.float64(0.8575600005093111)), (('B5', 'test_type'), 'Mann-Whitney U test'), (('B5', 'Mann_Whitney_u_stat'), np.float64(170.0)), (('B5', 'Mann_Whitney_pvalue'), np.float64(0.1134072906742428)), (('B5', 'interpretation'), 'no significant difference'), (('C1', 'SW_kalinini'), np.float64(0.9308679582916604)), (('C1', 'SW_resplendens'), np.float64(0.9597240512085654)), (('C1', 'SW_pvalue_kalinini'), np.float64(0.41970062489428844)), (('C1', 'SW_pvalue_resplendens'), np.float64(0.45781598349135627)), (('C1', 'levene_statistic'), np.float64(0.05293752148541057)), (('C1', 'levene_pvalue'), np.float64(0.8194928965363276)), (('C1', 'test_type'), \"Student's t-test\"), (('C1', 'student_t_stat'), np.float64(0.8513651340456071)), (('C1', 'student_t_pvalue'), np.float64(0.4008929217414374)), (('C1', 'interpretation'), 'no significant difference'), (('D1', 'SW_kalinini'), np.float64(0.9075834300850827)), (('D1', 'SW_resplendens'), np.float64(0.9757669576029899)), (('D1', 'SW_pvalue_kalinini'), np.float64(0.22827445943692593)), (('D1', 'SW_pvalue_resplendens'), np.float64(0.8230722283817218)), (('D1', 'levene_statistic'), np.float64(0.06502109723266758)), (('D1', 'levene_pvalue'), np.float64(0.8003607435549867)), (('D1', 'test_type'), \"Student's t-test\"), (('D1', 'student_t_stat'), np.float64(-1.4576479532664657)), (('D1', 'student_t_pvalue'), np.float64(0.15468239999205952)), (('D1', 'interpretation'), 'no significant difference'), (('D2', 'SW_kalinini'), np.float64(0.9801503144121737)), (('D2', 'SW_resplendens'), np.float64(0.9703678576869269)), (('D2', 'SW_pvalue_kalinini'), np.float64(0.966992793072662)), (('D2', 'SW_pvalue_resplendens'), np.float64(0.6978131367301723)), (('D2', 'levene_statistic'), np.float64(1.535578378382783)), (('D2', 'levene_pvalue'), np.float64(0.22428930789353785)), (('D2', 'test_type'), \"Student's t-test\"), (('D2', 'student_t_stat'), np.float64(-0.6469121538493855)), (('D2', 'student_t_pvalue'), np.float64(0.5223024561607685)), (('D2', 'interpretation'), 'no significant difference'), (('D3', 'SW_kalinini'), np.float64(0.9452576107360586)), (('D3', 'SW_resplendens'), np.float64(0.9172469594449411)), (('D3', 'SW_pvalue_kalinini'), np.float64(0.5841219445123066)), (('D3', 'SW_pvalue_resplendens'), np.float64(0.05817901010483413)), (('D3', 'levene_statistic'), np.float64(0.03728661028032174)), (('D3', 'levene_pvalue'), np.float64(0.8481030704447662)), (('D3', 'test_type'), \"Student's t-test\"), (('D3', 'student_t_stat'), np.float64(-1.1477093995856362)), (('D3', 'student_t_pvalue'), np.float64(0.25959683204677286)), (('D3', 'interpretation'), 'no significant difference'), (('D4', 'SW_kalinini'), np.float64(0.8851935761728941)), (('D4', 'SW_resplendens'), np.float64(0.9535379791904071)), (('D4', 'SW_pvalue_kalinini'), np.float64(0.12103917910623391)), (('D4', 'SW_pvalue_resplendens'), np.float64(0.3458755302505938)), (('D4', 'levene_statistic'), np.float64(2.5025154095680486)), (('D4', 'levene_pvalue'), np.float64(0.12349950470529253)), (('D4', 'test_type'), \"Student's t-test\"), (('D4', 'student_t_stat'), np.float64(-2.5524028916335)), (('D4', 'student_t_pvalue'), np.float64(0.015672129070715562)), (('D4', 'interpretation'), 'significant difference'), (('E1', 'SW_kalinini'), np.float64(0.9288511804200883)), (('E1', 'SW_resplendens'), np.float64(0.9455553590010942)), (('E1', 'SW_pvalue_kalinini'), np.float64(0.3993490193502841)), (('E1', 'SW_pvalue_resplendens'), np.float64(0.23610636011830372)), (('E1', 'levene_statistic'), np.float64(2.139521126376273)), (('E1', 'levene_pvalue'), np.float64(0.15329987936789333)), (('E1', 'test_type'), \"Student's t-test\"), (('E1', 'student_t_stat'), np.float64(-2.453152601048032)), (('E1', 'student_t_pvalue'), np.float64(0.019792715310950695)), (('E1', 'interpretation'), 'significant difference'), (('E2', 'SW_kalinini'), np.float64(0.8256203089519034)), (('E2', 'SW_resplendens'), np.float64(0.9804790225025201)), (('E2', 'SW_pvalue_kalinini'), np.float64(0.020447491855587686)), (('E2', 'SW_pvalue_resplendens'), np.float64(0.9141601968720404)), (('E2', 'test_type'), 'Mann-Whitney U test'), (('E2', 'Mann_Whitney_u_stat'), np.float64(124.0)), (('E2', 'Mann_Whitney_pvalue'), np.float64(0.9413086393059091)), (('E2', 'interpretation'), 'no significant difference'), (('F1', 'SW_kalinini'), np.float64(0.9066291602821244)), (('F1', 'SW_resplendens'), np.float64(0.9666036983729482)), (('F1', 'SW_pvalue_kalinini'), np.float64(0.25862998958040934)), (('F1', 'SW_pvalue_resplendens'), np.float64(0.6083221841930575)), (('F1', 'levene_statistic'), np.float64(7.025255346835403)), (('F1', 'levene_pvalue'), np.float64(0.012541908788938865)), (('F1', 'test_type'), \"Welch's t-test\"), (('F1', 'welch_t_stat'), np.float64(-2.664794660201687)), (('F1', 'welch_t_pvalue'), np.float64(0.01216791501459798)), (('F1', 'interpretation'), 'significant difference'), (('F2', 'SW_kalinini'), np.float64(0.9300537991618564)), (('F2', 'SW_resplendens'), np.float64(0.9799316988473675)), (('F2', 'SW_pvalue_kalinini'), np.float64(0.4484215557694918)), (('F2', 'SW_pvalue_resplendens'), np.float64(0.9050031603321789)), (('F2', 'levene_statistic'), np.float64(1.0554896774980815)), (('F2', 'levene_pvalue'), np.float64(0.31219617730869326)), (('F2', 'test_type'), \"Student's t-test\"), (('F2', 'student_t_stat'), np.float64(-2.330678588423216)), (('F2', 'student_t_pvalue'), np.float64(0.026450308128959394)), (('F2', 'interpretation'), 'significant difference'), (('F3', 'SW_kalinini'), np.float64(0.9610951828226211)), (('F3', 'SW_resplendens'), np.float64(0.9761214646653565)), (('F3', 'SW_pvalue_kalinini'), np.float64(0.7982855970607419)), (('F3', 'SW_pvalue_resplendens'), np.float64(0.8307426512085687)), (('F3', 'levene_statistic'), np.float64(0.003029034670350557)), (('F3', 'levene_pvalue'), np.float64(0.9564624337961941)), (('F3', 'test_type'), \"Student's t-test\"), (('F3', 'student_t_stat'), np.float64(-2.605457969723344)), (('F3', 'student_t_pvalue'), np.float64(0.01397017299261337)), (('F3', 'interpretation'), 'significant difference'), (('F4', 'SW_kalinini'), np.float64(0.9268426398596062)), (('F4', 'SW_resplendens'), np.float64(0.9143240776504272)), (('F4', 'SW_pvalue_kalinini'), np.float64(0.4175641304128594)), (('F4', 'SW_pvalue_resplendens'), np.float64(0.05041645159587204)), (('F4', 'levene_statistic'), np.float64(2.7396986165905357)), (('F4', 'levene_pvalue'), np.float64(0.10797395284177184)), (('F4', 'test_type'), \"Student's t-test\"), (('F4', 'student_t_stat'), np.float64(-2.924510330850044)), (('F4', 'student_t_pvalue'), np.float64(0.0063976578766514365)), (('F4', 'interpretation'), 'significant difference'), (('F5', 'SW_kalinini'), np.float64(0.8907080772235296)), (('F5', 'SW_resplendens'), np.float64(0.946787781081116)), (('F5', 'SW_pvalue_kalinini'), np.float64(0.17271660399530614)), (('F5', 'SW_pvalue_resplendens'), np.float64(0.25068853973680627)), (('F5', 'levene_statistic'), np.float64(0.0005990199233981152)), (('F5', 'levene_pvalue'), np.float64(0.9806306890234643)), (('F5', 'test_type'), \"Student's t-test\"), (('F5', 'student_t_stat'), np.float64(-1.9488761465851416)), (('F5', 'student_t_pvalue'), np.float64(0.06040969835555588)), (('F5', 'interpretation'), 'no significant difference'), (('A1÷A3', 'SW_kalinini'), np.float64(0.8534062535020495)), (('A1÷A3', 'SW_resplendens'), np.float64(0.9735799984402101)), (('A1÷A3', 'SW_pvalue_kalinini'), np.float64(0.16766597247472426)), (('A1÷A3', 'SW_pvalue_resplendens'), np.float64(0.7738051591542754)), (('A1÷A3', 'levene_statistic'), np.float64(1.502602199600253)), (('A1÷A3', 'levene_pvalue'), np.float64(0.2308562223247189)), (('A1÷A3', 'test_type'), \"Student's t-test\"), (('A1÷A3', 'student_t_stat'), np.float64(0.14000778170190384)), (('A1÷A3', 'student_t_pvalue'), np.float64(0.8896930649647603)), (('A1÷A3', 'interpretation'), 'no significant difference'), (('A4÷A3', 'SW_kalinini'), np.float64(0.7598389861894206)), (('A4÷A3', 'SW_resplendens'), np.float64(0.8987421319992254)), (('A4÷A3', 'SW_pvalue_kalinini'), np.float64(0.0248229093822819)), (('A4÷A3', 'SW_pvalue_resplendens'), np.float64(0.02381709257631676)), (('A4÷A3', 'test_type'), 'Mann-Whitney U test'), (('A4÷A3', 'Mann_Whitney_u_stat'), np.float64(56.0)), (('A4÷A3', 'Mann_Whitney_pvalue'), np.float64(0.5109005936592143)), (('A4÷A3', 'interpretation'), 'no significant difference'), (('A5÷A3', 'SW_kalinini'), np.float64(0.8601094514290261)), (('A5÷A3', 'SW_resplendens'), np.float64(0.8767250265360891)), (('A5÷A3', 'SW_pvalue_kalinini'), np.float64(0.18954190519387337)), (('A5÷A3', 'SW_pvalue_resplendens'), np.float64(0.00864000981369926)), (('A5÷A3', 'test_type'), 'Mann-Whitney U test'), (('A5÷A3', 'Mann_Whitney_u_stat'), np.float64(77.0)), (('A5÷A3', 'Mann_Whitney_pvalue'), np.float64(0.6939118352911456)), (('A5÷A3', 'interpretation'), 'no significant difference'), (('B4÷B1', 'SW_kalinini'), np.float64(0.9125850296867288)), (('B4÷B1', 'SW_resplendens'), np.float64(0.823017669444733)), (('B4÷B1', 'SW_pvalue_kalinini'), np.float64(0.2616216324212444)), (('B4÷B1', 'SW_pvalue_resplendens'), np.float64(0.0009164236918581076)), (('B4÷B1', 'test_type'), 'Mann-Whitney U test'), (('B4÷B1', 'Mann_Whitney_u_stat'), np.float64(142.0)), (('B4÷B1', 'Mann_Whitney_pvalue'), np.float64(0.5808190020869934)), (('B4÷B1', 'interpretation'), 'no significant difference'), (('B4÷B2', 'SW_kalinini'), np.float64(0.9113355700247073)), (('B4÷B2', 'SW_resplendens'), np.float64(0.7385058400135861)), (('B4÷B2', 'SW_pvalue_kalinini'), np.float64(0.252919210745863)), (('B4÷B2', 'SW_pvalue_resplendens'), np.float64(4.6177420581384276e-05)), (('B4÷B2', 'test_type'), 'Mann-Whitney U test'), (('B4÷B2', 'Mann_Whitney_u_stat'), np.float64(141.0)), (('B4÷B2', 'Mann_Whitney_pvalue'), np.float64(0.6062901463451414)), (('B4÷B2', 'interpretation'), 'no significant difference'), (('B4÷B3', 'SW_kalinini'), np.float64(0.9225456421104286)), (('B4÷B3', 'SW_resplendens'), np.float64(0.5839199561371705)), (('B4÷B3', 'SW_pvalue_kalinini'), np.float64(0.34041584569592764)), (('B4÷B3', 'SW_pvalue_resplendens'), np.float64(6.040050024488365e-07)), (('B4÷B3', 'test_type'), 'Mann-Whitney U test'), (('B4÷B3', 'Mann_Whitney_u_stat'), np.float64(134.0)), (('B4÷B3', 'Mann_Whitney_pvalue'), np.float64(0.7966476231011546)), (('B4÷B3', 'interpretation'), 'no significant difference'), (('D2÷D1', 'SW_kalinini'), np.float64(0.9162535838588874)), (('D2÷D1', 'SW_resplendens'), np.float64(0.9632505448003522)), (('D2÷D1', 'SW_pvalue_kalinini'), np.float64(0.28866072083948624)), (('D2÷D1', 'SW_pvalue_resplendens'), np.float64(0.5320367650682417)), (('D2÷D1', 'levene_statistic'), np.float64(0.029658383020728377)), (('D2÷D1', 'levene_pvalue'), np.float64(0.8643522131660986)), (('D2÷D1', 'test_type'), \"Student's t-test\"), (('D2÷D1', 'student_t_stat'), np.float64(0.9961662226130137)), (('D2÷D1', 'student_t_pvalue'), np.float64(0.3266429238569116)), (('D2÷D1', 'interpretation'), 'no significant difference'), (('D3÷D1', 'SW_kalinini'), np.float64(0.9172413385465591)), (('D3÷D1', 'SW_resplendens'), np.float64(0.9682894248495126)), (('D3÷D1', 'SW_pvalue_kalinini'), np.float64(0.29632912027150565)), (('D3÷D1', 'SW_pvalue_resplendens'), np.float64(0.6481281330967199)), (('D3÷D1', 'levene_statistic'), np.float64(0.0008150127292543203)), (('D3÷D1', 'levene_pvalue'), np.float64(0.9774020495986707)), (('D3÷D1', 'test_type'), \"Student's t-test\"), (('D3÷D1', 'student_t_stat'), np.float64(0.9091003444704702)), (('D3÷D1', 'student_t_pvalue'), np.float64(0.3700937063290267)), (('D3÷D1', 'interpretation'), 'no significant difference'), (('D4÷D2', 'SW_kalinini'), np.float64(0.9535410215509091)), (('D4÷D2', 'SW_resplendens'), np.float64(0.9541830678133756)), (('D4÷D2', 'SW_pvalue_kalinini'), np.float64(0.6894143753228377)), (('D4÷D2', 'SW_pvalue_resplendens'), np.float64(0.35641833895898656)), (('D4÷D2', 'levene_statistic'), np.float64(3.847654678914068)), (('D4÷D2', 'levene_pvalue'), np.float64(0.058564843334476466)), (('D4÷D2', 'test_type'), \"Student's t-test\"), (('D4÷D2', 'student_t_stat'), np.float64(-2.645510729468724)), (('D4÷D2', 'student_t_pvalue'), np.float64(0.012539853276251678)), (('D4÷D2', 'interpretation'), 'significant difference'), (('E1÷E2', 'SW_kalinini'), np.float64(0.939459577571199)), (('E1÷E2', 'SW_resplendens'), np.float64(0.9779951244834973)), (('E1÷E2', 'SW_pvalue_kalinini'), np.float64(0.5141657928732875)), (('E1÷E2', 'SW_pvalue_resplendens'), np.float64(0.869338631156765)), (('E1÷E2', 'levene_statistic'), np.float64(0.785855614193378)), (('E1÷E2', 'levene_pvalue'), np.float64(0.3819702106793096)), (('E1÷E2', 'test_type'), \"Student's t-test\"), (('E1÷E2', 'student_t_stat'), np.float64(-1.9678976600103992)), (('E1÷E2', 'student_t_pvalue'), np.float64(0.057796675475554185)), (('E1÷E2', 'interpretation'), 'no significant difference')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistical_info_dict.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc66db68-01a4-40a8-8bc3-6924c4e94f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Mann_Whitney_pvalue', 'Mann_Whitney_u_stat', 'SW_kalinini',\n",
      "       'SW_pvalue_kalinini', 'SW_pvalue_resplendens', 'SW_resplendens',\n",
      "       'interpretation', 'levene_pvalue', 'levene_statistic',\n",
      "       'student_t_pvalue', 'student_t_stat', 'test_type', 'welch_t_pvalue',\n",
      "       'welch_t_stat'],\n",
      "      dtype='object', name='statistic')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>statistic</th>\n",
       "      <th>test_type</th>\n",
       "      <th>interpretation</th>\n",
       "      <th>Mann_Whitney_u_stat</th>\n",
       "      <th>Mann_Whitney_pvalue</th>\n",
       "      <th>SW_kalinini</th>\n",
       "      <th>SW_pvalue_kalinini</th>\n",
       "      <th>SW_resplendens</th>\n",
       "      <th>SW_pvalue_resplendens</th>\n",
       "      <th>levene_statistic</th>\n",
       "      <th>levene_pvalue</th>\n",
       "      <th>student_t_stat</th>\n",
       "      <th>student_t_pvalue</th>\n",
       "      <th>welch_t_stat</th>\n",
       "      <th>welch_t_pvalue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81869</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.97174</td>\n",
       "      <td>0.730556</td>\n",
       "      <td>1.18731</td>\n",
       "      <td>0.285503</td>\n",
       "      <td>-1.359585</td>\n",
       "      <td>0.185208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1÷A3</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853406</td>\n",
       "      <td>0.167666</td>\n",
       "      <td>0.97358</td>\n",
       "      <td>0.773805</td>\n",
       "      <td>1.502602</td>\n",
       "      <td>0.230856</td>\n",
       "      <td>0.140008</td>\n",
       "      <td>0.889693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851221</td>\n",
       "      <td>0.16102</td>\n",
       "      <td>0.964654</td>\n",
       "      <td>0.563395</td>\n",
       "      <td>1.846361</td>\n",
       "      <td>0.185451</td>\n",
       "      <td>-2.167579</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930251</td>\n",
       "      <td>0.582042</td>\n",
       "      <td>0.971987</td>\n",
       "      <td>0.736439</td>\n",
       "      <td>0.45934</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>-3.297398</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0.712256</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.943177</td>\n",
       "      <td>0.210171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4÷A3</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.510901</td>\n",
       "      <td>0.759839</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.898742</td>\n",
       "      <td>0.023817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.979104</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>0.245484</td>\n",
       "      <td>0.905434</td>\n",
       "      <td>0.032768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5÷A3</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.693912</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.189542</td>\n",
       "      <td>0.876725</td>\n",
       "      <td>0.00864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.801559</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.97329</td>\n",
       "      <td>0.767065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955762</td>\n",
       "      <td>0.71796</td>\n",
       "      <td>0.972666</td>\n",
       "      <td>0.75246</td>\n",
       "      <td>0.691244</td>\n",
       "      <td>0.411903</td>\n",
       "      <td>-2.709564</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946446</td>\n",
       "      <td>0.598942</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>0.438137</td>\n",
       "      <td>0.481834</td>\n",
       "      <td>0.492602</td>\n",
       "      <td>-1.696814</td>\n",
       "      <td>0.09944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954223</td>\n",
       "      <td>0.698188</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.227871</td>\n",
       "      <td>0.883654</td>\n",
       "      <td>0.354245</td>\n",
       "      <td>-1.154653</td>\n",
       "      <td>0.256783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4÷B1</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.580819</td>\n",
       "      <td>0.912585</td>\n",
       "      <td>0.261622</td>\n",
       "      <td>0.823018</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4÷B2</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.60629</td>\n",
       "      <td>0.911336</td>\n",
       "      <td>0.252919</td>\n",
       "      <td>0.738506</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4÷B3</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.796648</td>\n",
       "      <td>0.922546</td>\n",
       "      <td>0.340416</td>\n",
       "      <td>0.58392</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B5</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.785186</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.977405</td>\n",
       "      <td>0.85756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930868</td>\n",
       "      <td>0.419701</td>\n",
       "      <td>0.959724</td>\n",
       "      <td>0.457816</td>\n",
       "      <td>0.052938</td>\n",
       "      <td>0.819493</td>\n",
       "      <td>0.851365</td>\n",
       "      <td>0.400893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907583</td>\n",
       "      <td>0.228274</td>\n",
       "      <td>0.975767</td>\n",
       "      <td>0.823072</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>0.800361</td>\n",
       "      <td>-1.457648</td>\n",
       "      <td>0.154682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98015</td>\n",
       "      <td>0.966993</td>\n",
       "      <td>0.970368</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>1.535578</td>\n",
       "      <td>0.224289</td>\n",
       "      <td>-0.646912</td>\n",
       "      <td>0.522302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2÷D1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916254</td>\n",
       "      <td>0.288661</td>\n",
       "      <td>0.963251</td>\n",
       "      <td>0.532037</td>\n",
       "      <td>0.029658</td>\n",
       "      <td>0.864352</td>\n",
       "      <td>0.996166</td>\n",
       "      <td>0.326643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945258</td>\n",
       "      <td>0.584122</td>\n",
       "      <td>0.917247</td>\n",
       "      <td>0.058179</td>\n",
       "      <td>0.037287</td>\n",
       "      <td>0.848103</td>\n",
       "      <td>-1.147709</td>\n",
       "      <td>0.259597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3÷D1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>0.296329</td>\n",
       "      <td>0.968289</td>\n",
       "      <td>0.648128</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.977402</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.370094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885194</td>\n",
       "      <td>0.121039</td>\n",
       "      <td>0.953538</td>\n",
       "      <td>0.345876</td>\n",
       "      <td>2.502515</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>-2.552403</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4÷D2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953541</td>\n",
       "      <td>0.689414</td>\n",
       "      <td>0.954183</td>\n",
       "      <td>0.356418</td>\n",
       "      <td>3.847655</td>\n",
       "      <td>0.058565</td>\n",
       "      <td>-2.645511</td>\n",
       "      <td>0.01254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928851</td>\n",
       "      <td>0.399349</td>\n",
       "      <td>0.945555</td>\n",
       "      <td>0.236106</td>\n",
       "      <td>2.139521</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>-2.453153</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1÷E2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93946</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.977995</td>\n",
       "      <td>0.869339</td>\n",
       "      <td>0.785856</td>\n",
       "      <td>0.38197</td>\n",
       "      <td>-1.967898</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>Mann-Whitney U test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.941309</td>\n",
       "      <td>0.82562</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>0.91416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>Welch's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906629</td>\n",
       "      <td>0.25863</td>\n",
       "      <td>0.966604</td>\n",
       "      <td>0.608322</td>\n",
       "      <td>7.025255</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.664795</td>\n",
       "      <td>0.012168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930054</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.979932</td>\n",
       "      <td>0.905003</td>\n",
       "      <td>1.05549</td>\n",
       "      <td>0.312196</td>\n",
       "      <td>-2.330679</td>\n",
       "      <td>0.02645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961095</td>\n",
       "      <td>0.798286</td>\n",
       "      <td>0.976121</td>\n",
       "      <td>0.830743</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.956462</td>\n",
       "      <td>-2.605458</td>\n",
       "      <td>0.01397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926843</td>\n",
       "      <td>0.417564</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>2.739699</td>\n",
       "      <td>0.107974</td>\n",
       "      <td>-2.92451</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5</th>\n",
       "      <td>Student's t-test</td>\n",
       "      <td>no significant difference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890708</td>\n",
       "      <td>0.172717</td>\n",
       "      <td>0.946788</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.980631</td>\n",
       "      <td>-1.948876</td>\n",
       "      <td>0.06041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "statistic            test_type             interpretation Mann_Whitney_u_stat  \\\n",
       "metric                                                                          \n",
       "A1            Student's t-test  no significant difference                 NaN   \n",
       "A1÷A3         Student's t-test  no significant difference                 NaN   \n",
       "A2            Student's t-test     significant difference                 NaN   \n",
       "A3            Student's t-test     significant difference                 NaN   \n",
       "A4         Mann-Whitney U test  no significant difference                46.0   \n",
       "A4÷A3      Mann-Whitney U test  no significant difference                56.0   \n",
       "A5         Mann-Whitney U test  no significant difference                68.0   \n",
       "A5÷A3      Mann-Whitney U test  no significant difference                77.0   \n",
       "B1         Mann-Whitney U test     significant difference                58.0   \n",
       "B2            Student's t-test     significant difference                 NaN   \n",
       "B3            Student's t-test  no significant difference                 NaN   \n",
       "B4            Student's t-test  no significant difference                 NaN   \n",
       "B4÷B1      Mann-Whitney U test  no significant difference               142.0   \n",
       "B4÷B2      Mann-Whitney U test  no significant difference               141.0   \n",
       "B4÷B3      Mann-Whitney U test  no significant difference               134.0   \n",
       "B5         Mann-Whitney U test  no significant difference               170.0   \n",
       "C1            Student's t-test  no significant difference                 NaN   \n",
       "D1            Student's t-test  no significant difference                 NaN   \n",
       "D2            Student's t-test  no significant difference                 NaN   \n",
       "D2÷D1         Student's t-test  no significant difference                 NaN   \n",
       "D3            Student's t-test  no significant difference                 NaN   \n",
       "D3÷D1         Student's t-test  no significant difference                 NaN   \n",
       "D4            Student's t-test     significant difference                 NaN   \n",
       "D4÷D2         Student's t-test     significant difference                 NaN   \n",
       "E1            Student's t-test     significant difference                 NaN   \n",
       "E1÷E2         Student's t-test  no significant difference                 NaN   \n",
       "E2         Mann-Whitney U test  no significant difference               124.0   \n",
       "F1              Welch's t-test     significant difference                 NaN   \n",
       "F2            Student's t-test     significant difference                 NaN   \n",
       "F3            Student's t-test     significant difference                 NaN   \n",
       "F4            Student's t-test     significant difference                 NaN   \n",
       "F5            Student's t-test  no significant difference                 NaN   \n",
       "\n",
       "statistic Mann_Whitney_pvalue SW_kalinini SW_pvalue_kalinini SW_resplendens  \\\n",
       "metric                                                                        \n",
       "A1                        NaN     0.81869           0.085976        0.97174   \n",
       "A1÷A3                     NaN    0.853406           0.167666        0.97358   \n",
       "A2                        NaN    0.851221            0.16102       0.964654   \n",
       "A3                        NaN    0.930251           0.582042       0.971987   \n",
       "A4                     0.2325    0.712256           0.008301       0.943177   \n",
       "A4÷A3                0.510901    0.759839           0.024823       0.898742   \n",
       "A5                   0.979104    0.874675           0.245484       0.905434   \n",
       "A5÷A3                0.693912    0.860109           0.189542       0.876725   \n",
       "B1                   0.012306    0.801559           0.009862        0.97329   \n",
       "B2                        NaN    0.955762            0.71796       0.972666   \n",
       "B3                        NaN    0.946446           0.598942       0.958726   \n",
       "B4                        NaN    0.954223           0.698188       0.944828   \n",
       "B4÷B1                0.580819    0.912585           0.261622       0.823018   \n",
       "B4÷B2                 0.60629    0.911336           0.252919       0.738506   \n",
       "B4÷B3                0.796648    0.922546           0.340416        0.58392   \n",
       "B5                   0.113407    0.785186           0.006007       0.977405   \n",
       "C1                        NaN    0.930868           0.419701       0.959724   \n",
       "D1                        NaN    0.907583           0.228274       0.975767   \n",
       "D2                        NaN     0.98015           0.966993       0.970368   \n",
       "D2÷D1                     NaN    0.916254           0.288661       0.963251   \n",
       "D3                        NaN    0.945258           0.584122       0.917247   \n",
       "D3÷D1                     NaN    0.917241           0.296329       0.968289   \n",
       "D4                        NaN    0.885194           0.121039       0.953538   \n",
       "D4÷D2                     NaN    0.953541           0.689414       0.954183   \n",
       "E1                        NaN    0.928851           0.399349       0.945555   \n",
       "E1÷E2                     NaN     0.93946           0.514166       0.977995   \n",
       "E2                   0.941309     0.82562           0.020447       0.980479   \n",
       "F1                        NaN    0.906629            0.25863       0.966604   \n",
       "F2                        NaN    0.930054           0.448422       0.979932   \n",
       "F3                        NaN    0.961095           0.798286       0.976121   \n",
       "F4                        NaN    0.926843           0.417564       0.914324   \n",
       "F5                        NaN    0.890708           0.172717       0.946788   \n",
       "\n",
       "statistic SW_pvalue_resplendens levene_statistic levene_pvalue student_t_stat  \\\n",
       "metric                                                                          \n",
       "A1                     0.730556          1.18731      0.285503      -1.359585   \n",
       "A1÷A3                  0.773805         1.502602      0.230856       0.140008   \n",
       "A2                     0.563395         1.846361      0.185451      -2.167579   \n",
       "A3                     0.736439          0.45934        0.5037      -3.297398   \n",
       "A4                     0.210171              NaN           NaN            NaN   \n",
       "A4÷A3                  0.023817              NaN           NaN            NaN   \n",
       "A5                     0.032768              NaN           NaN            NaN   \n",
       "A5÷A3                   0.00864              NaN           NaN            NaN   \n",
       "B1                     0.767065              NaN           NaN            NaN   \n",
       "B2                      0.75246         0.691244      0.411903      -2.709564   \n",
       "B3                     0.438137         0.481834      0.492602      -1.696814   \n",
       "B4                     0.227871         0.883654      0.354245      -1.154653   \n",
       "B4÷B1                  0.000916              NaN           NaN            NaN   \n",
       "B4÷B2                  0.000046              NaN           NaN            NaN   \n",
       "B4÷B3                  0.000001              NaN           NaN            NaN   \n",
       "B5                      0.85756              NaN           NaN            NaN   \n",
       "C1                     0.457816         0.052938      0.819493       0.851365   \n",
       "D1                     0.823072         0.065021      0.800361      -1.457648   \n",
       "D2                     0.697813         1.535578      0.224289      -0.646912   \n",
       "D2÷D1                  0.532037         0.029658      0.864352       0.996166   \n",
       "D3                     0.058179         0.037287      0.848103      -1.147709   \n",
       "D3÷D1                  0.648128         0.000815      0.977402         0.9091   \n",
       "D4                     0.345876         2.502515        0.1235      -2.552403   \n",
       "D4÷D2                  0.356418         3.847655      0.058565      -2.645511   \n",
       "E1                     0.236106         2.139521        0.1533      -2.453153   \n",
       "E1÷E2                  0.869339         0.785856       0.38197      -1.967898   \n",
       "E2                      0.91416              NaN           NaN            NaN   \n",
       "F1                     0.608322         7.025255      0.012542            NaN   \n",
       "F2                     0.905003          1.05549      0.312196      -2.330679   \n",
       "F3                     0.830743         0.003029      0.956462      -2.605458   \n",
       "F4                     0.050416         2.739699      0.107974       -2.92451   \n",
       "F5                     0.250689         0.000599      0.980631      -1.948876   \n",
       "\n",
       "statistic student_t_pvalue welch_t_stat welch_t_pvalue  \n",
       "metric                                                  \n",
       "A1                0.185208          NaN            NaN  \n",
       "A1÷A3             0.889693          NaN            NaN  \n",
       "A2                0.039176          NaN            NaN  \n",
       "A3                0.002739          NaN            NaN  \n",
       "A4                     NaN          NaN            NaN  \n",
       "A4÷A3                  NaN          NaN            NaN  \n",
       "A5                     NaN          NaN            NaN  \n",
       "A5÷A3                  NaN          NaN            NaN  \n",
       "B1                     NaN          NaN            NaN  \n",
       "B2                0.010733          NaN            NaN  \n",
       "B3                 0.09944          NaN            NaN  \n",
       "B4                0.256783          NaN            NaN  \n",
       "B4÷B1                  NaN          NaN            NaN  \n",
       "B4÷B2                  NaN          NaN            NaN  \n",
       "B4÷B3                  NaN          NaN            NaN  \n",
       "B5                     NaN          NaN            NaN  \n",
       "C1                0.400893          NaN            NaN  \n",
       "D1                0.154682          NaN            NaN  \n",
       "D2                0.522302          NaN            NaN  \n",
       "D2÷D1             0.326643          NaN            NaN  \n",
       "D3                0.259597          NaN            NaN  \n",
       "D3÷D1             0.370094          NaN            NaN  \n",
       "D4                0.015672          NaN            NaN  \n",
       "D4÷D2              0.01254          NaN            NaN  \n",
       "E1                0.019793          NaN            NaN  \n",
       "E1÷E2             0.057797          NaN            NaN  \n",
       "E2                     NaN          NaN            NaN  \n",
       "F1                     NaN    -2.664795       0.012168  \n",
       "F2                 0.02645          NaN            NaN  \n",
       "F3                 0.01397          NaN            NaN  \n",
       "F4                0.006398          NaN            NaN  \n",
       "F5                 0.06041          NaN            NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save statistical results\n",
    "statistical_info_df = pd.DataFrame(\n",
    "    [(k1, k2, v) for (k1, k2), v in statistical_info_dict.items()],\n",
    "     columns = [\"metric\", \"statistic\", \"value\"]                             )\n",
    "\n",
    "df_pivoted = statistical_info_df.pivot(index='metric', columns='statistic', values='value')#.reset_index()\n",
    "print(df_pivoted.columns)\n",
    "df_pivoted = df_pivoted[[\"test_type\", \"interpretation\", 'Mann_Whitney_u_stat', 'Mann_Whitney_pvalue', 'SW_kalinini',\n",
    "       'SW_pvalue_kalinini','SW_resplendens', 'SW_pvalue_resplendens', \n",
    "       'levene_statistic', 'levene_pvalue', \n",
    "       'student_t_stat', 'student_t_pvalue', \n",
    "       'welch_t_stat', 'welch_t_pvalue']] #Mann_Whitney_pvalue']\n",
    "df_pivoted.to_csv('statistical_tests.csv', index=True)\n",
    "df_pivoted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9970e66-f69b-4894-be8f-fc3cb8c1a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_decimals_from_latex(latex_text):\n",
    "    \"\"\"\n",
    "    Receives a string containing LaTeX table code and returns a new string where\n",
    "    any numeric values with decimals are rounded to the nearest integer.\n",
    "    \n",
    "    Args:\n",
    "        latex_text (str): LaTeX code with tables.\n",
    "    \n",
    "    Returns:\n",
    "        str: Modified LaTeX code with numbers formatted to have no decimals.\n",
    "    \"\"\"\n",
    "    def replace_number(match):\n",
    "        num_str = match.group(0)\n",
    "        try:\n",
    "            # Convert the string to a float, round it, and convert back to string.\n",
    "            num = float(num_str)\n",
    "            return str(int(round(num)))\n",
    "        except ValueError:\n",
    "            # In case of an error, return the original string.\n",
    "            return num_str\n",
    "\n",
    "    # This pattern matches numbers containing a decimal point.\n",
    "    # It assumes numbers are positive. Modify the pattern if you need to match negatives.\n",
    "    pattern = r'\\b\\d+\\.\\d+\\b'\n",
    "    \n",
    "    # Replace all occurrences using the replace_number function.\n",
    "    formatted_text = re.sub(pattern, replace_number, latex_text)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75fe061-cfb6-4844-8c61-4f0f897339e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   metric  normality_kalinini  normality_resplendens   normality  \\\n",
      "0      A1                True                   True      normal   \n",
      "1      A2                True                   True      normal   \n",
      "2      A3                True                   True      normal   \n",
      "3      A4               False                   True  non normal   \n",
      "4      A5                True                  False  non normal   \n",
      "5      B1               False                   True  non normal   \n",
      "6      B2                True                   True      normal   \n",
      "7      B3                True                   True      normal   \n",
      "8      B4                True                   True      normal   \n",
      "9      B5               False                   True  non normal   \n",
      "10     C1                True                   True      normal   \n",
      "11     D1                True                   True      normal   \n",
      "12     D2                True                   True      normal   \n",
      "13     D3                True                   True      normal   \n",
      "14     D4                True                   True      normal   \n",
      "15     E1                True                   True      normal   \n",
      "16     E2               False                   True  non normal   \n",
      "17     F1                True                   True      normal   \n",
      "18     F2                True                   True      normal   \n",
      "19     F3                True                   True      normal   \n",
      "20     F4                True                   True      normal   \n",
      "21     F5                True                   True      normal   \n",
      "22  A1÷A3                True                   True      normal   \n",
      "23  A4÷A3               False                  False  non normal   \n",
      "24  A5÷A3                True                  False  non normal   \n",
      "25  B4÷B1                True                  False  non normal   \n",
      "26  B4÷B2                True                  False  non normal   \n",
      "27  B4÷B3                True                  False  non normal   \n",
      "28  D2÷D1                True                   True      normal   \n",
      "29  D3÷D1                True                   True      normal   \n",
      "30  D4÷D2                True                   True      normal   \n",
      "31  E1÷E2                True                   True      normal   \n",
      "\n",
      "    levene_pvalue   variance            test_type    t_stat   p_value  \\\n",
      "0        0.285503      equal     Student's t-test -1.359585  0.185208   \n",
      "1        0.185451      equal     Student's t-test -2.167579  0.039176   \n",
      "2        0.503700      equal     Student's t-test -3.297398  0.002739   \n",
      "3             NaN  different  Mann-Whitney U test       NaN  0.232500   \n",
      "4             NaN  different  Mann-Whitney U test       NaN  0.979104   \n",
      "5             NaN  different  Mann-Whitney U test       NaN  0.012306   \n",
      "6        0.411903      equal     Student's t-test -2.709564  0.010733   \n",
      "7        0.492602      equal     Student's t-test -1.696814  0.099440   \n",
      "8        0.354245      equal     Student's t-test -1.154653  0.256783   \n",
      "9             NaN  different  Mann-Whitney U test       NaN  0.113407   \n",
      "10       0.819493      equal     Student's t-test  0.851365  0.400893   \n",
      "11       0.800361      equal     Student's t-test -1.457648  0.154682   \n",
      "12       0.224289      equal     Student's t-test -0.646912  0.522302   \n",
      "13       0.848103      equal     Student's t-test -1.147709  0.259597   \n",
      "14       0.123500      equal     Student's t-test -2.552403  0.015672   \n",
      "15       0.153300      equal     Student's t-test -2.453153  0.019793   \n",
      "16            NaN  different  Mann-Whitney U test       NaN  0.941309   \n",
      "17       0.012542  different       Welch's t-test -2.664795  0.012168   \n",
      "18       0.312196      equal     Student's t-test -2.330679  0.026450   \n",
      "19       0.956462      equal     Student's t-test -2.605458  0.013970   \n",
      "20       0.107974      equal     Student's t-test -2.924510  0.006398   \n",
      "21       0.980631      equal     Student's t-test -1.948876  0.060410   \n",
      "22       0.230856      equal     Student's t-test  0.140008  0.889693   \n",
      "23            NaN  different  Mann-Whitney U test       NaN  0.510901   \n",
      "24            NaN  different  Mann-Whitney U test       NaN  0.693912   \n",
      "25            NaN  different  Mann-Whitney U test       NaN  0.580819   \n",
      "26            NaN  different  Mann-Whitney U test       NaN  0.606290   \n",
      "27            NaN  different  Mann-Whitney U test       NaN  0.796648   \n",
      "28       0.864352      equal     Student's t-test  0.996166  0.326643   \n",
      "29       0.977402      equal     Student's t-test  0.909100  0.370094   \n",
      "30       0.058565      equal     Student's t-test -2.645511  0.012540   \n",
      "31       0.381970      equal     Student's t-test -1.967898  0.057797   \n",
      "\n",
      "               interpretation     significance  u_stat  \n",
      "0   no significant difference  non significant     NaN  \n",
      "1      significant difference      significant     NaN  \n",
      "2      significant difference      significant     NaN  \n",
      "3   no significant difference  non significant    46.0  \n",
      "4   no significant difference  non significant    68.0  \n",
      "5      significant difference      significant    58.0  \n",
      "6      significant difference      significant     NaN  \n",
      "7   no significant difference  non significant     NaN  \n",
      "8   no significant difference  non significant     NaN  \n",
      "9   no significant difference  non significant   170.0  \n",
      "10  no significant difference  non significant     NaN  \n",
      "11  no significant difference  non significant     NaN  \n",
      "12  no significant difference  non significant     NaN  \n",
      "13  no significant difference  non significant     NaN  \n",
      "14     significant difference      significant     NaN  \n",
      "15     significant difference      significant     NaN  \n",
      "16  no significant difference  non significant   124.0  \n",
      "17     significant difference      significant     NaN  \n",
      "18     significant difference      significant     NaN  \n",
      "19     significant difference      significant     NaN  \n",
      "20     significant difference      significant     NaN  \n",
      "21  no significant difference  non significant     NaN  \n",
      "22  no significant difference  non significant     NaN  \n",
      "23  no significant difference  non significant    56.0  \n",
      "24  no significant difference  non significant    77.0  \n",
      "25  no significant difference  non significant   142.0  \n",
      "26  no significant difference  non significant   141.0  \n",
      "27  no significant difference  non significant   134.0  \n",
      "28  no significant difference  non significant     NaN  \n",
      "29  no significant difference  non significant     NaN  \n",
      "30     significant difference      significant     NaN  \n",
      "31  no significant difference  non significant     NaN  \n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'result_df' is your dataframe and 'metrics_under_consideration' is a list of metric names\n",
    "measurement_df_2 = result_df\n",
    "kalinini_data = measurement_df_2[measurement_df_2[\"species\"] == \"kalinini\"]\n",
    "resplendens_data = measurement_df_2[measurement_df_2[\"species\"] == \"resplendens\"]\n",
    "\n",
    "# List of metrics to test\n",
    "metrics = metrics_under_consideration\n",
    "\n",
    "# Dictionary to store test results\n",
    "t_test_results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    # Extract the data for each species' metric and drop missing values\n",
    "    kalinini_values = kalinini_data[metric].dropna()\n",
    "    resplendens_values = resplendens_data[metric].dropna()\n",
    "    \n",
    "    # Check normality (Shapiro-Wilk test) for both species\n",
    "    kalinini_normal = stats.shapiro(kalinini_values)[1] > 0.05  # p-value > 0.05 means normal\n",
    "    resplendens_normal = stats.shapiro(resplendens_values)[1] > 0.05\n",
    "    \n",
    "    # Determine overall normality for this metric\n",
    "    overall_normality = \"normal\" if (kalinini_normal and resplendens_normal) else \"non normal\"\n",
    "    \n",
    "    # Initialize a dictionary to store this metric's test results\n",
    "    test_result = {\n",
    "        \"normality_kalinini\": kalinini_normal,\n",
    "        \"normality_resplendens\": resplendens_normal,\n",
    "        \"normality\": overall_normality\n",
    "    }\n",
    "    \n",
    "    if kalinini_normal and resplendens_normal:\n",
    "        # Perform Levene's test for homogeneity of variances\n",
    "        levene_test = stats.levene(kalinini_values, resplendens_values)\n",
    "        # Determine variance equality category\n",
    "        variance_category = \"equal\" if levene_test.pvalue > 0.05 else \"different\"\n",
    "        test_result[\"levene_pvalue\"] = levene_test.pvalue\n",
    "        test_result[\"variance\"] = variance_category\n",
    "        \n",
    "        # Choose the appropriate t-test\n",
    "        if variance_category == \"equal\":\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values)\n",
    "            test_type = \"Student's t-test\"\n",
    "        else:\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values, equal_var=False)\n",
    "            test_type = \"Welch's t-test\"\n",
    "            \n",
    "        test_result[\"test_type\"] = test_type\n",
    "        test_result[\"t_stat\"] = t_stat\n",
    "        test_result[\"p_value\"] = p_value\n",
    "    else:\n",
    "        # When at least one group fails normality, use the Mann-Whitney U test\n",
    "        u_stat, p_value = stats.mannwhitneyu(kalinini_values, resplendens_values)\n",
    "        test_result[\"test_type\"] = \"Mann-Whitney U test\"\n",
    "        test_result[\"u_stat\"] = u_stat\n",
    "        test_result[\"p_value\"] = p_value\n",
    "        # For non-parametric tests, we generally consider the variance comparison as 'different'\n",
    "        test_result[\"variance\"] = \"different\"\n",
    "        test_result[\"levene_pvalue\"] = None\n",
    "\n",
    "    # Interpretation of significance (textual) and add a categorical significance field\n",
    "    interpretation = \"significant difference\" if p_value < 0.05 else \"no significant difference\"\n",
    "    significance = \"significant\" if p_value < 0.05 else \"non significant\"\n",
    "    test_result[\"interpretation\"] = interpretation\n",
    "    test_result[\"significance\"] = significance\n",
    "    \n",
    "    # Save the results for this metric\n",
    "    t_test_results[metric] = test_result\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame.from_dict(t_test_results, orient='index').reset_index().rename(columns={'index': 'metric'})\n",
    "#results_df.columns = results_df.columns.str.replace('_', '-')\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6bb138-91cb-4c7b-b8f7-3804d205fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "current_date = datetime.today().date()\n",
    "\n",
    "def create_paragraph(text):\n",
    "    \"\"\"\n",
    "    Returns a LaTeX snippet for a centered paragraph.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to be inserted in the paragraph.\n",
    "        \n",
    "    Returns:\n",
    "        str: LaTeX code for the centered paragraph.\n",
    "    \"\"\"\n",
    "    # In LaTeX, centering text can be done with the center environment\n",
    "    latex_paragraph = (\n",
    "        \"\\\\begin{center}\\n\"\n",
    "        f\"{text}\\n\"\n",
    "        \"\\\\end{center}\\n\\n\"\n",
    "    )\n",
    "    return latex_paragraph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deca737c-d567-4973-8ff6-091f7cffdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Global constant for the current date\n",
    "current_date = datetime.today().date()\n",
    "\n",
    "def front_page():\n",
    "    \"\"\"\n",
    "    Returns the LaTeX code for a front page (title page) similar to the ReportLab front_page() function.\n",
    "    \"\"\"\n",
    "    # Construct the LaTeX code for the title page\n",
    "    latex_front_page = (\n",
    "        \"\\\\begin{titlepage}\\n\"\n",
    "        \"  \\\\centering\\n\\n\"\n",
    "        \"  % Title\\n\"\n",
    "        \"  {\\\\Huge \\\\textbf{Biometry report} \\\\par}\\n\"\n",
    "        \"  \\\\vspace{1.5cm}\\n\\n\"\n",
    "        \"  % Authors\\n\"\n",
    "        \"  {\\\\Large Dra. Marcela Hernández, Dr. Esteban Bermúdez Ureña, Angel Aguirre \\\\& Esteban Soto. \\\\par}\\n\"\n",
    "        \"  \\\\vspace{0.5cm}\\n\\n\"\n",
    "        \"  % Institution\\n\"\n",
    "        \"  {\\\\Large Centro de Investigación en Ciencia e Ingeniería de los Materiales \\\\par}\\n\"\n",
    "        \"  \\\\vspace{0.5cm}\\n\\n\"\n",
    "        \"  % Additional details\\n\"\n",
    "        \"  {\\\\Large 2025 \\\\par}\\n\"\n",
    "        \"  {\\\\Large University of Costa Rica \\\\par}\\n\"\n",
    "        \"  \\\\vspace{0.5cm}\\n\"\n",
    "        \"  {\\\\Large \" + str(current_date) + \" \\\\par}\\n\\n\"\n",
    "        \"  \\\\vfill\\n\"\n",
    "        \"\\\\end{titlepage}\\n\"\n",
    "        \"\\\\newpage\\n\"\n",
    "    )\n",
    "    return latex_front_page\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844575a8-5770-408f-8881-867c130aec84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{Introduction}\\n\\nZubov et al. (2019) describe a new species of \\\\textit{Chrysina}. In its comparative analysis, it is stated that the new species is very similar to \\\\textit{C. resplendens} and only a few morphological differences can be noted. This work intends to perform a quantitative analysis of these differences using a sample of 11 \\\\textit{C. kalinini} specimens and 23 \\\\textit{C. resplendens} specimens.\\n\\nThe measurements described in the article are specified more precisely and alternative metrics are analyzed.\\n\\n\\\\newpage\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def introduction_section(df):\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for the introduction section of the report.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing specimen data with at least\n",
    "                               columns 'species' and 'code'.\n",
    "\n",
    "    Returns:\n",
    "        str: LaTeX code for the introduction section.\n",
    "    \"\"\"\n",
    "    # Compute specimen counts from the dataframe\n",
    "    number_of_kalinini_specimens = df[df[\"species\"] == \"kalinini\"][\"code\"].count()\n",
    "    number_of_resplendens_specimens = df[df[\"species\"] == \"resplendens\"][\"code\"].count()\n",
    "    \n",
    "    # Build the LaTeX introduction section\n",
    "    latex_introduction = (\n",
    "        \"\\\\section{Introduction}\\n\\n\"\n",
    "        \"Zubov et al. (2019) describe a new species of \\\\textit{Chrysina}. In its comparative analysis, \"\n",
    "        \"it is stated that the new species is very similar to \\\\textit{C. resplendens} and only a few \"\n",
    "        \"morphological differences can be noted. This work intends to perform a quantitative analysis of these \"\n",
    "        \"differences using a sample of \"\n",
    "        f\"{number_of_kalinini_specimens} \\\\textit{{C. kalinini}} specimens and \"\n",
    "        f\"{number_of_resplendens_specimens} \\\\textit{{C. resplendens}} specimens.\\n\\n\"\n",
    "        \"The measurements described in the article are specified more precisely and alternative metrics are analyzed.\\n\\n\"\n",
    "        \"\\\\newpage\\n\"\n",
    "    )\n",
    "    \n",
    "    return latex_introduction\n",
    "\n",
    "introduction_section(measurement_df_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9451d1-a372-4bc0-a74b-26557db572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methodology_latex(df):\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for the methodology section of the report.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing specimen data with at least\n",
    "                               the columns \"species\", \"code\", \"sex_code\", and \"location_code\".\n",
    "    \n",
    "    Returns:\n",
    "        str: LaTeX code for the methodology section.\n",
    "    \"\"\"\n",
    "    # Compute counts and groupings\n",
    "    number_of_kalinini_specimens = df[df[\"species\"] == \"kalinini\"][\"code\"].count()\n",
    "    number_of_resplendens_specimens = df[df[\"species\"] == \"resplendens\"][\"code\"].count()\n",
    "    \n",
    "    # Unique locations per species; convert numpy arrays to comma‐separated strings\n",
    "    unique_locations_by_species = df.groupby(\"species\")[\"location_code\"].unique()\n",
    "    unique_locations = {}\n",
    "    for species, locations in unique_locations_by_species.items():\n",
    "        # Convert each numpy array of locations to a string\n",
    "        loc_str = \", \".join(map(str, locations))\n",
    "        unique_locations[species] = loc_str\n",
    "    \n",
    "    # Sex counts for C. kalinini\n",
    "    number_of_kalinini_m_specimens = df[(df[\"species\"] == \"kalinini\") & (df[\"sex_code\"] == \"M\")][\"code\"].count()\n",
    "    number_of_kalinini_f_specimens = df[(df[\"species\"] == \"kalinini\") & (df[\"sex_code\"] == \"F\")][\"code\"].count()\n",
    "    number_of_kalinini_u_specimens = number_of_kalinini_specimens - number_of_kalinini_m_specimens - number_of_kalinini_f_specimens\n",
    "\n",
    "    # Sex counts for C. resplendens\n",
    "    number_of_resplendens_m_specimens = df[(df[\"species\"] == \"resplendens\") & (df[\"sex_code\"] == \"M\")][\"code\"].count()\n",
    "    number_of_resplendens_f_specimens = df[(df[\"species\"] == \"resplendens\") & (df[\"sex_code\"] == \"F\")][\"code\"].count()\n",
    "    # Note: The original code repeats the unknown count for kalinini. If a similar unknown count is needed\n",
    "    # for C. resplendens, it can be computed as shown below. Otherwise, you may adjust accordingly.\n",
    "    number_of_resplendens_u_specimens = number_of_resplendens_specimens - number_of_resplendens_m_specimens - number_of_resplendens_f_specimens\n",
    "\n",
    "    # Build the LaTeX section\n",
    "    latex_methodology = (\n",
    "        \"\\\\section{Methodology}\\n\\n\"\n",
    "        \"Chrysina samples were retrieved from the following locations: \\\\\\\\ \\n\"\n",
    "    )\n",
    "\n",
    "    # Include the unique locations information for each species\n",
    "    for species, locs in unique_locations.items():\n",
    "        latex_methodology += f\"\\\\textit{{{species}}}: {locs} \\\\\\\\ \\n\"\n",
    "    \n",
    "    latex_methodology += \"\\n\"\n",
    "\n",
    "    # Sex distribution text as a bullet list\n",
    "    latex_methodology += (\n",
    "        \"Sex distribution is as follows:\\n\"\n",
    "        \"\\\\begin{itemize}\\n\"\n",
    "        f\"  \\\\item \\\\textit{{C. kalinini}}: {number_of_kalinini_m_specimens} males, {number_of_kalinini_f_specimens} females, {number_of_kalinini_u_specimens} unknown\\n\"\n",
    "        f\"  \\\\item \\\\textit{{C. resplendens}}: {number_of_resplendens_m_specimens} males, {number_of_resplendens_f_specimens} females, {number_of_resplendens_u_specimens} unknown\\n\"\n",
    "        \"\\\\end{itemize}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    # Additional paragraphs with a bit of spacing\n",
    "    latex_methodology += (\n",
    "        \"Using an estereoscope (Resolution 4.781 $\\\\mu$m per pixel), its head, clipeum, mesosternal process, prosternal process, and ventral plates were measured. \\n\\n\"\n",
    "        \"An OCR software was used to retrieve the measurements and to add contextual information about collection location, sex, genus, and species. \\n\\n\"\n",
    "        \"Zubov et al.'s morphological differences were calculated using the metrics taken with the estereoscope. \\n\\n\"\n",
    "        r\"\"\"For the statistical analysis, the measurement dataset is filtered to include only entries that correspond to either \\textit{resplendens} or \\textit{kalinini} specimens. \n",
    "\n",
    "For each metric, \\texttt{NA} values are dropped, and a Shapiro-Wilk test for normality is performed for both species.\n",
    "\n",
    "If the p-value of the Shapiro-Wilk test is greater than 0.05, the dataset can be assumed to be normal.\n",
    "\n",
    "If both datasets are normal, a Levene test is performed to check for homogeneity of variances. \n",
    "\n",
    "If the value for the Levene’s test is greater than 0.05, variances are deemed to be equal.\n",
    "\n",
    "At this point, one of the following cases will occur:\n",
    "\n",
    "\\begin{itemize}\n",
    "    \\item If the datasets are normal with equal variances, a Student’s t-test is applied.\n",
    "    \\item If the datasets are normal with different variances, a Welch’s t-test is applied.\n",
    "    \\item If at least one group is not normal, a Mann-Whitney U test is applied.\n",
    "\\end{itemize}\n",
    "\n",
    "For all three tests, if the p-value is less than 0.05, there is no significant difference.\n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # Append a page break at the end of the section\n",
    "    latex_methodology += \"\\\\newpage\\n\"\n",
    "\n",
    "    return latex_methodology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1192fa5-71dc-4047-89f5-3d8fdfb7553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Assume these global dictionaries exist:\n",
    "# normality_info_dict, metric_description, t_test_results, metric_image, protocol_image_location\n",
    "# Also assume figure_counter is initialized somewhere (e.g., figure_counter = 1)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Helper Functions (Placeholders)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def get_metric_image_file(image_path):\n",
    "    \"\"\"\n",
    "    Compresses and saves the image at image_path to a new file and returns the new filename.\n",
    "    \n",
    "    This is a placeholder for your image processing code.\n",
    "    \"\"\"\n",
    "    from PIL import Image as PILImage\n",
    "    # Create a compressed image filename based on the original filename.\n",
    "    path = Path(image_path)\n",
    "    basename = path.name.replace(\".png\", \"\") \n",
    "    parent = path.parent\n",
    "\n",
    "    current_path = Path.cwd()  # Call the function to get the current working directory\n",
    "    compressed_image_path = current_path / \"report_output\" / \"images\" / f\"{basename}.jpeg\"\n",
    "    \n",
    "    original_image = PILImage.open(image_path)\n",
    "    try:\n",
    "        original_image.save(compressed_image_path, \"JPEG\", quality=70)\n",
    "    except Exception:\n",
    "        original_image.save(compressed_image_path, \"PNG\")\n",
    "    return compressed_image_path\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# LaTeX Section Functions\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def dataset_description_latex(df, image_path, group_by=\"species\"):\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for a dataset description section that includes a\n",
    "    normality test report and boxplot plots for each numerical metric.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataset.\n",
    "        group_by (str): Column name to group data by (default is \"species\").\n",
    "        \n",
    "    Returns:\n",
    "        str: LaTeX code for the dataset description section.\n",
    "    \"\"\"\n",
    "    latex = \"\"\n",
    "    latex += \"\\\\section{Dataset Description}\\n\\n\"\n",
    "    \n",
    "    # Normality test subsection\n",
    "    latex += \"\\\\subsection{Normality Test}\\n\\n\"\n",
    "    latex += (\n",
    "        f\"Shapiro-Wilk p-values for \\\\textit{{C. kalinini}} population are \"\n",
    "        f\"{normality_info_dict['kalinini']:.2f}, and for \\\\textit{{C. resplendens}} population are \"\n",
    "        f\"{normality_info_dict['resplendens']:.2f}.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # boxplot plots subsection\n",
    "    latex += \"\\\\subsection{Boxplots for Each Metric}\\n\\n\"\n",
    "    \n",
    "    # Loop through all numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numeric_columns:\n",
    "        latex += f\"\\\\subsubsection*{{Metric {column}}}\\n\\n\"\n",
    "        desc = metric_description.get(column, \"No description available.\")\n",
    "        latex += desc + \"\\n\\n\"\n",
    "        \n",
    "        # Generate and save the boxplot plot image\n",
    "        \n",
    "        image_folder = Path(\"report_output\") /\"images\"\n",
    "        image_filename = image_folder / f\"boxplot_{column}.png\"\n",
    "        generate_boxplot_with_stripplot(df, column, group_by, image_filename)\n",
    "\n",
    "        image_location = Path(\"images\") / f\"boxplot_{column}.png\"\n",
    "        posix_image_filename = image_location.as_posix()\n",
    "        \n",
    "        # Include the image in a figure environment\n",
    "        latex += \"\\\\begin{figure}[H]\\n\\\\centering\\n\"\n",
    "        latex += f\"\\\\includegraphics[width=0.7\\\\linewidth]{{{posix_image_filename}}}\\n\"\n",
    "        latex += f\"\\\\caption{{Boxplot and specimen distribution (superposed) for the metric {column} by {group_by}}}\\n\"\n",
    "        latex += \"\\\\end{figure}\\n\\n\"\n",
    "    \n",
    "    latex += \"\\\\newpage\\n\"\n",
    "    return latex\n",
    "\n",
    "def Analysis_latex(df, figure_counter=1, group_by = \"species\"):\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for a statistical analysis section. For each metric in the\n",
    "    global t_test_results dictionary, it includes a boxplot plot, test details, and\n",
    "    optionally a metric image if available.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataset.\n",
    "        figure_counter (int): Starting figure counter (default is 1).\n",
    "        \n",
    "    Returns:\n",
    "        str: LaTeX code for the statistical analysis section.\n",
    "    \"\"\"\n",
    "    #species_under_consideration = [\"kalinini\",\"resplendens\"]\n",
    "    #df = df[df[\"species\"] ==species_under_consideration]\n",
    "    \n",
    "    latex = \"\"\n",
    "    latex += \"\\\\section{Statistical Analysis}\\n\\n\"\n",
    "    \n",
    "    for metric, result in t_test_results.items():\n",
    "        latex += f\"\\\\subsection*{{Metric: {metric}}}\\n\\n\"\n",
    "        desc = metric_description.get(metric, \"No description available.\")\n",
    "        latex += desc + \"\\n\\n\"\n",
    "        \n",
    "        # Generate and save the boxplot plot for the current metric\n",
    "        image_filename = Path(\"report_output\")/ \"images\" / \"boxplot\"/ f\"boxplot_{metric}.png\"\n",
    "        generate_boxplot_with_stripplot(df, metric, \"species\", image_filename)\n",
    "\n",
    "        image_location = Path(\"images\")/ \"boxplot\" / f\"boxplot_{metric}.png\"\n",
    "        posix_image_filename = image_location.as_posix()\n",
    "        print(posix_image_filename)\n",
    "        latex += \"\\\\begin{figure}[H]\\n\\\\centering\\n\"\n",
    "        latex += f\"\\\\includegraphics[width=0.7\\\\linewidth]{{{posix_image_filename}}}\\n\"\n",
    "        latex += f\"\\\\caption{{  Boxplot and specimen distribution (superposed) for the metric  {metric} by {group_by}}}\\n\"\n",
    "        latex += \"\\\\end{figure}\\n\\n\"\n",
    "        figure_counter += 1\n",
    "        \n",
    "        # Include test results as a series of bold labels and values\n",
    "        latex += \"\\\\noindent\\\\textbf{Test Type:} \" + result[\"test_type\"] + \" \\\\\\\\\\n\"\n",
    "        test_stat = result.get(\"t_stat\", result.get(\"u_stat\"))\n",
    "        latex += \"\\\\noindent\\\\textbf{Test Statistic:} \" + f\"{test_stat:.3f}\" + \" \\\\\\\\\\n\"\n",
    "        latex += \"\\\\noindent\\\\textbf{P-value:} \" + f\"{result[\"p_value\"]:.3f}\"+ \" \\\\\\\\\\n\"\n",
    "        latex += \"\\\\noindent\\\\textbf{Interpretation:} \" + result[\"interpretation\"] + \"\\n\\n\"\n",
    "        \n",
    "        # Optionally include a metric image if it exists and the metric name does not start with \"W\"\n",
    "        if (not metric.startswith(\"W\")) and (metric in metric_image):\n",
    "            # Build the image path and get the compressed image filename\n",
    "            image_path = Path(protocol_image_location) / metric_image[metric]\n",
    "            metric_img_file = get_metric_image_file(image_path)\n",
    "\n",
    "            metric_img_location = Path(\"images\")/\"protocol\"  / metric_image[metric]\n",
    "            latex += \"\\\\begin{figure}[H]\\n\\\\centering\\n\"\n",
    "            latex += f\"\\\\includegraphics[width=0.5\\\\linewidth]{{{metric_img_location.as_posix()}}}\\n\"\n",
    "            latex += f\"\\\\caption{{ Metric {metric}}}\\n\"\n",
    "            latex += \"\\\\end{figure}\\n\\n\"\n",
    "            figure_counter += 1\n",
    "        \n",
    "        latex += \"\\\\newpage\\n\"\n",
    "    \n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "300eb332-0c98-424b-9dd8-c7361893355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dataframe_to_latex_tables(df , unit = \"mm\"):\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame to a single LaTeX table with vertical dividers between columns,\n",
    "    horizontal lines above, below the header, and at the bottom, and a gray background for the header.\n",
    "    All numeric values are rounded to three decimals.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the complete LaTeX code for the table.\n",
    "    \"\"\"\n",
    "    # Round numeric values to three decimals\n",
    "    df_rounded = df.round(3)\n",
    "    \n",
    "    # Determine the number of columns and create a column format with vertical dividers.\n",
    "    n_cols = df_rounded.shape[1]\n",
    "    col_format = \"|\" + \"c|\" * n_cols\n",
    "\n",
    "    # Begin building the LaTeX table string.\n",
    "    latex_str = \"\\\\begin{table}[H]\\n\\\\centering\\n\"\n",
    "    latex_str += f\"\\\\begin{{tabular}}{{{col_format}}}\\n\"\n",
    "    \n",
    "    # Add top horizontal line.\n",
    "    latex_str += \"\\\\hline\\n\"\n",
    "\n",
    "    #Add units to every column \n",
    "    if unit:   \n",
    "        unit_str = f\"({unit})\"\n",
    "        keywords = [\"÷\", \"test\", \"p_value\", \"percentage\",\"percentual\", \"metric\"]\n",
    "        \n",
    "        def insert_units(lst, unit_str):\n",
    "            new_list = []\n",
    "            for element in lst:\n",
    "                if element == \"species\": #omit species\n",
    "                    new_list.append( f\"{element}\" )\n",
    "                    continue\n",
    "                if any(keyword in element for keyword in keywords):\n",
    "                    print(element)\n",
    "                    new_list.append(f\"{element}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    new_list.append( f\"{element} {unit_str}\" )\n",
    "            return new_list\n",
    "    \n",
    "        columns = insert_units(df_rounded.columns, unit_str)\n",
    "    else:\n",
    "        columns = df_rounded.columns\n",
    "    # Add header row with gray background.\n",
    "    # latex_str += \"\\\\rowcolor{gray!30}\\n\"\n",
    "    header_row = \" & \".join(columns) + \" \\\\\\\\ \\n\"\n",
    "    header_row = header_row.replace(\"_\", \"\\\\_\")\n",
    "    latex_str += header_row\n",
    "    \n",
    "    # Insert a horizontal line below the header.\n",
    "    latex_str += \"\\\\hline\\n\"\n",
    "    \n",
    "    # Add each data row.\n",
    "    for _, row in df_rounded.iterrows():\n",
    "        row_items = \" & \".join(str(item) for item in row)\n",
    "        latex_str += row_items + \" \\\\\\\\ \\n\"\n",
    "    \n",
    "    # Add a final horizontal line.\n",
    "    latex_str += \"\\\\hline\\n\"\n",
    "    \n",
    "    # End the tabular environment and the table.\n",
    "    latex_str += \"\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "    \n",
    "    return latex_str\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20ead670-fdcc-43d0-a07b-0325a5c42ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(lst, chunk_size=3):\n",
    "    \"\"\"Split lst into chunks of size chunk_size.\"\"\"\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b245a16b-546e-44a3-a9ca-dc849654ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_and_averages_for_each_metric(df, results_df):\n",
    "    using_millimiters = True\n",
    "    # Select only numeric columns\n",
    "    #numeric_cols = df.select_dtypes(include='number').columns\n",
    "    \n",
    "    significant_metrics = results_df.loc[results_df[\"significance\"] == \"significant\", \"metric\"].tolist()\n",
    "    list_of_lists = chunk_list(significant_metrics, chunk_size=2)\n",
    "    #print(list_of_lists)\n",
    "    \n",
    "    tables = []\n",
    "    for x in list_of_lists: \n",
    "        # Group by 'species' and compute mean and std for numeric columns\n",
    "        result = df.groupby('species')[x].agg(['mean', 'std'])\n",
    "        if using_millimiters:\n",
    "            result = result/1000 #convert to mm\n",
    "        #print(result)\n",
    "        \n",
    "        # Optionally flatten MultiIndex columns if desired\n",
    "        result.columns = ['_'.join(col).strip() for col in result.columns.values]\n",
    "        result = result.reset_index()\n",
    "        print(result.columns.values)\n",
    "       \n",
    "        \n",
    "        table = dataframe_to_latex_tables(result, unit = \"mm\")\n",
    "        tables += [table]\n",
    "    concat = \"\"\n",
    "    #concat += \"\\\\subsection{Standard deviation and average for each significant metric} \\n\"\n",
    "    for element in tables:\n",
    "        text = element\n",
    "        if not using_millimiters:\n",
    "            text = remove_decimals_from_latex(latex_text=element)  #si sse hace en micrómetros\n",
    "        concat += text\n",
    "    concat += \"\\n\"\n",
    "    return concat\n",
    "    #return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa614a03-9775-40f6-ad82-20425bf062eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric\n",
      "p_value\n",
      "percentual_diff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"For the non significant metrics, its range varies between 0.06 and 0.98.\\n \\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|}\\n\\\\hline\\nmetric & p\\\\_value & difference (mm) & percentual\\\\_diff \\\\\\\\ \\n\\\\hline\\nE1÷E2 & 0.06 & 0.01 & 15.59 \\\\\\\\ \\nF5 & 0.06 & 0.01 & 20.82 \\\\\\\\ \\nB3 & 0.1 & 0.05 & 98.88 \\\\\\\\ \\nB5 & 0.11 & 0.06 & 126.81 \\\\\\\\ \\nD1 & 0.15 & 0.1 & 209.36 \\\\\\\\ \\nA1 & 0.19 & 0.14 & 270.42 \\\\\\\\ \\nA4 & 0.23 & 0.18 & 365.0 \\\\\\\\ \\nB4 & 0.26 & 0.21 & 413.57 \\\\\\\\ \\nD3 & 0.26 & 0.21 & 419.19 \\\\\\\\ \\nD2÷D1 & 0.33 & 0.28 & 553.29 \\\\\\\\ \\nD3÷D1 & 0.37 & 0.32 & 640.19 \\\\\\\\ \\nC1 & 0.4 & 0.35 & 701.79 \\\\\\\\ \\nA4÷A3 & 0.51 & 0.46 & 921.8 \\\\\\\\ \\nD2 & 0.52 & 0.47 & 944.6 \\\\\\\\ \\nB4÷B1 & 0.58 & 0.53 & 1061.64 \\\\\\\\ \\nB4÷B2 & 0.61 & 0.56 & 1112.58 \\\\\\\\ \\nA5÷A3 & 0.69 & 0.64 & 1287.82 \\\\\\\\ \\nB4÷B3 & 0.8 & 0.75 & 1493.3 \\\\\\\\ \\nA1÷A3 & 0.89 & 0.84 & 1679.39 \\\\\\\\ \\nE2 & 0.94 & 0.89 & 1782.62 \\\\\\\\ \\nA5 & 0.98 & 0.93 & 1858.21 \\\\\\\\ \\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\\nThat means for some non significant metrics, its p value is very close to 0.05, suggesting that there is a possibility with\\n    more samples its difference could be significant. For these metrics further investigation is required: ['A1' 'A4' 'A5' 'B3' 'B4'].\\n\\n    \""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pvalue_analysis(df, results_df):\n",
    "    final_text = \"\"\n",
    "    subsection = \"\"\n",
    "    #subsection = \"\\\\subsection{P value analysis for non significant metrics} \\n\"\n",
    "    mean_of_pvalue = (results_df[results_df[\"significance\"]== \"non significant\" ][\"p_value\"].mean())\n",
    "    std_of_pvalue = (results_df[results_df[\"significance\"]== \"non significant\" ][\"p_value\"].std())\n",
    "    min_of_pvalue = (results_df[results_df[\"significance\"]== \"non significant\" ][\"p_value\"].min())\n",
    "    max_of_pvalue = (results_df[results_df[\"significance\"]== \"non significant\" ][\"p_value\"].max())\n",
    "    text_1 = f\"For the non significant metrics, its range varies between {min_of_pvalue:.2f} and {max_of_pvalue:.2f}.\\n \"\n",
    "    non_sig_df = results_df[results_df[\"significance\"]== \"non significant\" ][[\"metric\",\"p_value\"]]\n",
    "    #print(non_sig_df)\n",
    "    non_sig_df[\"difference\"] = non_sig_df[\"p_value\"] - 0.05\n",
    "    non_sig_df[\"percentual_diff\"] = non_sig_df[\"difference\"] /0.05 * 100\n",
    "    \n",
    "   \n",
    "   \n",
    "    m = non_sig_df[[\"metric\", \"p_value\", \"difference\", \"percentual_diff\"]].sort_values(by=\"percentual_diff\")\n",
    "    m = m.round(2)\n",
    "    table_text = dataframe_to_latex_tables(m)\n",
    "    #table = remove_decimals_from_latex(latex_text=table_text) \n",
    "    #print(text_1)\n",
    "    #print(text_2)\n",
    "    #print(m)\n",
    "    #print(table_text)\n",
    "    close_metrics = non_sig_df[\"metric\"].head(5).values\n",
    "    text_2 = f\"\"\"That means for some non significant metrics, its p value is very close to 0.05, suggesting that there is a possibility with\n",
    "    more samples its difference could be significant. For these metrics further investigation is required: {close_metrics}.\\n\n",
    "    \"\"\"\n",
    "    final_text += subsection\n",
    "    final_text += text_1\n",
    "    final_text += table_text\n",
    "    final_text += text_2\n",
    "    return final_text\n",
    "    \n",
    "pvalue_analysis(measurement_df_2, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21792503-b9b6-40de-b576-05802a3e152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables_latex(df, results_df):\n",
    "    text = \"\"\n",
    "    text += std_and_averages_for_each_metric(df, results_df)\n",
    "    text += r\"\\newpage\"\n",
    "    text += pvalue_analysis(df, results_df)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59b0ee9-d7b1-43b4-8a1c-1c80efd3f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['metric', 'normality_kalinini', 'normality_resplendens', 'normality',\n",
      "       'levene_pvalue', 'variance', 'test_type', 't_stat', 'p_value',\n",
      "       'interpretation', 'significance', 'u_stat'],\n",
      "      dtype='object')\n",
      "metric\n",
      "test_type\n",
      "p_value\n",
      "Index(['metric', 'normality_kalinini', 'normality_resplendens', 'normality',\n",
      "       'levene_pvalue', 'variance', 'test_type', 't_stat', 'p_value',\n",
      "       'interpretation', 'significance', 'u_stat'],\n",
      "      dtype='object')\n",
      "metric\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\\\onecolumngrid\\\\newpage\\n\\\\small\\\\centering\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\\n\\\\hline\\nmetric & normality\\\\_kalinini (mm) & normality\\\\_resplendens (mm) & normality (mm) & levene\\\\_pvalue (mm) & variance (mm) & test\\\\_type & t\\\\_stat (mm) & p\\\\_value \\\\\\\\ \\n\\\\hline\\nA1 & True & True & normal & 0.286 & equal & Student's t-test & -1.36 & 0.185 \\\\\\\\ \\nA2 & True & True & normal & 0.185 & equal & Student's t-test & -2.168 & 0.039 \\\\\\\\ \\nA3 & True & True & normal & 0.504 & equal & Student's t-test & -3.297 & 0.003 \\\\\\\\ \\nA4 & False & True & non normal & nan & different & Mann-Whitney U test & nan & 0.232 \\\\\\\\ \\nA5 & True & False & non normal & nan & different & Mann-Whitney U test & nan & 0.979 \\\\\\\\ \\nB1 & False & True & non normal & nan & different & Mann-Whitney U test & nan & 0.012 \\\\\\\\ \\nB2 & True & True & normal & 0.412 & equal & Student's t-test & -2.71 & 0.011 \\\\\\\\ \\nB3 & True & True & normal & 0.493 & equal & Student's t-test & -1.697 & 0.099 \\\\\\\\ \\nB4 & True & True & normal & 0.354 & equal & Student's t-test & -1.155 & 0.257 \\\\\\\\ \\nB5 & False & True & non normal & nan & different & Mann-Whitney U test & nan & 0.113 \\\\\\\\ \\nC1 & True & True & normal & 0.819 & equal & Student's t-test & 0.851 & 0.401 \\\\\\\\ \\nD1 & True & True & normal & 0.8 & equal & Student's t-test & -1.458 & 0.155 \\\\\\\\ \\nD2 & True & True & normal & 0.224 & equal & Student's t-test & -0.647 & 0.522 \\\\\\\\ \\nD3 & True & True & normal & 0.848 & equal & Student's t-test & -1.148 & 0.26 \\\\\\\\ \\nD4 & True & True & normal & 0.123 & equal & Student's t-test & -2.552 & 0.016 \\\\\\\\ \\nE1 & True & True & normal & 0.153 & equal & Student's t-test & -2.453 & 0.02 \\\\\\\\ \\nE2 & False & True & non normal & nan & different & Mann-Whitney U test & nan & 0.941 \\\\\\\\ \\nF1 & True & True & normal & 0.013 & different & Welch's t-test & -2.665 & 0.012 \\\\\\\\ \\nF2 & True & True & normal & 0.312 & equal & Student's t-test & -2.331 & 0.026 \\\\\\\\ \\nF3 & True & True & normal & 0.956 & equal & Student's t-test & -2.605 & 0.014 \\\\\\\\ \\nF4 & True & True & normal & 0.108 & equal & Student's t-test & -2.925 & 0.006 \\\\\\\\ \\nF5 & True & True & normal & 0.981 & equal & Student's t-test & -1.949 & 0.06 \\\\\\\\ \\nA1÷A3 & True & True & normal & 0.231 & equal & Student's t-test & 0.14 & 0.89 \\\\\\\\ \\nA4÷A3 & False & False & non normal & nan & different & Mann-Whitney U test & nan & 0.511 \\\\\\\\ \\nA5÷A3 & True & False & non normal & nan & different & Mann-Whitney U test & nan & 0.694 \\\\\\\\ \\nB4÷B1 & True & False & non normal & nan & different & Mann-Whitney U test & nan & 0.581 \\\\\\\\ \\nB4÷B2 & True & False & non normal & nan & different & Mann-Whitney U test & nan & 0.606 \\\\\\\\ \\nB4÷B3 & True & False & non normal & nan & different & Mann-Whitney U test & nan & 0.797 \\\\\\\\ \\nD2÷D1 & True & True & normal & 0.864 & equal & Student's t-test & 0.996 & 0.327 \\\\\\\\ \\nD3÷D1 & True & True & normal & 0.977 & equal & Student's t-test & 0.909 & 0.37 \\\\\\\\ \\nD4÷D2 & True & True & normal & 0.059 & equal & Student's t-test & -2.646 & 0.013 \\\\\\\\ \\nE1÷E2 & True & True & normal & 0.382 & equal & Student's t-test & -1.968 & 0.058 \\\\\\\\ \\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\\n\\n\\n\\\\normalsize \\\\newpage\\n\\\\small\\\\centering\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{|c|c|c|c|}\\n\\\\hline\\nmetric & interpretation (mm) & u\\\\_stat (mm) & significance (mm) \\\\\\\\ \\n\\\\hline\\nA1 & no significant difference & nan & non significant \\\\\\\\ \\nA2 & significant difference & nan & significant \\\\\\\\ \\nA3 & significant difference & nan & significant \\\\\\\\ \\nA4 & no significant difference & 46.0 & non significant \\\\\\\\ \\nA5 & no significant difference & 68.0 & non significant \\\\\\\\ \\nB1 & significant difference & 58.0 & significant \\\\\\\\ \\nB2 & significant difference & nan & significant \\\\\\\\ \\nB3 & no significant difference & nan & non significant \\\\\\\\ \\nB4 & no significant difference & nan & non significant \\\\\\\\ \\nB5 & no significant difference & 170.0 & non significant \\\\\\\\ \\nC1 & no significant difference & nan & non significant \\\\\\\\ \\nD1 & no significant difference & nan & non significant \\\\\\\\ \\nD2 & no significant difference & nan & non significant \\\\\\\\ \\nD3 & no significant difference & nan & non significant \\\\\\\\ \\nD4 & significant difference & nan & significant \\\\\\\\ \\nE1 & significant difference & nan & significant \\\\\\\\ \\nE2 & no significant difference & 124.0 & non significant \\\\\\\\ \\nF1 & significant difference & nan & significant \\\\\\\\ \\nF2 & significant difference & nan & significant \\\\\\\\ \\nF3 & significant difference & nan & significant \\\\\\\\ \\nF4 & significant difference & nan & significant \\\\\\\\ \\nF5 & no significant difference & nan & non significant \\\\\\\\ \\nA1÷A3 & no significant difference & nan & non significant \\\\\\\\ \\nA4÷A3 & no significant difference & 56.0 & non significant \\\\\\\\ \\nA5÷A3 & no significant difference & 77.0 & non significant \\\\\\\\ \\nB4÷B1 & no significant difference & 142.0 & non significant \\\\\\\\ \\nB4÷B2 & no significant difference & 141.0 & non significant \\\\\\\\ \\nB4÷B3 & no significant difference & 134.0 & non significant \\\\\\\\ \\nD2÷D1 & no significant difference & nan & non significant \\\\\\\\ \\nD3÷D1 & no significant difference & nan & non significant \\\\\\\\ \\nD4÷D2 & significant difference & nan & significant \\\\\\\\ \\nE1÷E2 & no significant difference & nan & non significant \\\\\\\\ \\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\\n\\n\\n\\\\normalsize \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result_summary(results_df):\n",
    "    text = r\"\\onecolumngrid\"\n",
    "    text += r\"\\newpage\"\n",
    "    text += \"\\n\"\n",
    "    text += r\"\\small\"\n",
    "    #text += r\"\\begin{sidewaystable}[H]\"\n",
    "    text += r\"\\centering\"\n",
    "    print(results_df.columns)\n",
    "    text += dataframe_to_latex_tables(results_df[['metric', 'normality_kalinini', 'normality_resplendens', 'normality',\n",
    "       'levene_pvalue', 'variance', 'test_type', 't_stat', 'p_value']])   \n",
    "    text += \"\\n\" \n",
    "    #text += r\"\\end{sidewaystable}\"\n",
    "    text += \"\\n\"\n",
    "    text += r\"\\normalsize \"\n",
    "    \n",
    "    text += r\"\\newpage\"\n",
    "    text += \"\\n\"\n",
    "    text += r\"\\small\"\n",
    "    #text += r\"\\begin{sidewaystable}[H]\"\n",
    "    text += r\"\\centering\"\n",
    "    print(results_df.columns)\n",
    "    text += dataframe_to_latex_tables(results_df[['metric','interpretation', 'u_stat', 'significance']])   \n",
    "    text += \"\\n\" \n",
    "    #text += r\"\\end{sidewaystable}\"\n",
    "    text += \"\\n\"\n",
    "    text += r\"\\normalsize \"\n",
    "    return text\n",
    "result_summary(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "718beca5-8e9e-4fdc-a370-66c138df06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_preamble():\n",
    "    \"\"\"\n",
    "    Generates a LaTeX preamble that includes all required packages and settings.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the LaTeX preamble and beginning of the document.\n",
    "    \"\"\"\n",
    "    preamble = r\"\"\"\n",
    "\n",
    "% Input encoding\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\n",
    "% Language (optional; adjust if needed)\n",
    "\\usepackage[english]{babel}\n",
    "\n",
    "% For graphics inclusion\n",
    "\\usepackage{graphicx}\n",
    "\n",
    "% For controlling float placement (e.g. [H] for figures and tables)\n",
    "\\usepackage{float}\n",
    "\n",
    "% For nicer tables (booktabs for horizontal lines, xcolor for coloring)\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage[table]{xcolor}\n",
    "\n",
    "% Adjust margins (optional)\n",
    "\\usepackage[margin=1in]{geometry}\n",
    "\n",
    "% For hyperlinks (optional)\n",
    "\\usepackage{hyperref}\n",
    "\n",
    "% For improved font rendering (optional)\n",
    "\\usepackage{lmodern}\n",
    "\n",
    "\n",
    "% --------------------------\n",
    "% You can now include sections, figures, tables, etc.\n",
    "% --------------------------\n",
    "\"\"\"\n",
    "    return preamble\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da7e3a94-745c-44c8-ad41-6197cd8761c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>...</th>\n",
       "      <th>A1÷A3</th>\n",
       "      <th>A4÷A3</th>\n",
       "      <th>A5÷A3</th>\n",
       "      <th>B4÷B1</th>\n",
       "      <th>B4÷B2</th>\n",
       "      <th>B4÷B3</th>\n",
       "      <th>D2÷D1</th>\n",
       "      <th>D3÷D1</th>\n",
       "      <th>D4÷D2</th>\n",
       "      <th>E1÷E2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cupreomarginata</th>\n",
       "      <td>4039.822500</td>\n",
       "      <td>3546.723750</td>\n",
       "      <td>4507.655000</td>\n",
       "      <td>1992.433750</td>\n",
       "      <td>1530.982500</td>\n",
       "      <td>5273.870000</td>\n",
       "      <td>7510.032500</td>\n",
       "      <td>8050.698750</td>\n",
       "      <td>4812.461250</td>\n",
       "      <td>153.568750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897067</td>\n",
       "      <td>0.442298</td>\n",
       "      <td>0.339964</td>\n",
       "      <td>0.912445</td>\n",
       "      <td>0.640930</td>\n",
       "      <td>0.597830</td>\n",
       "      <td>0.498265</td>\n",
       "      <td>1.434794</td>\n",
       "      <td>1.203349</td>\n",
       "      <td>0.636558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalinini</th>\n",
       "      <td>4002.656667</td>\n",
       "      <td>3609.385000</td>\n",
       "      <td>4608.270000</td>\n",
       "      <td>1658.206667</td>\n",
       "      <td>1854.680000</td>\n",
       "      <td>5490.752727</td>\n",
       "      <td>8238.267273</td>\n",
       "      <td>8718.554545</td>\n",
       "      <td>5458.398182</td>\n",
       "      <td>151.621818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868765</td>\n",
       "      <td>0.359353</td>\n",
       "      <td>0.403076</td>\n",
       "      <td>0.994060</td>\n",
       "      <td>0.662431</td>\n",
       "      <td>0.626180</td>\n",
       "      <td>0.562978</td>\n",
       "      <td>1.862876</td>\n",
       "      <td>1.062452</td>\n",
       "      <td>0.612242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resplendens</th>\n",
       "      <td>4161.616087</td>\n",
       "      <td>3772.468261</td>\n",
       "      <td>4810.819565</td>\n",
       "      <td>1789.721304</td>\n",
       "      <td>1846.759565</td>\n",
       "      <td>5679.961304</td>\n",
       "      <td>8561.340870</td>\n",
       "      <td>8984.585217</td>\n",
       "      <td>5585.811304</td>\n",
       "      <td>148.978261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865372</td>\n",
       "      <td>0.371797</td>\n",
       "      <td>0.383791</td>\n",
       "      <td>0.983549</td>\n",
       "      <td>0.652590</td>\n",
       "      <td>0.622042</td>\n",
       "      <td>0.542486</td>\n",
       "      <td>1.807503</td>\n",
       "      <td>1.226800</td>\n",
       "      <td>0.688782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          A1           A2           A3           A4  \\\n",
       "species                                                               \n",
       "cupreomarginata  4039.822500  3546.723750  4507.655000  1992.433750   \n",
       "kalinini         4002.656667  3609.385000  4608.270000  1658.206667   \n",
       "resplendens      4161.616087  3772.468261  4810.819565  1789.721304   \n",
       "\n",
       "                          A5           B1           B2           B3  \\\n",
       "species                                                               \n",
       "cupreomarginata  1530.982500  5273.870000  7510.032500  8050.698750   \n",
       "kalinini         1854.680000  5490.752727  8238.267273  8718.554545   \n",
       "resplendens      1846.759565  5679.961304  8561.340870  8984.585217   \n",
       "\n",
       "                          B4          B5  ...     A1÷A3     A4÷A3     A5÷A3  \\\n",
       "species                                   ...                                 \n",
       "cupreomarginata  4812.461250  153.568750  ...  0.897067  0.442298  0.339964   \n",
       "kalinini         5458.398182  151.621818  ...  0.868765  0.359353  0.403076   \n",
       "resplendens      5585.811304  148.978261  ...  0.865372  0.371797  0.383791   \n",
       "\n",
       "                    B4÷B1     B4÷B2     B4÷B3     D2÷D1     D3÷D1     D4÷D2  \\\n",
       "species                                                                       \n",
       "cupreomarginata  0.912445  0.640930  0.597830  0.498265  1.434794  1.203349   \n",
       "kalinini         0.994060  0.662431  0.626180  0.562978  1.862876  1.062452   \n",
       "resplendens      0.983549  0.652590  0.622042  0.542486  1.807503  1.226800   \n",
       "\n",
       "                    E1÷E2  \n",
       "species                    \n",
       "cupreomarginata  0.636558  \n",
       "kalinini         0.612242  \n",
       "resplendens      0.688782  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47f0a8ab-a333-4f1b-ae2f-fc89e9acf137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>D4</th>\n",
       "      <th>E1</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>D4÷D2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cupreomarginata</th>\n",
       "      <td>3546.723750</td>\n",
       "      <td>4507.655000</td>\n",
       "      <td>5273.870000</td>\n",
       "      <td>7510.032500</td>\n",
       "      <td>689.930000</td>\n",
       "      <td>415.872500</td>\n",
       "      <td>1447.683750</td>\n",
       "      <td>1481.271250</td>\n",
       "      <td>1538.331250</td>\n",
       "      <td>1971.521250</td>\n",
       "      <td>1.203349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalinini</th>\n",
       "      <td>3609.385000</td>\n",
       "      <td>4608.270000</td>\n",
       "      <td>5490.752727</td>\n",
       "      <td>8238.267273</td>\n",
       "      <td>732.170909</td>\n",
       "      <td>503.520000</td>\n",
       "      <td>1402.484000</td>\n",
       "      <td>1397.500000</td>\n",
       "      <td>1451.600000</td>\n",
       "      <td>1935.343000</td>\n",
       "      <td>1.062452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resplendens</th>\n",
       "      <td>3772.468261</td>\n",
       "      <td>4810.819565</td>\n",
       "      <td>5679.961304</td>\n",
       "      <td>8561.340870</td>\n",
       "      <td>859.733478</td>\n",
       "      <td>576.953043</td>\n",
       "      <td>1464.046087</td>\n",
       "      <td>1475.331739</td>\n",
       "      <td>1537.430435</td>\n",
       "      <td>2184.256087</td>\n",
       "      <td>1.226800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          A2           A3           B1           B2  \\\n",
       "species                                                               \n",
       "cupreomarginata  3546.723750  4507.655000  5273.870000  7510.032500   \n",
       "kalinini         3609.385000  4608.270000  5490.752727  8238.267273   \n",
       "resplendens      3772.468261  4810.819565  5679.961304  8561.340870   \n",
       "\n",
       "                         D4          E1           F1           F2  \\\n",
       "species                                                             \n",
       "cupreomarginata  689.930000  415.872500  1447.683750  1481.271250   \n",
       "kalinini         732.170909  503.520000  1402.484000  1397.500000   \n",
       "resplendens      859.733478  576.953043  1464.046087  1475.331739   \n",
       "\n",
       "                          F3           F4     D4÷D2  \n",
       "species                                              \n",
       "cupreomarginata  1538.331250  1971.521250  1.203349  \n",
       "kalinini         1451.600000  1935.343000  1.062452  \n",
       "resplendens      1537.430435  2184.256087  1.226800  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "significant_results = results_df.loc[results_df[\"significance\"] == \"significant\", \"metric\"].to_list()\n",
    "significant_metrics_df = aggregated_mean[significant_results]\n",
    "non_significant_results = results_df.loc[results_df[\"significance\"] != \"significant\", \"metric\"].to_list()\n",
    "non_significant_metrics_df = aggregated_mean[significant_results]\n",
    "significant_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5a2506-1957-4492-833e-ccd6ff73150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the metric A2 C. kalinini has an average of 3.61 $mm$ and a standard deviation of  0.12 $mm$. C. resplendens has an average of 3.77 $mm$ and a standard deviation of  0.17 $mm$. The difference between species is statiscally significant\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metric_significance_description(metric, mean_df, std_df, significance, unit = \"\"):\n",
    "    text = \"\"\n",
    "    species = [\"kalinini\", \"resplendens\"]\n",
    "    #print(species)\n",
    "    text += f\"For the metric {metric} \"\n",
    "    unit = \"mm\"\n",
    "    \n",
    "    for sp in species:\n",
    "        average = mean_df.loc[sp, metric]\n",
    "        std = std_df.loc[sp, metric]\n",
    "        average_mm = average/1000\n",
    "        std_mm = std/1000\n",
    "        txt = f\"C. {sp} has an average of {average_mm:.2f} ${unit}$ and a standard deviation of  {std_mm:.2f} ${unit}$. \" #{std_mm:.1e}\n",
    "        text += txt\n",
    "    text += f\"The difference between species is {significance}\\n\"\n",
    "    return text\n",
    "metric_significance_description(metric = \"A2\", mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1f830c6-798a-47d7-bd4c-9ba3f058a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion_latex(df):\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for the conclusion section.\n",
    "    \n",
    "    This section includes:\n",
    "      - A subsection heading for the comparison with Zubov et al. claims.\n",
    "      - Several claims with italicized and normal text.\n",
    "      - A page break after the claims.\n",
    "      - A comparative table (generated from the DataFrame).\n",
    "      - A final page break.\n",
    "      \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame to be used for generating the comparative table.\n",
    "        \n",
    "    Returns:\n",
    "        str: LaTeX code for the conclusion section.\n",
    "    \"\"\"\n",
    "    latex = \"\"\n",
    "    \n",
    "    # Comparison heading\n",
    "    latex += \"\\\\subsection{Comparison with Zubov et al. claims}\\n\\n\"\n",
    "    \n",
    "    # Claim 1\n",
    "    latex += \"\\\\subsubsection*{Claim 1}\\n\"\n",
    "    latex += \"\\\\textit{The new species is very close to \\\\textit{C. resplendens} and has only few morphological differences from it. \"\n",
    "    latex += \"Clypeus of \\\\textit{C. kalinini sp.n.} is slightly longer than in \\\\textit{C. resplendens}.}\\n\\n\"\n",
    "    latex += \"Head's vertical clipeus length, \\\\textbf{A5}, shows a statistically significant difference. \"\n",
    "    #latex += metric_significance_description(metric = \"A5\", mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")\n",
    "    #latex += metric_significance_description(metric = \"A3\", mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")\n",
    "    #latex += \"These can be used as alternatives to \\\\textbf{A1÷A3}.\\n\\n\"\n",
    "    \n",
    "    # Claim 2\n",
    "    latex += \"\\\\subsubsection*{Claim 2}\\n\"\n",
    "    latex += \"\\\\textit{Pronotum in \\\\textit{C. kalinini sp.n.} is slightly longer in relation to its width than in \\\\textit{C. resplendens}, its sides have smaller angles, whereas in \\\\textit{C. resplendens} the sides of pronotum are rounded.}\\n\\n\"\n",
    "    latex += \"None of the pronotum's vertical length---horizontal width ratios (Metrics \\\\textbf{B4÷B1}, \\\\textbf{B4÷B2}, \\\\textbf{B4÷B3}) showed a significant difference between species.\\n\\n\"\n",
    "    latex += metric_significance_description(metric = \"B1\", mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")\n",
    "    latex += metric_significance_description(metric = \"B2\", mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")\n",
    "    latex += \"The angle of the pronotum, as seen from its side (C1), has no significant difference between species.\"\n",
    "    latex += \"The angle of the pronotum, or as seen from the top (B5), has no significant difference between species.\"\n",
    "    \n",
    "    # Claim 3\n",
    "    latex += \"\\\\subsubsection*{Claim 3}\\n\"\n",
    "    latex += \"\\\\textit{Mesosternal process shiny, shorter and wider than in \\\\textit{C. resplendens}, where the process is long and narrow and its \"\n",
    "    latex += \"apical half is greenish golden (Fig. 6--8).}\\n\\n\"\n",
    "    latex += \"The first approach is to interpret the claim as a statement about the width-length ratio of the mesosternal process. \\n\\n\"\n",
    "    latex += \"The vertical length base width ratio, \\\\textbf{D3÷D1},  is not statistically significant \\n\\n\"\n",
    "    latex += \"The vertical length down to the vertex of the dark stripe of the mesosternal process- horizontal length of the dark stripe, \\\\textbf{D4÷D2}\\n\\n, is not statistically significant.\"\n",
    "    \n",
    "    latex += \"There is a significant difference in  the absolute vertical length values between the two species (Metric \\\\textbf{D2}, Figure 23). \"\n",
    "    latex += \"There is no significant difference in their widths (Metrics \\\\textbf{D1} and \\\\textbf{D3}). \"\n",
    "    latex += \"There is a significant difference between species in the vertical distance between the tip of the mesosternal process and the lower point of the dark curve in its middle.\\n\\n\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Claim 4\n",
    "    latex += \"\\\\subsubsection*{Claim 4}\\n\"\n",
    "    latex += \"\\\\textit{Prosternal plate of \\\\textit{C. kalinini sp.n.} is rounded triangular and flat, whereas in \\\\textit{C. resplendens} it is square and has a clear dent.}\\n\\n\"\n",
    "    latex += \"Although there is a difference between the absolute values of the foremost width of the prosternal process (Metric \\\\textbf{E1}, Figure 29), \"\n",
    "    latex += \"there is no significant difference in how square the prosternal plate is for each species when the ratio of lengths is taken into account \"\n",
    "    latex += \"(Metric \\\\textbf{E1÷E2}, ratio between \\\\textbf{E1} and \\\\textbf{E2}; Figure 51).\\n\\n\"\n",
    "\n",
    "    # other metrics\n",
    "    latex += \"\\\\subsubsection*{Other metrics}\\n\"\n",
    "    latex += \"Other metrics of interest, not directly related to any of Zubov et al's claims are the following:\\n\\n\"\n",
    "    for metric in [\"D4\",\"E1\",\"F1\",\"F2\",\"F3\",\"F4\"]:\n",
    "        \n",
    "        latex += metric_significance_description(metric = metric, mean_df = aggregated_mean, std_df = aggregated_std, significance = \"statiscally significant\", unit=\"\\\\mu m\")\n",
    "        latex += \"\\n\\n\"\n",
    "    # Insert a page break after the claims\n",
    "    latex += \"\\\\newpage\\n\\n\"\n",
    "    \n",
    "    # Comparative table heading\n",
    "    latex += \"\\\\subsection{A word of caution}\\n\\n\"\n",
    "    latex += \"Even though there are multiple significant metrics, all of them are unfeasible to be used in the field given that most of these differences are of less than 1 mm in length.:\\n\\n\"\n",
    "    # Generate LaTeX tables from the DataFrame.\n",
    "    # This assumes that you have a function 'dataframe_to_latex_tables' that returns a list of table strings.\n",
    "    #tables = dataframe_to_latex_tables(df)\n",
    "    #for table in tables:\n",
    "    #    latex += table + \"\\n\"\n",
    "    \n",
    "    # Final page break\n",
    "    latex += \"\\\\newpage\\n\\n\"\n",
    "    \n",
    "    return latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5236c8f-067f-476f-8f6f-6d013329a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bib_file():\n",
    "    bib_content = \"\"\"@article{zubov2019chrysina,\n",
    "  author = {A.S. Zubov and N.V. Ivshin and A. Yu. Titarenko and B.V. Andrianov},\n",
    "  title = {Description of a new species of Chrysina Kirby, 1828 (Coleoptera: Scarabaeidae: Rutelinae) from resplendens group, based on morphological characters and mtDNA COX I molecular marker},\n",
    "  journal = {Acta Biologica Sibirica},\n",
    "  year = {2019},\n",
    "  volume = {5},\n",
    "  number = {1},\n",
    "  pages = {71--76},\n",
    "  issn = {2412-1908},\n",
    "  doi = {10.14258/abs.v5.i1.5194}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%\n",
    "% Below is a list of possible bibliography entries along with their required and optional fields\n",
    "%    Taken from the wikipedia entry for BibTeX at http://en.wikipedia.wiki/BibTeX 19-Nov-2007\n",
    "%\n",
    "%\n",
    "%\n",
    "\n",
    "%article\n",
    "%    An article from a journal or magazine.\n",
    "%    Required fields: author, title, journal, year\n",
    "%    Optional fields: volume, number, pages, month, note, key\n",
    "%book\n",
    "%    A book with an explicit publisher.\n",
    "%    Required fields: author/editor, title, publisher, year\n",
    "%    Optional fields: volume, series, address, edition, month, note, key\n",
    "%booklet\n",
    "%    A work that is printed and bound, but without a named publisher or sponsoring institution.\n",
    "%    Required fields: title\n",
    "%    Optional fields: author, howpublished, address, month, year, note, key\n",
    "%conference\n",
    "%    The same as inproceedings, included for Scribe (markup language) compatibility.\n",
    "%    Required fields: author, title, booktitle, year\n",
    "%    Optional fields: editor, pages, organization, publisher, address, month, note, key\n",
    "%inbook\n",
    "%    A part of a book, which may be a chapter (or section or whatever) and/or a range of pages.\n",
    "%    Required fields: author/editor, title, chapter/pages, publisher, year\n",
    "%    Optional fields: volume, series, address, edition, month, note, key\n",
    "%incollection\n",
    "%    A part of a book having its own title.\n",
    "%   Required fields: author, title, booktitle, year\n",
    "%    Optional fields: editor, pages, organization, publisher, address, month, note, key\n",
    "%inproceedings\n",
    "%    An article in a conference proceedings.\n",
    "%    Required fields: author, title, booktitle, year\n",
    "%    Optional fields: editor, pages, organization, publisher, address, month, note, key\n",
    "%manual\n",
    "%    Technical documentation.\n",
    "%    Required fields: title\n",
    "%    Optional fields: author, organization, address, edition, month, year, note, key\n",
    "%mastersthesis\n",
    "%    A Master's thesis.\n",
    "%    Required fields: author, title, school, year\n",
    "%    Optional fields: address, month, note, key\n",
    "%misc\n",
    "%    For use when nothing else fits.\n",
    "%    Required fields: none\n",
    "%    Optional fields: author, title, howpublished, month, year, note, key\n",
    "%phdthesis\n",
    "%    A Ph.D. thesis.\n",
    "%    Required fields: author, title, school, year\n",
    "%    Optional fields: address, month, note, key\n",
    "%proceedings\n",
    "%    The proceedings of a conference.\n",
    "%    Required fields: title, year\n",
    "%    Optional fields: editor, publisher, organization, address, month, note, key\n",
    "%techreport\n",
    "%    A report published by a school or other institution, usually numbered within a series.\n",
    "%    Required fields: author, title, institution, year\n",
    "%    Optional fields: type, number, address, month, note, key\n",
    "%unpublished\n",
    "%   A document having an author and title, but not formally published.\n",
    "%    Required fields: author, title, note\n",
    "%    Optional fields: month, year, key\n",
    "\"\"\"\n",
    "    with open(r\"report_output/ref.bib\", \"w\") as bib_file:\n",
    "        bib_file.write(bib_content)\n",
    "    print(\"BibTeX file 'ref.bib' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6795cc6-fc62-423b-baa9-2ab710586a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX bibliography generated as 'bibliography.tex'.\n"
     ]
    }
   ],
   "source": [
    "def create_bibliography_latex():\n",
    "    \"\"\"\n",
    "    Generates LaTeX code for a bibliography (references) section.\n",
    "    \n",
    "    Returns:\n",
    "        str: LaTeX code for the bibliography.\n",
    "    \"\"\"\n",
    "    latex = \"\"\n",
    "    \n",
    "    # Create an unnumbered section for References.\n",
    "    latex += \"\\\\section*{References}\\n\\n\"\n",
    "    \n",
    "    # Begin an enumerated list of references.\n",
    "    latex += \"\\\\begin{enumerate}\\n\"\n",
    "    \n",
    "    # Reference 1\n",
    "    latex += (\"  \\\\item Zubov, A.S.; Ivshin, N.V.; Titarenko, A.Y.; Andrianov, B.V. (2019). Description of a new species of \"\n",
    "              \"Chrysina Kirby, 1828 (Coleoptera: Scarabaeidae: Rutelinae) from the resplendens group, based on morphological characters \"\n",
    "              \"and mtDNA COX I molecular marker. \\\\textit{Acta Biologica Sibirica}, 5(1), 71--76.\\n\")\n",
    "    \n",
    "    # Additional references can be added here.\n",
    "    # latex += \"  \\\\item Author B, et al. (Year). Title of the paper. Journal Name, Volume(Issue), Page Numbers.\\n\"\n",
    "    \n",
    "    latex += \"\\\\end{enumerate}\\n\"\n",
    "    \n",
    "    # Optionally, add some vertical space after the bibliography.\n",
    "    latex += \"\\n\\\\vspace{1cm}\\n\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "# --- Example usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    bib_code = create_bibliography_latex()\n",
    "    with open(\"bibliography.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(bib_code)\n",
    "    print(\"LaTeX bibliography generated as 'bibliography.tex'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83fdca53-5038-44e2-b959-6664b15cf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_main_latex():\n",
    "    latex_code = r\"\"\"\n",
    "%\\documentclass[aps,twocolumn,secnumarabic,nobalancelastpage,amsmath,amssymb,nofootinbib]{revtex4}\n",
    "\\documentclass[aps,secnumarabic,nobalancelastpage,amsmath,amssymb,nofootinbib]{revtex4}\n",
    "\\usepackage{gensymb} \n",
    "\\usepackage{multirow}\n",
    "\\usepackage{graphics}      \n",
    "\\usepackage{graphicx}      \n",
    "\\usepackage{longtable}     \n",
    "\\usepackage{url}           \n",
    "\\usepackage{bm}            \n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{comment}\n",
    "\\usepackage{pdflscape}\n",
    "\\usepackage{rotating}\n",
    "\n",
    "\\usepackage[letterpaper,top= 2.75cm,bottom=3.5cm,left=1.8cm,right=1.8cm]{geometry}\n",
    "\\usepackage{ifsym}                        \n",
    "\\usepackage{amssymb}                      \n",
    "\\usepackage{amsmath}                      \n",
    "\\usepackage{amsthm}                       \n",
    "\\usepackage{color}                        \n",
    "\\usepackage{multienum}                    \n",
    "\\usepackage{tabularx}                     \n",
    "\\usepackage{booktabs}                     \n",
    "\\usepackage{fancyhdr}\n",
    "\\usepackage{pgf}\n",
    "\\usepackage{tikz}\n",
    "\\tikzstyle{guiones}+=[dashed]\n",
    "\\usetikzlibrary{patterns,arrows,snakes,shapes,automata,plotmarks,backgrounds}\n",
    "\\usepackage{lscape}\n",
    "\\usepackage{titlesec}\n",
    "\\usepackage{array,ragged2e}\n",
    "\\newcolumntype{P}[1]{>{\\RaggedRight\\arraybackslash}p{#1}}\n",
    "\\usepackage{float}\n",
    "\\usepackage{placeins}\n",
    "\\usepackage{pdfpages} % Required for including PDF files\n",
    "\n",
    "\\setlength{\\columnsep}{7.5mm} \n",
    "\\titleformat*{\\section}{\\normalsize\\bfseries}\n",
    "\\titleformat*{\\subsection}{\\normalsize\\bfseries}  \n",
    "\n",
    "\\def\\bibsection{\\section*{\\refname}} \n",
    "\\usepackage[pdfborder={0 0 0},colorlinks=false]{hyperref}\n",
    "\\usepackage{xurl} \n",
    "\\usepackage{adjustbox}\n",
    "\\usepackage{titlesec}\n",
    "\n",
    "% Cambiar tamaño de letra manteniendo la negrita\n",
    "\\titleformat{\\section}\n",
    "  {\\normalfont\\large\\bfseries}  % Negrita y tamaño grande\n",
    "  {\\thesection}{1em}{}\n",
    "\n",
    "\\titleformat{\\subsection}\n",
    "  {\\normalfont\\large\\bfseries}  % Negrita y tamaño mediano\n",
    "  {\\thesubsection}{1em}{}\n",
    "\n",
    "\\titleformat{\\subsubsection}\n",
    "  {\\normalfont\\fontsize{11}{14}\\selectfont\\bfseries\\itshape}  % Negrita y tamaño normal\n",
    "  {\\thesubsubsection}{1em}{}\n",
    "\n",
    "\\usepackage{hyperref}\n",
    "\n",
    "\\newcommand{\\displayboxplot}[1]{%\n",
    "    \\begin{figure}[H]\n",
    "        \\centering\n",
    "        \\includegraphics[trim=0cm 0cm 0cm 0.9cm, clip, width=0.9\\linewidth]{images/boxplot/boxplot_#1.png}\n",
    "        \\vspace{-0.4cm}\n",
    "        \\caption{Boxplot and specimen distribution (superposed) for the metric $#1$, by species.}\n",
    "    \\end{figure}\n",
    "}\n",
    "%Para los ratios, el comando displayboxplot hará mal la caption (por los $$, pero me parecen necesarios), no es imposible de arreglar, pero tampoco hay tantos ratios.\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "{\\begin{flushleft}\n",
    "\\vskip-25pt \n",
    "{\\includegraphics[width = 0.15\\textwidth]{images/escudos/firma-promocional-con-texto-negro.png}}\n",
    "\\end{flushleft}}\n",
    "\n",
    "\\title{{\\Large Biometry report}}\n",
    "\\author{Dra. Marcela Hernández}\n",
    "\\author{Dr. Esteban Bermúdez Ureña}\n",
    "\\author{Esteban Soto}\n",
    "\\author{Ángel Aguirre}\n",
    "\\email{marcela.hernandezjimenez@ucr.ac.cr}\n",
    "\\email{esteban.bermudezurena@ucr.ac.cr}\n",
    "\\email{esteban.sotomonge@ucr.ac.cr}\n",
    "\\email{angel.aguirre@ucr.ac.cr}\n",
    "\n",
    "%Hay que mejorar como se ven los correos\n",
    "\n",
    "\\affiliation{Centro de Investigación en Ciencia e Ingeniería de los Materiales, Universidad de Costa Rica}\n",
    "\\date{\\today} \n",
    "\n",
    "\\input{Abstract}\n",
    "\n",
    "\\maketitle\n",
    "\\newpage\n",
    "%\\input{Introduction}\n",
    "\n",
    "%\\input{Methodology}\n",
    "\n",
    "%\\input{Analysis}\n",
    "\n",
    "%\\input{Claims}\n",
    "%\\newpage\n",
    "\\input{Tables}\n",
    "%\\input{Results}\n",
    "\n",
    "\\bibliographystyle{apsrev4-1}\n",
    "\\bibliographystyle{plain}\n",
    "\\bibliography{ref}\n",
    "\n",
    "%\\section{Anexos}\n",
    "%\\appendix\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    return latex_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa2ceb2b-5728-403a-9c82-831b55aa2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abstract_latex():\n",
    "    text = r\"\"\"\"\\begin{abstract}\n",
    "Zubov et al. (2019)\\cite{zubov2019chrysina} describe a new species of Chrysina. In their comparative analysis and remarks, it is stated that the new species is very similar to C. resplendens, with only a few morphological differences being noted. This study aims to perform a quantitative analysis of these differences using a sample of 11 C. kalinini specimens and 23 C. resplendens specimens. The measurements described in the article are specified with greater precision, and alternative metrics are analyzed. Furthermore, the claims made in the mentioned paper are reviewed, assessing their validity and exploring new methods for differentiating the two beetle species with striking similarities.\n",
    "\\end{abstract}\"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e023961-76b8-4b30-bc4b-787ca9c43edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_51c33\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_51c33_level0_col0\" class=\"col_heading level0 col0\" >A</th>\n",
       "      <th id=\"T_51c33_level0_col1\" class=\"col_heading level0 col1\" >B</th>\n",
       "      <th id=\"T_51c33_level0_col2\" class=\"col_heading level0 col2\" >C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_51c33_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_51c33_row0_col0\" class=\"data row0 col0\" >123.5</td>\n",
       "      <td id=\"T_51c33_row0_col1\" class=\"data row0 col1\" >0.001234</td>\n",
       "      <td id=\"T_51c33_row0_col2\" class=\"data row0 col2\" >5.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51c33_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_51c33_row1_col0\" class=\"data row1 col0\" >2346</td>\n",
       "      <td id=\"T_51c33_row1_col1\" class=\"data row1 col1\" >123.5</td>\n",
       "      <td id=\"T_51c33_row1_col2\" class=\"data row1 col2\" >34.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51c33_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_51c33_row2_col0\" class=\"data row2 col0\" >34570</td>\n",
       "      <td id=\"T_51c33_row2_col1\" class=\"data row2 col1\" >789</td>\n",
       "      <td id=\"T_51c33_row2_col2\" class=\"data row2 col2\" >123.456000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1aa18f59340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def set_significant_figures(df, columns, sig_figs):\n",
    "    \"\"\"\n",
    "    Set a specified number of significant figures for certain columns in a pandas DataFrame\n",
    "    and apply formatting to the display, ensuring no scientific notation is used.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - columns (list): List of column names to format.\n",
    "    - sig_figs (int): The number of significant figures.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with the modified values and formatted display.\n",
    "    \"\"\"\n",
    "    # Function to round the values based on significant figures\n",
    "    def round_sig(x, sig):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return round(x, sig - int(np.floor(np.log10(abs(x)))) - 1)\n",
    "\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply rounding to the specified columns\n",
    "    for column in columns:\n",
    "        if column in df_copy.columns:\n",
    "            df_copy[column] = df_copy[column].apply(lambda x: round_sig(x, sig_figs))\n",
    "\n",
    "    # Apply the formatting for display purposes\n",
    "    def format_cell(val):\n",
    "        # Use fixed-point notation without unnecessary decimals\n",
    "        if isinstance(val, (int, float)):\n",
    "            # Remove unnecessary decimal places\n",
    "            return f\"{val:.{sig_figs}g}\".rstrip('0').rstrip('.') if not val.is_integer() else f\"{int(val)}\"\n",
    "        return val\n",
    "\n",
    "    # Apply formatting to the specified columns\n",
    "    df_style = df_copy.style.format({col: lambda x: format_cell(x) for col in columns})\n",
    "\n",
    "    return df_style\n",
    "\n",
    "# Example usage\n",
    "data = {'A': [123.4567, 2345.6789, 34567.1234], 'B': [0.001234, 123.456, 789.01], 'C': [5.678, 34.567, 123.456]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Specify which columns to format and the number of significant figures\n",
    "columns_to_format = ['A', 'B']\n",
    "sig_figs = 4\n",
    "\n",
    "# Get the modified DataFrame with styling\n",
    "styled_df = set_significant_figures(df, columns_to_format, sig_figs)\n",
    "\n",
    "# Display the DataFrame in Jupyter Notebook or other environments\n",
    "styled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "707d3de9-9ef1-4fe9-a973-2af4c43b184c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             code       A1       A2       A3       A4       A5       B1  \\\n",
      "0   CICIMAUCR0001  4120.58  3511.41  4674.61  1430.02  1958.09  5525.11   \n",
      "1   CICIMAUCR0002  4117.20  3529.93  4475.22  1462.50  1922.14  5352.33   \n",
      "2   CICIMAUCR0003  3971.18  3584.00  4563.49  1402.85  1924.31  5360.70   \n",
      "3   CICIMAUCR0004  3627.85  3538.61  4585.22  1475.45  2028.42  5328.44   \n",
      "4   CICIMAUCR0006      NaN      NaN      NaN      NaN      NaN  5326.82   \n",
      "5   CICIMAUCR0008      NaN      NaN      NaN      NaN      NaN  5471.34   \n",
      "6   CICIMAUCR0009      NaN      NaN      NaN      NaN      NaN  5989.42   \n",
      "7   CICIMAUCR0097  4006.44  3685.78  4546.28  2076.73  1707.97  5380.23   \n",
      "8   CICIMAUCR0105  4172.69  3806.58  4804.80  2101.69  1587.15  5606.02   \n",
      "9   CICIMAUCR0113      NaN      NaN      NaN      NaN      NaN  5623.08   \n",
      "10  CICIMAUCR0116      NaN      NaN      NaN      NaN      NaN  5434.79   \n",
      "15  CICIMAUCR0210  3908.96  3849.10  4976.72  2090.46  1635.22  5832.83   \n",
      "16  CICIMAUCR0212  4437.51  3793.03  4865.54  2032.75  1517.12  5707.65   \n",
      "17  CICIMAUCR0213  4296.25  3668.76  4705.02  2029.81  1495.22  5631.26   \n",
      "20  CICIMAUCR0223  4088.09  3757.84  4858.87  2097.78  1508.74  5865.71   \n",
      "21  CICIMAUCR0225  4275.07  3536.45  4624.23  1982.69  1475.26  5287.93   \n",
      "22  CICIMAUCR0232  3492.88  3654.27  4788.63  1856.41  1392.69  5566.18   \n",
      "23  CICIMAUCR0233  4363.86  3850.47  4953.46  2229.41  1653.33  5961.04   \n",
      "24  CICIMAUCR0234  4522.92  3685.04  4728.88  1986.53  1531.20  5448.04   \n",
      "25  CICIMAUCR0235  4237.33  3729.27  4858.17  1958.46  1444.04  5765.59   \n",
      "26  CICIMAUCR0236  3989.87  3506.93  4509.08  1524.21  2037.03  5378.16   \n",
      "28  CICIMAUCR0240  3924.10  3674.20  4628.10  1520.68  1960.05  5572.03   \n",
      "30  CICIMAUCR0245  4045.97  3735.48  4851.80  2094.74  1561.72  5714.28   \n",
      "31  CICIMAUCR0247  3862.44  3499.71  4597.01  1379.67  1750.32  5231.88   \n",
      "32  CICIMAUCR0248  4207.99  4090.03  5058.53  1651.85  2194.49  5896.09   \n",
      "33  CICIMAUCR0250  4310.11  3871.48  4836.41  1663.11  2091.39  5582.49   \n",
      "34  CICIMAUCR0251  4477.21  4020.76  4969.25  1830.78  2363.89  6054.12   \n",
      "35  CICIMAUCR0252  4134.28  4009.18  4895.32  1702.28  2261.59  5734.82   \n",
      "36  CICIMAUCR0253  4117.55  3584.51  4739.36  1484.83  2006.04  5639.24   \n",
      "37  CICIMAUCR0254  4000.29  4037.84  4972.28  1599.46  2077.79  5779.71   \n",
      "38  CICIMAUCR0257  4505.37  3814.10  4786.94  1632.58  2174.00  5926.81   \n",
      "39  CICIMAUCR0258  3836.37  3599.31  4731.99  1470.47  1883.11  5641.74   \n",
      "40  CICIMAUCR0260  4088.12  3946.79  4836.32  1740.60  2302.60  5760.88   \n",
      "41  CICIMAUCR0261  4594.63  3852.22  4876.94  1604.03  2158.63  5660.63   \n",
      "\n",
      "         B2       B3       B4  ...     B4÷B1     B4÷B2     B4÷B3     D2÷D1  \\\n",
      "0   7967.86  8652.41  5101.49  ...  0.923328  0.640258  0.589603  0.652524   \n",
      "1   8099.20  8615.37  5225.63  ...  0.976328  0.645203  0.606547  0.548089   \n",
      "2   8185.66  8495.90  5436.72  ...  1.014181  0.664176  0.639923  0.624912   \n",
      "3   8139.54  8178.22  5299.74  ...  0.994614  0.651111  0.648031  0.499221   \n",
      "4   7841.55  8184.22  5172.77  ...  0.971080  0.659662  0.632042  0.574212   \n",
      "5   8279.86  8642.64  5445.43  ...  0.995264  0.657672  0.630066  0.657315   \n",
      "6   8721.56  9409.23  5938.63  ...  0.991520  0.680914  0.631149  0.566016   \n",
      "7   8422.95  8922.97  5502.10  ...  1.022651  0.653227  0.616622  0.530823   \n",
      "8   8648.11  9122.30  5654.68  ...  1.008680  0.653863  0.619874  0.517631   \n",
      "9   8291.05  9072.48  5807.61  ...  1.032817  0.700467  0.640135  0.487839   \n",
      "10  8023.60  8608.36  5457.58  ...  1.004193  0.680191  0.633986  0.534173   \n",
      "15  9158.45  9559.65  5864.23  ...  1.005383  0.640308  0.613436  0.605104   \n",
      "16  8711.56  9021.34  5774.05  ...  1.011634  0.662803  0.640043  0.471159   \n",
      "17  8436.10  8695.46  5468.85  ...  0.971159  0.648268  0.628932  0.535321   \n",
      "20  8650.40  9249.71  5807.39  ...  0.990057  0.671344  0.627846  0.572586   \n",
      "21  7857.52  7956.65  4937.28  ...  0.933689  0.628351  0.620522  0.565181   \n",
      "22  8546.45  8616.36  5517.99  ...  0.991342  0.645647  0.640408  0.544388   \n",
      "23  8936.57  9479.12  6014.86  ...  1.009029  0.673061  0.634538  0.554073   \n",
      "24  8252.06  8421.82  5323.80  ...  0.977195  0.645148  0.632144  0.651225   \n",
      "25  8652.47  8898.34  5537.96  ...  0.960519  0.640044  0.622359  0.507312   \n",
      "26  8063.84  8445.92  5275.30  ...  0.980874  0.654192  0.624597  0.663984   \n",
      "28  8504.85  8645.80  5370.97  ...  0.963916  0.631518  0.621223  0.498266   \n",
      "30  8678.80  8890.30  5692.37  ...  0.996166  0.655894  0.640290  0.505499   \n",
      "31  7912.14  8363.66  5284.65  ...  1.010086  0.667917  0.631859  0.518322   \n",
      "32  8986.76  9495.57  4871.22  ...  0.826178  0.542044  0.512999  0.497005   \n",
      "33  8371.27  8923.75  5567.72  ...  0.997354  0.665099  0.623922  0.564420   \n",
      "34  8994.20  9478.35  6004.95  ...  0.991878  0.667647  0.633544  0.594204   \n",
      "35  8794.98  9392.86  6012.14  ...  1.048357  0.683588  0.640076  0.455127   \n",
      "36  8186.13  8953.10  5483.97  ...  0.972466  0.669910  0.612522  0.483385   \n",
      "37  8880.82  9416.34  5878.90  ...  1.017162  0.661977  0.624330  0.586536   \n",
      "38  8621.43  9022.05  5455.91  ...  0.920547  0.632831  0.604731  0.479003   \n",
      "39  8537.50  8996.30  5764.17  ...  1.021701  0.675159  0.640727  0.560598   \n",
      "40  8812.01  9670.86  5896.94  ...  1.023618  0.669194  0.609764  0.552420   \n",
      "41  8364.53  9052.15  5668.04  ...  1.001309  0.677628  0.626154  0.512053   \n",
      "\n",
      "       D3÷D1     D4÷D2     E1÷E2      species  location_code  sex_code  \n",
      "0   1.893143  0.925360  0.812048     kalinini             AM       NaN  \n",
      "1   2.000158  1.041976  0.597514     kalinini             AM         M  \n",
      "2   1.995213  1.162874  0.488846     kalinini             AM         M  \n",
      "3   1.642313  0.957518  0.577308     kalinini             AM         M  \n",
      "4   2.075859  0.969237  0.693946     kalinini             AM       NaN  \n",
      "5   2.043285  1.007729  0.675432     kalinini             AM       NaN  \n",
      "6   1.789978  1.282293  0.566546     kalinini             AM       NaN  \n",
      "7   1.950781  1.083536  0.573013     kalinini             AM       NaN  \n",
      "8   1.687759  1.081919  0.646249     kalinini             AM       NaN  \n",
      "9   1.791455  1.054259  0.601480     kalinini            NaN       NaN  \n",
      "10  1.621689  1.120277  0.502280     kalinini             AM         M  \n",
      "15  1.830754  1.166656  0.624935  resplendens             MV         F  \n",
      "16  1.608583  1.503363  0.580864  resplendens             MV         F  \n",
      "17  1.888897  1.518341  0.663648  resplendens             MV         M  \n",
      "20  2.126733  1.410422  0.517243  resplendens             MV         M  \n",
      "21  1.726640  1.144252  0.600241  resplendens             MV         F  \n",
      "22  1.733387  1.141660  0.607118  resplendens             MV         M  \n",
      "23  1.527043  1.114116  0.836128  resplendens             MV         F  \n",
      "24  1.872762  1.468502  0.616060  resplendens             MV         M  \n",
      "25  1.974255  1.077609  0.489270  resplendens             MV         M  \n",
      "26  2.041221  0.835042  0.751497  resplendens             MV         M  \n",
      "28  1.669918  1.135701  0.791135  resplendens             MV         M  \n",
      "30  1.647961  1.158794  0.562600  resplendens             MV         M  \n",
      "31  2.060819  1.332079  0.975501  resplendens             MV         M  \n",
      "32  1.586013  0.873179  0.800595  resplendens             MV         F  \n",
      "33  1.939472  1.329477  0.668255  resplendens             MV         M  \n",
      "34  1.798970  0.932866  0.706880  resplendens             MV         F  \n",
      "35  1.659664  1.189713  0.642668  resplendens             MV         F  \n",
      "36  1.834377  1.493650  0.692178  resplendens             MV         M  \n",
      "37  1.764174  1.275311  0.762472  resplendens             MV         F  \n",
      "38  1.680003  1.313492  0.707687  resplendens             MV         F  \n",
      "39  1.927198  1.227851  0.694719  resplendens             MV         M  \n",
      "40  1.671473  1.189847  0.785322  resplendens             MV         F  \n",
      "41  2.002257  1.384470  0.764963  resplendens             MV         M  \n",
      "\n",
      "[34 rows x 45 columns]\n",
      "Index(['metric', 'normality_kalinini', 'normality_resplendens', 'normality',\n",
      "       'levene_pvalue', 'variance', 'test_type', 't_stat', 'p_value',\n",
      "       'interpretation', 'significance', 'u_stat'],\n",
      "      dtype='object')\n",
      "metric\n",
      "test_type\n",
      "p_value\n",
      "Index(['metric', 'normality_kalinini', 'normality_resplendens', 'normality',\n",
      "       'levene_pvalue', 'variance', 'test_type', 't_stat', 'p_value',\n",
      "       'interpretation', 'significance', 'u_stat'],\n",
      "      dtype='object')\n",
      "metric\n",
      "['species' 'A2_mean' 'A2_std' 'A3_mean' 'A3_std']\n",
      "['species' 'B1_mean' 'B1_std' 'B2_mean' 'B2_std']\n",
      "['species' 'D4_mean' 'D4_std' 'E1_mean' 'E1_std']\n",
      "['species' 'F1_mean' 'F1_std' 'F2_mean' 'F2_std']\n",
      "['species' 'F3_mean' 'F3_std' 'F4_mean' 'F4_std']\n",
      "['species' 'D4÷D2_mean' 'D4÷D2_std']\n",
      "D4÷D2_mean\n",
      "D4÷D2_std\n",
      "metric\n",
      "p_value\n",
      "percentual_diff\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'kalinini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m measurement_df_2 \u001b[38;5;241m=\u001b[39m measurement_df_2[(measurement_df_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkalinini\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m|\u001b[39m (measurement_df_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresplendens\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(measurement_df_2)\n\u001b[1;32m--> 104\u001b[0m create_report(measurement_df_2, cached_tex_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, group_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 49\u001b[0m, in \u001b[0;36mcreate_report\u001b[1;34m(df, cached_tex_files, group_by)\u001b[0m\n\u001b[0;32m     47\u001b[0m tables \u001b[38;5;241m=\u001b[39m create_tables_latex(df, results_df)\n\u001b[0;32m     48\u001b[0m main \u001b[38;5;241m=\u001b[39m create_main_latex()\n\u001b[1;32m---> 49\u001b[0m dataset_description \u001b[38;5;241m=\u001b[39m  dataset_description_latex(df, image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mesteb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mescarabajos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbiometry\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreport_output\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, group_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m analysis \u001b[38;5;241m=\u001b[39m Analysis_latex(df, figure_counter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, group_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Pass your df and figure_counter\u001b[39;00m\n\u001b[0;32m     51\u001b[0m conclusion \u001b[38;5;241m=\u001b[39m conclusion_latex(df)      \u001b[38;5;66;03m# Pass your dataframe as needed x\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 57\u001b[0m, in \u001b[0;36mdataset_description_latex\u001b[1;34m(df, image_path, group_by)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Normality test subsection\u001b[39;00m\n\u001b[0;32m     54\u001b[0m latex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msubsection\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mNormality Test}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m latex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapiro-Wilk p-values for \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mC. kalinini\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m population are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormality_info_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkalinini\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and for \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtextit\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mC. resplendens\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m population are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormality_info_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresplendens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# boxplot plots subsection\u001b[39;00m\n\u001b[0;32m     62\u001b[0m latex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msubsection\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mBoxplots for Each Metric}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'kalinini'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "#   generate_latex_preamble()       -> returns the preamble string\n",
    "#   front_page_latex()              -> returns LaTeX code for the front page\n",
    "#   introduction_latex(df)          -> returns LaTeX code for the introduction section\n",
    "#   methodology_latex(df)           -> returns LaTeX code for the methodology section\n",
    "#   dataset_description_latex(df, group_by=\"species\") -> returns LaTeX code for dataset description section\n",
    "#   Analysis_latex(df, figure_counter=1)  -> returns LaTeX code for statistical analysis section\n",
    "#   conclusion_latex(df)            -> returns LaTeX code for the conclusion section\n",
    "#   create_bibliography_latex()     -> returns LaTeX code for the bibliography\n",
    "#\n",
    "\n",
    "# =============================================================================\n",
    "def compile_latex(cwd, compile_cmd):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            compile_cmd, cwd=cwd, check=True,\n",
    "            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"LaTeX compilation failed.\")\n",
    "        print(\"Return code:\", e.returncode)\n",
    "        print(\"Output:\", e.stdout)\n",
    "        print(\"Error output:\", e.stderr)\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def create_report(df = measurement_df_2, cached_tex_files = True,group_by = \"species\"):\n",
    "    report_location = r\"C:\\Users\\esteb\\escarabajos\\biometry\\report_output\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(report_location):\n",
    "        os.makedirs(report_location)\n",
    "\n",
    "    if not cached_tex_files:\n",
    "        # Prepare each section's LaTeX code\n",
    "        preamble = generate_latex_preamble() #x\n",
    "        front_page_section = front_page()\n",
    "        introduction = introduction_section(df)  # Pass your dataframe as needed\n",
    "        methodology = methodology_latex(df)    # Pass your dataframe as needed\n",
    "        summary_table = result_summary(results_df)\n",
    "        tables = create_tables_latex(df, results_df)\n",
    "        main = create_main_latex()\n",
    "        dataset_description =  dataset_description_latex(df, image_path = r\"C:\\Users\\esteb\\escarabajos\\biometry\\report_output\\images\", group_by=\"species\")\n",
    "        analysis = Analysis_latex(df, figure_counter=1, group_by = \"species\")  # Pass your df and figure_counter\n",
    "        conclusion = conclusion_latex(df)      # Pass your dataframe as needed x\n",
    "        bibliography = create_bibliography_latex()\n",
    "        abstract = create_abstract_latex()\n",
    "        create_bib_file()\n",
    "    \n",
    "        # Write each section to a separate .tex file (optional, for organization)\n",
    "        sections = {\n",
    "            \"preamble.tex\": preamble,\n",
    "            \"front_page.tex\": front_page_section,\n",
    "            \"introduction.tex\": introduction,\n",
    "            \"methodology.tex\": methodology,\n",
    "            \"Analysis.tex\": analysis,\n",
    "            \"Tables.tex\": tables,\n",
    "            \"Results.tex\": summary_table,\n",
    "            \"Claims.tex\": conclusion,\n",
    "            \"bibliography.tex\": bibliography,\n",
    "            \"main.tex\": main,\n",
    "            \"Abstract.tex\": abstract\n",
    "        }\n",
    "        \n",
    "        for filename, content in sections.items():\n",
    "            path = os.path.join(report_location, filename)\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "    \n",
    "\n",
    "\n",
    "    # Now compile main.tex into a PDF using pdflatex.\n",
    "    # Run pdflatex twice to ensure that references are updated.\n",
    "    compile_cmd = [\"pdflatex\", \"-interaction=nonstopmode\", \"main.tex\"]\n",
    "    cwd = os.path.abspath(report_location)\n",
    "    compile_latex(cwd, compile_cmd)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # First pass\n",
    "        subprocess.run(compile_cmd, cwd=cwd, check=True)\n",
    "        # Second pass\n",
    "        subprocess.run(compile_cmd, cwd=cwd, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during LaTeX compilation:\", e)\n",
    "        return\n",
    "\n",
    "    \n",
    "    # The resulting PDF will be at report_location/main.pdf\n",
    "    pdf_path = os.path.join(cwd, \"main.pdf\")\n",
    "    print(f\"The report has been generated at: {pdf_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #filter cupreomarginata\n",
    "    measurement_df_2 = measurement_df_2[(measurement_df_2[\"species\"] == \"kalinini\") | (measurement_df_2[\"species\"] == \"resplendens\")]\n",
    "    print(measurement_df_2)\n",
    "    \n",
    "    create_report(measurement_df_2, cached_tex_files = False, group_by = \"species\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee3ba6-1f11-4aac-a675-7e826c78f9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b1966-2029-41e0-acb4-d98715f2a5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cde76f-7e1a-47e3-93f1-99e3effefa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d4c78-5fed-4c2d-b1db-68a5be71a34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59e4db-d411-4ff1-a4d2-3f71fbcec2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
