{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036c2631-ff5b-43de-8b0a-b0b3659cbfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to metric_image.json\n",
      "Dictionary loaded from metric_image.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage  # Correct import for PIL Image\n",
    "\n",
    "# ReportLab imports\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import Paragraph, Spacer, Image, PageBreak, SimpleDocTemplate\n",
    "import datetime\n",
    "\n",
    "# Counter\n",
    "global figure_counter \n",
    "figure_counter = 1\n",
    "\n",
    "# Methods\n",
    "def createTextObject(text, style, centered=False):\n",
    "    \"\"\"\n",
    "    Creates a Paragraph with optional centered alignment.\n",
    "    \"\"\"\n",
    "    if centered:\n",
    "        style = ParagraphStyle(name=\"Centered\", parent=style, alignment=1)  # 1 = TA_CENTER\n",
    "    return Paragraph(text, style)\n",
    "\n",
    "def generate_violin_plot(df, column, group_by=None):\n",
    "    \"\"\"\n",
    "    Generates a violin plot for a given column of a DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    if group_by:\n",
    "        sns.violinplot(data=df, x=group_by, y=column)\n",
    "    else:\n",
    "        sns.violinplot(data=df[column])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format=\"PNG\")\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def generate_boxplot_with_stripplot(df, column, group_by=None):\n",
    "    \"\"\"\n",
    "    Generates a boxplot with stripplot (points for each data point) where outliers\n",
    "    (those falling outside 1.5 times the IQR) are shown as red points and the rest as black.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column (str): The column to plot.\n",
    "        group_by (str, optional): The column to group by. If None, no grouping is applied.\n",
    "\n",
    "    Returns:\n",
    "        BytesIO: A buffer containing the plot image in PNG format.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    if group_by:\n",
    "        # Draw the boxplot without fliers\n",
    "        sns.boxplot(data=df, x=group_by, y=column, hue=group_by, palette=\"Set2\", legend=False, showfliers=False)\n",
    "        \n",
    "        # For each group, compute the IQR-based bounds and plot points accordingly\n",
    "        groups = df[group_by].unique()\n",
    "        for grp in groups:\n",
    "            # Select data for this group\n",
    "            grp_data = df[df[group_by] == grp][column]\n",
    "            Q1 = grp_data.quantile(0.25)\n",
    "            Q3 = grp_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Classify the points as non-outliers and outliers\n",
    "            non_outliers = grp_data[(grp_data >= lower_bound) & (grp_data <= upper_bound)]\n",
    "            outliers = grp_data[(grp_data < lower_bound) | (grp_data > upper_bound)]\n",
    "            \n",
    "            # Plot non-outliers (black)\n",
    "            sns.stripplot(x=[grp] * len(non_outliers), y=non_outliers, color=\"black\", alpha=0.5, jitter=True)\n",
    "            # Plot outliers (red)\n",
    "            sns.stripplot(x=[grp] * len(outliers), y=outliers, color=\"red\", alpha=0.5, jitter=True)\n",
    "            \n",
    "        plt.title(f\"Boxplot with Stripplot of {column} grouped by {group_by}\")\n",
    "    else:\n",
    "        # Draw the boxplot without fliers for the whole column\n",
    "        sns.boxplot(data=df, y=column, color=\"lightblue\", showfliers=False)\n",
    "        \n",
    "        # Compute bounds for the overall data\n",
    "        data = df[column]\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Classify the points\n",
    "        non_outliers = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "        outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "        \n",
    "        # When no grouping, use a constant x value (e.g., 0) for all points\n",
    "        sns.stripplot(x=[0] * len(non_outliers), y=non_outliers, color=\"black\", alpha=0.5, jitter=True)\n",
    "        sns.stripplot(x=[0] * len(outliers), y=outliers, color=\"red\", alpha=0.5, jitter=True)\n",
    "        plt.title(f\"Boxplot with Stripplot of {column}\")\n",
    "        plt.xlabel(\"\")  # No x-axis label needed when not grouped\n",
    "\n",
    "    plt.ylabel(column)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot into a BytesIO buffer in PNG format\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format=\"PNG\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "global metric_image\n",
    "metric_image = {\n",
    "    \"A1\": \"Head_A1.png\",\n",
    "    \"A2\": \"Head_A2.png\",\n",
    "    \"A3\": \"Head_A3.png\",\n",
    "    \"A4\": \"Head_A4.png\",\n",
    "    \"A5\": \"Head_A5.png\",\n",
    "    \"B1\": \"Pronotum_B1.png\",\n",
    "    \"B2\": \"Pronotum_B2.png\",\n",
    "    \"B3\": \"Pronotum_B3.png\",\n",
    "    \"B4\": \"Pronotum_B4.png\",\n",
    "    \"B5\": \"Pronotum_B5.png\",\n",
    "    \"C1\": \"Lateral_C1.png\",\n",
    "    \"D1\": \"Mesosternal_process_D1.png\",\n",
    "    \"D2\": \"Mesosternal_process_D2.png\",\n",
    "    \"D3\": \"Mesosternal_process_D3.png\",\n",
    "    \"D4\": \"Mesosternal_process_D4.png\",\n",
    "    \"E1\": \"Prosternal_process_E1.png\",\n",
    "    \"E2\": \"Prosternal_process_E2.png\",\n",
    "    \"F1\": \"Ventral.png\",\n",
    "    \"F2\": \"Ventral.png\",\n",
    "    \"F3\": \"Ventral.png\",\n",
    "    \"F4\": \"Ventral.png\",\n",
    "    \"F5\": \"Ventral.png\",\n",
    "    \"W2\": \"Head.png\",\n",
    "    \"W3\": \"Head.png\",\n",
    "    \"W4\": \"Head.png\",\n",
    "    \"W5\": \"Head.png\",\n",
    "    \"W6\": \"Pronotum.png\",\n",
    "    \"W7\": \"Pronotum.png\",\n",
    "    \"W9\": \"Mesosternal_process_D4.png\",\n",
    "    \"W10\": \"Mesosternal_process_D4.png\",\n",
    "    \"W13\": \"Prosternal_process.png\",\n",
    "}\n",
    "\n",
    "# Location of images\n",
    "global protocol_image_location\n",
    "protocol_image_location = Path(r\"F:\\BIOMETRY_PNG\\20250110\\Protocolo\")\n",
    "\n",
    "# --- Saving and Loading the Dictionary ---\n",
    "\n",
    "def save_metric_image(dictionary, filepath):\n",
    "    \"\"\"\n",
    "    Saves the metric_image dictionary to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        dictionary (dict): The dictionary to save.\n",
    "        filepath (str or Path): The path to the file where the dictionary will be saved.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        json.dump(dictionary, file, indent=4)\n",
    "    print(f\"Dictionary saved to {filepath}\")\n",
    "\n",
    "def load_metric_image(filepath):\n",
    "    \"\"\"\n",
    "    Loads the metric_image dictionary from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str or Path): The path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The loaded dictionary.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        loaded_dict = json.load(file)\n",
    "    print(f\"Dictionary loaded from {filepath}\")\n",
    "    return loaded_dict\n",
    "\n",
    "# Define the path for the JSON file\n",
    "metric_image_file = Path(\"metric_image.json\")\n",
    "\n",
    "# Save the metric_image dictionary\n",
    "save_metric_image(metric_image, metric_image_file)\n",
    "\n",
    "# Later, load the dictionary from the file\n",
    "metric_image_loaded = load_metric_image(metric_image_file)\n",
    "\n",
    "# Optional: Verify that both dictionaries are the same\n",
    "assert metric_image == metric_image_loaded, \"The loaded dictionary does not match the original!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92167d2c-b164-4d5e-bc41-ed22f5e08bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A1       A2       A3       A4       A5       B1       B2       B3  \\\n",
      "0  4120.58  3511.41  4674.61  1430.02  1958.09  5525.11  7967.86  8652.41   \n",
      "1  4117.20  3529.93  4475.22  1462.50  1922.14  5352.33  8099.20  8615.37   \n",
      "2  3971.18  3584.00  4563.49  1402.85  1924.31  5360.70  8185.66  8495.90   \n",
      "3  3627.85  3538.61  4585.22  1475.45  2028.42  5328.44  8139.54  8178.22   \n",
      "4      NaN      NaN      NaN      NaN      NaN  5326.82  7841.55  8184.22   \n",
      "\n",
      "        B4      B5  ...       D3      D4      E1      E2       F1       F2  \\\n",
      "0  5101.49  155.26  ...  2132.02  680.01  579.64  713.80  1385.64  1399.18   \n",
      "1  5225.63  148.98  ...  2278.68  650.62  507.14  848.75      NaN  1265.19   \n",
      "2  5436.72  149.16  ...  2275.50  828.78  420.73  860.66  1424.02  1374.55   \n",
      "3  5299.74  148.93  ...  2159.79  628.63  476.10  824.69  1367.70  1427.33   \n",
      "4  5172.77  150.12  ...  2186.98  586.34  444.66  640.77  1391.86  1327.51   \n",
      "\n",
      "        F3       F4       F5           code  \n",
      "0  1475.44  1857.42  1662.46  CICIMAUCR0001  \n",
      "1  1341.08  1776.71   943.28  CICIMAUCR0002  \n",
      "2  1375.56  1891.07  1692.07  CICIMAUCR0003  \n",
      "3  1515.73  2031.99  1639.23  CICIMAUCR0004  \n",
      "4  1315.48  1693.02  1496.06  CICIMAUCR0006  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Summary Statistics:\n",
      "                A1           A2           A3           A4           A5  \\\n",
      "count    37.000000    37.000000    37.000000    37.000000    37.000000   \n",
      "mean   4109.505135  3697.212703  4712.424595  1812.224324  1742.201351   \n",
      "std     250.101576   177.305029   181.444406   255.782814   409.817068   \n",
      "min    3492.880000  3451.580000  4300.610000  1379.670000    14.000000   \n",
      "25%    3977.820000  3538.610000  4569.680000  1599.460000  1517.120000   \n",
      "50%    4117.200000  3668.760000  4728.880000  1885.550000  1696.300000   \n",
      "75%    4282.460000  3814.100000  4858.170000  2039.240000  2028.420000   \n",
      "max    4594.630000  4090.030000  5058.530000  2229.410000  2363.890000   \n",
      "\n",
      "                B1           B2           B3           B4          B5  ...  \\\n",
      "count    41.000000    42.000000    41.000000    42.000000   42.000000  ...   \n",
      "mean   5555.049024  8276.477143  8746.133902  5405.136429  150.545000  ...   \n",
      "std     251.339195   508.676618   540.677913   406.046257    3.647167  ...   \n",
      "min    5058.620000  7130.950000  7709.840000  4575.510000  142.620000  ...   \n",
      "25%    5360.050000  7979.165000  8421.820000  5137.077500  148.557500  ...   \n",
      "50%    5572.030000  8327.790000  8695.460000  5456.745000  150.010000  ...   \n",
      "75%    5734.820000  8651.952500  9072.480000  5746.220000  153.162500  ...   \n",
      "max    6054.120000  9158.450000  9670.860000  6014.860000  158.790000  ...   \n",
      "\n",
      "               D2           D3           D4          E1           E2  \\\n",
      "count   42.000000    42.000000    42.000000   42.000000    42.000000   \n",
      "mean   675.328810  2192.427619   793.980714  527.038571   802.372857   \n",
      "std     86.537134   303.449494   143.188737   98.385978   106.726843   \n",
      "min    507.280000  1495.300000   586.340000  329.160000   589.830000   \n",
      "25%    616.287500  2092.992500   691.090000  456.150000   717.072500   \n",
      "50%    671.405000  2282.120000   767.320000  506.975000   822.545000   \n",
      "75%    722.922500  2408.570000   907.972500  596.580000   876.040000   \n",
      "max    884.710000  2603.100000  1085.840000  722.500000  1041.260000   \n",
      "\n",
      "                F1           F2           F3           F4           F5  \n",
      "count    40.000000    41.000000    41.000000    41.000000    41.000000  \n",
      "mean   1449.292750  1457.507317  1516.671951  2082.036341  1629.735122  \n",
      "std      79.167563    90.447028    90.052480   237.686777   279.159370  \n",
      "min    1302.830000  1252.740000  1315.480000  1693.020000   943.280000  \n",
      "25%    1402.645000  1391.440000  1463.850000  1892.950000  1460.690000  \n",
      "50%    1431.560000  1467.790000  1530.670000  2024.900000  1639.360000  \n",
      "75%    1516.322500  1515.810000  1577.910000  2283.170000  1815.100000  \n",
      "max    1620.870000  1654.440000  1704.720000  2594.010000  2485.280000  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "New metrics saved to metrics.csv\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(measurement_df):\n",
    "    # Ensure the required columns are present in the DataFrame\n",
    "    required_columns = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"C1\", \"D1\", \"D2\", \"D3\", \"D4\", \"E1\", \"E2\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"code\"]\n",
    "    \n",
    "    # Check if all required columns are available in the DataFrame\n",
    "    for column in required_columns:\n",
    "        if column not in measurement_df.columns:\n",
    "            print(f\"Warning: Missing column {column} in the DataFrame.\")\n",
    "    \n",
    "    # --- Statistics: Descriptive statistics for the measurements ---\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(measurement_df.describe())  # Basic statistics (mean, std, min, 25%, 50%, 75%, max)\n",
    "    \n",
    "    # --- Absolute Metrics ---\n",
    "    # Example: Metric for A1 (could be specific characteristics or formulae for these metrics)\n",
    "    #measurement_df[\"W1\"] = measurement_df[\"A1\"]  # Example, assuming A1 is a numeric column\n",
    "\n",
    "    # --- Relative Metrics ---\n",
    "    # Example: A1/A3, A4/A3, A5/A3 (just a few examples, can extend to others)\n",
    "    measurement_df[\"W2\"] = measurement_df[\"A1\"] / measurement_df[\"A3\"]\n",
    "    measurement_df[\"W3\"] = measurement_df[\"A4\"] / measurement_df[\"A3\"]\n",
    "    measurement_df[\"W4\"] = measurement_df[\"A5\"] / measurement_df[\"A3\"]\n",
    "\n",
    "    # --- Pronoto: Kalinini has a longer pronoto compared to its width ---\n",
    "    # Example: Calculating relative metric B4/B1, B4/B2, B4/B3\n",
    "    measurement_df[\"W5\"] = measurement_df[\"B4\"] / measurement_df[\"B1\"]\n",
    "    measurement_df[\"W6\"] = measurement_df[\"B4\"] / measurement_df[\"B2\"]\n",
    "    measurement_df[\"W7\"] = measurement_df[\"B4\"] / measurement_df[\"B3\"]\n",
    "\n",
    "    # --- Mesosternal Process: Example of a metric based on \"más brillante\" (more shiny) ---\n",
    "    # Let's assume we have a measure for brightness or some characteristic that corresponds to this.\n",
    "    # Using D2 as an example for being \"more short\" (assumed metric), you could add a new metric:\n",
    "    \n",
    "    # --- More Width (D1/D2, D3/D2) ---\n",
    "    measurement_df[\"W9\"] = measurement_df[\"D2\"] / measurement_df[\"D1\"]\n",
    "    measurement_df[\"W10\"] = measurement_df[\"D2\"] / measurement_df[\"D3\"]\n",
    "\n",
    "    # --- Alternative Metric (just an example, could be anything relevant to your dataset) ---\n",
    "    # For now, assuming a combination of some columns as an alternative metric\n",
    "  \n",
    "    \n",
    "    # --- Placa Prosternal: For kalinini and resplendens comparison ---\n",
    "    # This part is a bit more abstract and depends on how we define these measurements.\n",
    "    # You could categorize the species based on these characteristics if you have some measurements available.\n",
    "\n",
    "    # Kalinini is round, triangular, and flat; resplendens is square. \n",
    "    # For simplicity, let's assume we can flag them based on a column like \"shape\" or similar\n",
    "    \n",
    "\n",
    "    # --- Relative Metric: E1/E2 ---\n",
    "    measurement_df[\"W13\"] = measurement_df[\"E1\"] / measurement_df[\"E2\"]\n",
    "\n",
    "    # --- Return the updated DataFrame ---\n",
    "    return measurement_df\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "date = datetime.date.today()\n",
    "#file_path = f'summary just png files {date}.csv'  # Path to your saved file\n",
    "file_path = f\"summary just png files 2025-02-16.csv\"\n",
    "measurement_df = pd.read_csv(file_path, sep='\\t', decimal=',', header=0)\n",
    "\n",
    "\n",
    "# Print the first few rows to verify it worked\n",
    "print(measurement_df.head())\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `measurement_df` contains the extracted measurements from OCR.\n",
    "# You can now apply the feature engineering function to the DataFrame.\n",
    "measurement_df_2 = feature_engineering(measurement_df)\n",
    "\n",
    "metrics_df = pd.DataFrame([])\n",
    "metrics_df[\"code\"] = measurement_df_2[\"code\"]\n",
    "columns = [col for col in measurement_df_2.columns if col != \"code\"]\n",
    "for col in columns:\n",
    "    metrics_df[col] = measurement_df_2[col]\n",
    "# Print the final DataFrame to check the new features\n",
    "#print(measurement_df_2)\n",
    "\n",
    "#save the df into a file\n",
    "filename = \"metrics.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(filename, index=False, sep = \"\\t\", decimal = \".\" )\n",
    "print(f\"New metrics saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a251104-ce16-4e66-bd27-2e51fb844270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>column</th>\n",
       "      <th>outlier_value</th>\n",
       "      <th>median</th>\n",
       "      <th>lower_whisker</th>\n",
       "      <th>upper_whisker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CICIMAUCR0232</td>\n",
       "      <td>A1</td>\n",
       "      <td>3492.880000</td>\n",
       "      <td>4117.200000</td>\n",
       "      <td>3520.860000</td>\n",
       "      <td>4739.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CICIMAUCR0204</td>\n",
       "      <td>A5</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1696.300000</td>\n",
       "      <td>750.170000</td>\n",
       "      <td>2795.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CICIMAUCR0252</td>\n",
       "      <td>C1</td>\n",
       "      <td>164.380000</td>\n",
       "      <td>151.105000</td>\n",
       "      <td>139.732500</td>\n",
       "      <td>163.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CICIMAUCR0233</td>\n",
       "      <td>D2</td>\n",
       "      <td>884.710000</td>\n",
       "      <td>671.405000</td>\n",
       "      <td>456.335000</td>\n",
       "      <td>882.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>D3</td>\n",
       "      <td>1554.090000</td>\n",
       "      <td>2282.120000</td>\n",
       "      <td>1619.626250</td>\n",
       "      <td>2881.936250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CICIMAUCR0242</td>\n",
       "      <td>D3</td>\n",
       "      <td>1495.300000</td>\n",
       "      <td>2282.120000</td>\n",
       "      <td>1619.626250</td>\n",
       "      <td>2881.936250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CICIMAUCR0261</td>\n",
       "      <td>F5</td>\n",
       "      <td>2485.280000</td>\n",
       "      <td>1639.360000</td>\n",
       "      <td>929.075000</td>\n",
       "      <td>2346.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CICIMAUCR0232</td>\n",
       "      <td>W2</td>\n",
       "      <td>0.729411</td>\n",
       "      <td>0.880972</td>\n",
       "      <td>0.746008</td>\n",
       "      <td>1.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CICIMAUCR0204</td>\n",
       "      <td>W4</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.376002</td>\n",
       "      <td>0.167276</td>\n",
       "      <td>0.586846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>W6</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.654028</td>\n",
       "      <td>0.602293</td>\n",
       "      <td>0.707183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CICIMAUCR0248</td>\n",
       "      <td>W7</td>\n",
       "      <td>0.512999</td>\n",
       "      <td>0.623922</td>\n",
       "      <td>0.566053</td>\n",
       "      <td>0.674038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CICIMAUCR0215</td>\n",
       "      <td>W9</td>\n",
       "      <td>0.375515</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.395560</td>\n",
       "      <td>0.676174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CICIMAUCR0247</td>\n",
       "      <td>W13</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.663592</td>\n",
       "      <td>0.406807</td>\n",
       "      <td>0.882059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             code column  outlier_value       median  lower_whisker  \\\n",
       "0   CICIMAUCR0232     A1    3492.880000  4117.200000    3520.860000   \n",
       "1   CICIMAUCR0204     A5      14.000000  1696.300000     750.170000   \n",
       "2   CICIMAUCR0252     C1     164.380000   151.105000     139.732500   \n",
       "3   CICIMAUCR0233     D2     884.710000   671.405000     456.335000   \n",
       "4   CICIMAUCR0215     D3    1554.090000  2282.120000    1619.626250   \n",
       "5   CICIMAUCR0242     D3    1495.300000  2282.120000    1619.626250   \n",
       "6   CICIMAUCR0261     F5    2485.280000  1639.360000     929.075000   \n",
       "7   CICIMAUCR0232     W2       0.729411     0.880972       0.746008   \n",
       "8   CICIMAUCR0204     W4       0.003030     0.376002       0.167276   \n",
       "9   CICIMAUCR0248     W6       0.542044     0.654028       0.602293   \n",
       "10  CICIMAUCR0248     W7       0.512999     0.623922       0.566053   \n",
       "11  CICIMAUCR0215     W9       0.375515     0.534747       0.395560   \n",
       "12  CICIMAUCR0247    W13       0.975501     0.663592       0.406807   \n",
       "\n",
       "    upper_whisker  \n",
       "0     4739.420000  \n",
       "1     2795.370000  \n",
       "2      163.372500  \n",
       "3      882.875000  \n",
       "4     2881.936250  \n",
       "5     2881.936250  \n",
       "6     2346.715000  \n",
       "7        1.000297  \n",
       "8        0.586846  \n",
       "9        0.707183  \n",
       "10       0.674038  \n",
       "11       0.676174  \n",
       "12       0.882059  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_outliers(df):\n",
    "    \"\"\"\n",
    "    Scans the DataFrame for outliers in all numeric columns (excluding the 'code' column).\n",
    "    Returns a DataFrame with rows that have outliers, including:\n",
    "      - the value of the 'code' column,\n",
    "      - the column name where the outlier occurred,\n",
    "      - the outlier value,\n",
    "      - the median, lower whisker, and upper whisker for that column.\n",
    "    \"\"\"\n",
    "    outlier_records = []\n",
    "    \n",
    "    # Identify numeric columns.\n",
    "    # Exclude the 'code' column (assuming it is not to be analyzed as numeric data).\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    if 'code' in numeric_cols:\n",
    "        numeric_cols.remove('code')\n",
    "    \n",
    "    # Process each numeric column\n",
    "    for col in numeric_cols:\n",
    "        # Compute statistics for the column.\n",
    "        median = df[col].median()\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_whisker = Q1 - 1.5 * IQR\n",
    "        upper_whisker = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Identify outlier rows for this column.\n",
    "        # You can do this with a vectorized boolean condition:\n",
    "        is_outlier = (df[col] < lower_whisker) | (df[col] > upper_whisker)\n",
    "        \n",
    "        # For every row that is an outlier, record the required details.\n",
    "        for idx, row in df[is_outlier].iterrows():\n",
    "            outlier_records.append({\n",
    "                'code': row['code'],       # the value from the \"code\" column\n",
    "                'column': col,             # the column where the outlier was found\n",
    "                'outlier_value': row[col],\n",
    "                'median': median,\n",
    "                'lower_whisker': lower_whisker,\n",
    "                'upper_whisker': upper_whisker\n",
    "            })\n",
    "    \n",
    "    # Convert the list of records into a DataFrame to return.\n",
    "    return pd.DataFrame(outlier_records)\n",
    "\n",
    "detect_outliers(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd462c-a54a-4502-8529-9f164da1cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add species data\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory containing datapath_selector.py to the system path\n",
    "library_path = r\"C:\\Users\\esteb\\escarabajos\\libraries\"\n",
    "sys.path.append(library_path)\n",
    "\n",
    "# Now you can import datapath_selector.py as a module\n",
    "import datapath_selector\n",
    "import spectraltools\n",
    "from datapath_selector import get_paths\n",
    "from collection_tools import *\n",
    "from datetime import datetime\n",
    "collections_list = get_collections_list()\n",
    "collections_dict = get_collections_dict()\n",
    "\n",
    "# Define a function to apply species_lookup to each code\n",
    "def get_species_for_code(code):\n",
    "    # Use the species_lookup method from the relevant collection in collections_dict\n",
    "    return collections_dict[\"CICIMAUCR1\"].species_lookup(code=code, collection_list=collections_list)\n",
    "\n",
    "\n",
    "# Apply the function to the 'code' column of your DataFrame\n",
    "#convert codes into list\n",
    "code_list = measurement_df_2[\"code\"].tolist()\n",
    "result_df = pd.DataFrame([])\n",
    "result_df = pd.concat([measurement_df_2, result_df], axis=1)\n",
    "\n",
    "#print(f\"{result_df=}\")\n",
    "\n",
    "for code in code_list:\n",
    "    info_df = get_specimen_info(code)  # Fetch information for the given code\n",
    "    columns_of_interest = [\"code\", \"species\", \"location_code\", \"sex_code\"]\n",
    "    new_columns_df = info_df[columns_of_interest]\n",
    "\n",
    "    # Merge the new columns into result_df by \"code\"\n",
    "    if result_df.empty:\n",
    "        # If result_df is empty, initialize it with the first new_columns_df\n",
    "        result_df = new_columns_df\n",
    "    else:\n",
    "        # Update or add information for the specific \"code\"\n",
    "        for column in columns_of_interest:\n",
    "            if column != \"code\":  # Avoid trying to overwrite the \"code\" column itself\n",
    "                result_df.loc[result_df[\"code\"] == code, column] = new_columns_df.loc[new_columns_df[\"code\"] == code, column].values[0]\n",
    "\n",
    "    \n",
    "#measurement_df_2[\"species\"] = measurement_df_2[\"code\"].apply(get_species_for_code)\n",
    "print(f\"{result_df=}\")\n",
    "\n",
    "#define information_df\n",
    "information_df = result_df\n",
    "\n",
    "# First, group the entire dataframe by 'species', and then calculate the mean of 'A1'\n",
    "metrics_under_consideration = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"C1\", \"D1\", \"D2\", \"D3\", \"D4\", \"E1\", \"E2\", \"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"W2\", \"W3\", \"W4\", \"W5\", \"W6\", \"W7\", \"W9\", \"W10\", \"W13\"]\n",
    "    \n",
    "aggregated = result_df.groupby(\"species\")[metrics_under_consideration].mean()\n",
    "\n",
    "# Optionally, if you want to see the result:\n",
    "#print(aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fefbcb-e23c-4b31-bbcc-12a550e1dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Image, Spacer, Paragraph\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors\n",
    "### Third test: Plots on demand\n",
    "#!pip install reportlab\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc186c-8634-4fbd-a73e-43ce7d63a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'measurement_df_2' is your dataframe\n",
    "# Split the data by species\n",
    "measurement_df_2 = result_df\n",
    "kalinini_data = measurement_df_2[measurement_df_2[\"species\"] == \"kalinini\"]\n",
    "resplendens_data = measurement_df_2[measurement_df_2[\"species\"] == \"resplendens\"]\n",
    "\n",
    "# List of metrics to test (assuming your dataframe contains these columns)\n",
    "metrics = metrics_under_consideration\n",
    "\n",
    "# Dictionary to store test results\n",
    "global t_test_results\n",
    "t_test_results = {}\n",
    "\n",
    "#Normality\n",
    "normality_info_dict = {\n",
    "    \n",
    "}\n",
    "for metric in metrics:\n",
    "    # Extract the data for each species' metric\n",
    "    kalinini_values = kalinini_data[metric].dropna()  # Remove missing values\n",
    "    resplendens_values = resplendens_data[metric].dropna()  # Remove missing values\n",
    "    \n",
    "    # Check normality (Shapiro-Wilk test) for both species\n",
    "    kalinini_normal = stats.shapiro(kalinini_values)[1] > 0.05  # p-value > 0.05 => normal\n",
    "    resplendens_normal = stats.shapiro(resplendens_values)[1] > 0.05  # p-value > 0.05 => normal\n",
    "\n",
    "    #save info for report\n",
    "    normality_info_dict[\"kalinini\"] = kalinini_normal\n",
    "    normality_info_dict[\"resplendens\"] = resplendens_normal\n",
    "    \n",
    "    if kalinini_normal and resplendens_normal:\n",
    "        # Perform Levene's test for homogeneity of variance\n",
    "        levene_test = stats.levene(kalinini_values, resplendens_values)\n",
    "        print(levene_test)\n",
    "        # Perform Student's t-test if variances are equal (Levene's test p > 0.05)\n",
    "        if levene_test.pvalue > 0.05:\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values)\n",
    "            test_type = \"Student's t-test\"\n",
    "        else:\n",
    "            # If variances are unequal, use Welch's t-test (Welch correction)\n",
    "            t_stat, p_value = stats.ttest_ind(kalinini_values, resplendens_values, equal_var=False)\n",
    "            test_type = \"Welch's t-test\"\n",
    "        \n",
    "        # Interpretation\n",
    "        interpretation = \"significant difference\" if p_value < 0.05 else \"no significant difference\"\n",
    "        \n",
    "        t_test_results[metric] = {\n",
    "            \"levene_test\": levene_test.pvalue,\n",
    "            \"test_type\": test_type,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"interpretation\": interpretation\n",
    "        }\n",
    "    else:\n",
    "        # If normality fails, use the Mann-Whitney U test\n",
    "        u_stat, p_value = stats.mannwhitneyu(kalinini_values, resplendens_values)\n",
    "        test_type = \"Mann-Whitney U test\"\n",
    "        \n",
    "        # Interpretation\n",
    "        interpretation = \"significant difference\" if p_value < 0.05 else \"no significant difference\"\n",
    "        \n",
    "        t_test_results[metric] = {\n",
    "            \"levene_test\": levene_test.pvalue,\n",
    "            \"test_type\": test_type,\n",
    "            \"u_stat\": u_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"interpretation\": interpretation\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "global metric_description\n",
    "metric_description = { \"A1\": \"Vertical length of the head: measured from the center of the clipeus down to the middle of the back of the head.\",\n",
    "                      \"A2\": \"Horizontal length between the left and right sutures\",\n",
    "                      \"A3\": \"Horizontal length between the left and right eye’s canthus\",\n",
    "                      \"A4\": \"Vertical ortogonal length of the clipeus measured from the front down to A2 line\",\n",
    "                      \"A5\": \"Vertical ortogonal length of the clipeus measured from the front down to A3 line\",\n",
    "                      \"B1\": \"Horizontal length between the pronotum’s frontal angles\",\n",
    "                      \"B2\": \"Horizontal length between the pronotum’s middle angles\",\n",
    "                      \"B3\": \"Horizontal length between the pronotum’s hind angles\",\n",
    "                      \"B4\": \"Vertical length of the pronotum’s measured from the middle point of its front down to the middlepoint of its rear\",\n",
    "                      \"B5\": \"Angle of its side measured between the tangent lines to its straightest sections in the front and back, as seen from the top \",\n",
    "                      \"C1\": \"Angle of its side measured between the tangent lines to its straightest sections in the front and back as seen by the side\",\n",
    "                      \"D1\": \"Mesosternal process’ horizontal length measured from the secant point of the tangents of its sides with the horizontal line used to measure D1. \",\n",
    "                      \"D2\": \"Mesosternal process’ vertical length measured from the tip of the mesosternal process down to the line that joins the two lowest curves at the sides of the mesosternal process base\",\n",
    "                      \"D3\": \"Horizontal width of the dark middle line measured from its two lower ends\",\n",
    "                      \"D4\": \"Vertical length from the tip of the mesosternal process down to the lowest point of the black patch in the middle of the mesosternal process\",\n",
    "                      \"E1\": \"Horizontal top width of the prosternal plate \",\n",
    "                      \"E2\": \"Horizontal bottom width of the prosternal plate \",\n",
    "                      \"F1\": \"Vertical length of the foremost ventral plate\",\n",
    "                      \"F2\": \"Vertical length of the second foremost ventral plate\",\n",
    "                      \"F3\": \"Vertical length of the third foremost ventral plate\",\n",
    "                      \"F4\": \"Vertical length of the fourth foremost ventral plate \",\n",
    "                      \"F5\": \"Vertical length of the fifth foremost ventral plate\",\n",
    "                      \"W2\": \"A1/A3 Measure of the vertical length of beetle's head relative to its canthuses' distance width\",\n",
    "                      \"W3\": \"A4/A3 Measure of the vertical length of beetle's clipeum relative to its canthuses' distance width\",\n",
    "                      \"W4\": \"A5/A3 Measure of the vertical length of beetle's eyes relative to its canthuses' distance width\",\n",
    "                      \"W5\": \"Measure of the vertical length of the pronotum relative to its front width\",\n",
    "                      \"W6\": \"Measure of the vertical length of the pronotum relative to its middle width\",\n",
    "                      \"W7\": \"Measure of the vertical length of the pronotum relative to its back width\",\n",
    "                      \"W9\": \"Measure of the vertical length of the mesosternal process relative to its back width. D2/D1\",\n",
    "                      \"W10\": \"Measure of the vertical length of the mesosternal process relative to its middle width. D2/D3\",\n",
    "                      \"W13\": \"Measure of how square the prosternal plate is. Front width back width ratio E1/E2\",\n",
    "                     }\n",
    "\n",
    "statistical_analysis_text = \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bb138-91cb-4c7b-b8f7-3804d205fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#constants\n",
    "current_date = datetime.today().date()\n",
    "\n",
    "#methods\n",
    "def create_paragraph(text):\n",
    "    title_style = getSampleStyleSheet()[\"Title\"]\n",
    "    centered_title_style = ParagraphStyle(\n",
    "    name='CenteredTitle',\n",
    "    parent=title_style,\n",
    "    fontSize=14,\n",
    "    alignment=1  # 0 for left, 1 for center, 2 for right\n",
    "    )\n",
    "    content = Paragraph(text, centered_title_style)\n",
    "    return content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca737c-d567-4973-8ff6-091f7cffdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_page():\n",
    "    elements = []\n",
    "\n",
    "    # Title\n",
    "    title_style = getSampleStyleSheet()[\"Title\"]\n",
    "    title = Paragraph(\"Biometry report\", title_style)\n",
    "    elements.append(title)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Author\n",
    "    #author_style = getSampleStyleSheet()[\"Normal\"]\n",
    "    centered_title_style = ParagraphStyle(\n",
    "    name='CenteredTitle',\n",
    "    parent=title_style,\n",
    "    fontSize=14,\n",
    "    alignment=1  # 0 for left, 1 for center, 2 for right\n",
    "    )\n",
    "    #heading1_style = getSampleStyleSheet()[\"Heading3\"]\n",
    "    author = Paragraph(\"Dra. Marcela Hernández, Dr. Esteban Bermúdez Ureña, Angel Aguirre & Esteban Soto.\", centered_title_style)\n",
    "    elements.append(author)\n",
    "    elements.append(Spacer(1, 6))\n",
    "    institution = Paragraph(\"Centro de Investigación en Ciencia e Ingeniería de los Materiales\", centered_title_style)\n",
    "    elements.append(institution)\n",
    "    elements.append(create_paragraph(\"2025\"))\n",
    "    elements.append(create_paragraph(\"University of Costa Rica\"))\n",
    "    elements.append(create_paragraph(f\"{current_date}\"))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844575a8-5770-408f-8881-867c130aec84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def introduction_section(df):\n",
    "    \n",
    "    #Define sections and results\n",
    "    sections = {}\n",
    "    results =[]\n",
    "    information = []\n",
    "    information.append(PageBreak())\n",
    "\n",
    "    #Specimen count\n",
    "    number_of_kalinini_specimens = df[df[\"species\"] == \"kalinini\"][\"code\"].count()\n",
    "    number_of_resplendens_specimens = df[df[\"species\"] == \"resplendens\"][\"code\"].count()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Section 1: Introduction\n",
    "    description = []\n",
    "    title = [Paragraph(f\"Introduction\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "\n",
    "            Paragraph(f\"\"\"Zubov et al. (2019) describe a new species of Chrysina. \n",
    "            In its comparative analysis and remark it is stated that the new species is \n",
    "            very simmilar to C. resplendens and only few morphological differences can be\n",
    "            noted. This work intends to perform a quantitative analysis of these differences\n",
    "            using a sample of {number_of_kalinini_specimens} C. kalinini specimens and \n",
    "            {number_of_resplendens_specimens} C. resplendens specimens. \n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\" The measurements described in the article are specified more\n",
    "            precisely and alternative metrics are analyzed.\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            ]\n",
    "    description += title\n",
    "    \n",
    "\n",
    "    return description + information\n",
    "\n",
    "introduction_section(measurement_df_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9451d1-a372-4bc0-a74b-26557db572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methodology(df):\n",
    "    \n",
    "    #Define sections and results\n",
    "    sections = {}\n",
    "    results =[]\n",
    "    information = []\n",
    "    information.append(PageBreak())\n",
    "\n",
    "    #Specimen count\n",
    "    number_of_kalinini_specimens = df[df[\"species\"] == \"kalinini\"][\"code\"].count()\n",
    "    number_of_resplendens_specimens = df[df[\"species\"] == \"resplendens\"][\"code\"].count()\n",
    "    \n",
    "    #Locations\n",
    "    unique_locations_by_species = df.groupby(\"species\")[\"location_code\"].unique()\n",
    "\n",
    "    # Number of male and female specimens per species\n",
    "    number_of_kalinini_m_specimens = df[(df[\"species\"] == \"kalinini\") & (df[\"sex_code\"] == \"M\")][\"code\"].count()\n",
    "    number_of_kalinini_f_specimens = df[(df[\"species\"] == \"kalinini\") & (df[\"sex_code\"] == \"F\")][\"code\"].count()\n",
    "    number_of_kalinini_u_specimens = number_of_kalinini_specimens - number_of_kalinini_m_specimens -number_of_kalinini_f_specimens\n",
    "    \n",
    "    number_of_resplendens_m_specimens = df[(df[\"species\"] == \"resplendens\") & (df[\"sex_code\"] == \"M\")][\"code\"].count()\n",
    "    number_of_resplendens_f_specimens = df[(df[\"species\"] == \"resplendens\") & (df[\"sex_code\"] == \"F\")][\"code\"].count()\n",
    "    number_of_kalinini_u_specimens = number_of_kalinini_specimens - number_of_kalinini_m_specimens -number_of_kalinini_f_specimens\n",
    "\n",
    "    \n",
    "    # Section 1: Introduction\n",
    "    description = []\n",
    "    title = [Paragraph(f\"Methodology\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "\n",
    "            Paragraph(f\"\"\" Chrysina samples were retrieved from the following locations: {unique_locations_by_species}\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\"\n",
    "            Sex distribution is the following:\n",
    "            - C. kalinini: {number_of_kalinini_m_specimens} males, {number_of_kalinini_f_specimens} females , {number_of_kalinini_u_specimens} unknown\n",
    "            - C. resplendens: {number_of_resplendens_m_specimens} males, {number_of_resplendens_f_specimens} females, {number_of_kalinini_u_specimens} unknown\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\" Using an estereoscope its head, clipeum, mesosternal process, prosternal process and ventral plates were measured. \n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\"A OCR software was used to retrieve the measurements and to add contextual information about collection location, sex,\n",
    "            genus and species.\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\" Zubov's et al morphological differences were calculated using the metrics taken with the estereoscope.\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            Paragraph(f\"\"\" Afterwards, measurements were separated by species and a normality test was performed over the data. If the data was normal \n",
    "            and the variances between the populations are equal, a Student's T test was performed, if not a non-parametric Mann-Whitney U test was applied instead. If the p value was smaller than 0.05,\n",
    "            a statistical significant difference between the two species is determined.\n",
    "            \"\"\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 12),\n",
    "            #\n",
    "            ]\n",
    "    description += title\n",
    "    \n",
    "\n",
    "    return description + information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1192fa5-71dc-4047-89f5-3d8fdfb7553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_violin_plot(df, column, group_by):\n",
    "    \"\"\"Generates a violin plot for a given numerical column and returns a BytesIO buffer.\"\"\"\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.violinplot(x=df[group_by], y=df[column], inner=\"quartile\")\n",
    "    if not column.startswith(\"W\"):\n",
    "        plt.ylabel(\"length [$\\\\mu$m]\")\n",
    "    plt.title(f\"Violin Plot for {column}\")\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format=\"png\")\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "def get_metric_image(image_path):\n",
    "    \"\"\"Compresses and returns a ReportLab Image object.\"\"\"\n",
    "    basename = Path(image_path).name\n",
    "    original_image = PILImage.open(image_path)\n",
    "    compressed_image_path = f\"{basename}_c.jpg\"\n",
    "    \n",
    "    try:\n",
    "        original_image.save(compressed_image_path, \"JPEG\", quality=70)\n",
    "        return Image(compressed_image_path, width=200, height=200)\n",
    "    except:\n",
    "        original_image.save(compressed_image_path, \"PNG\", quality=100)\n",
    "        return Image(image_path, width=200, height=200) \n",
    "        \n",
    "def dataset_description(df, group_by=None):\n",
    "    \"\"\"Creates a dataset description report with violin plots and statistical analysis.\"\"\"\n",
    "    styles = getSampleStyleSheet()\n",
    "    description = []\n",
    "    description.append(Paragraph(\"Dataset Description\", styles[\"Heading2\"]))\n",
    "    description.append(Spacer(1, 12))\n",
    "    \n",
    "    description.append(Paragraph(\"Normality test\", styles[\"Heading3\"]))\n",
    "    description.append(Spacer(1, 12))\n",
    "    \n",
    "    description.append(Paragraph(f\"\"\" Shapiro-Wilk p-values for C. kalinini population are {normality_info_dict[\"kalinini\"]:.2f},\n",
    "                                    and for C. resplendens population are {normality_info_dict[\"kalinini\"]:.2f}\"\"\", styles[\"Normal\"]))\n",
    "    description.append(Spacer(1, 12))\n",
    "    description.append(Paragraph(\"Violin plots for each metric:\", styles[\"Heading3\"]))\n",
    "    description.append(Spacer(1, 12))\n",
    "    \n",
    "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        description.append(Paragraph(f\"Metric {column}\", styles[\"Heading3\"]))\n",
    "        description.append(Paragraph(f\"{metric_description.get(column, 'No description available.')}\", styles[\"Normal\"]))\n",
    "        description.append(Spacer(1, 12))\n",
    "        \n",
    "        # Generate violin plot\n",
    "        plot_buffer = generate_boxplot_with_stripplot(df, column, group_by=\"species\")\n",
    "        #plot_buffer = generate_violin_plot(df, column, group_by)\n",
    "        description.append(Image(plot_buffer, width=400*0.7, height=300*0.7))\n",
    "        \n",
    "        caption_text = f\"Figure {figure_counter}: Violin Plot for {column}\"\n",
    "        figure_counter += 1\n",
    "        caption_style = ParagraphStyle(name=\"CenteredCaption\", parent=styles[\"BodyText\"], alignment=1)\n",
    "        description.append(Paragraph(caption_text, caption_style))\n",
    "        description.append(Spacer(1, 12))\n",
    "    \n",
    "    description.append(PageBreak())\n",
    "    return description\n",
    "\n",
    "def statistical_analysis(df , figure_counter = figure_counter):\n",
    "    \"\"\"Generates a statistical analysis section with optional images.\"\"\"\n",
    "    styles = getSampleStyleSheet()\n",
    "    stat_analysis = [Paragraph(\"Statistical Analysis\", styles[\"Heading2\"]), Spacer(1, 12)]\n",
    "    \n",
    "    for metric, result in t_test_results.items():\n",
    "        stat_analysis.append(Paragraph(f\"Metric: {metric}\", styles[\"Heading3\"]))\n",
    "        stat_analysis.append(Paragraph(f\"{metric_description.get(metric, 'No description available.')}\", styles[\"Normal\"]))\n",
    "        \n",
    "        # Generate violin plot\n",
    "        plot_buffer = generate_boxplot_with_stripplot(df, metric, group_by=\"species\")\n",
    "        #plot_buffer = generate_violin_plot(df, metric, group_by = \"species\")\n",
    "        stat_analysis.append(Image(plot_buffer, width=400, height=300))\n",
    "        \n",
    "        caption_text = f\"Figure {figure_counter}: Violin Plot for {metric}\"\n",
    "        figure_counter += 1\n",
    "        caption_style = ParagraphStyle(name=\"CenteredCaption\", parent=styles[\"BodyText\"], alignment=1)\n",
    "        stat_analysis.append(Paragraph(caption_text, caption_style))\n",
    "        stat_analysis.append(Spacer(1, 12))\n",
    "\n",
    "        #test results\n",
    "        stat_analysis.append(Paragraph(f\"Test Type: {result['test_type']}\", styles[\"Normal\"]))\n",
    "        stat_analysis.append(Paragraph(f\"Test Statistic: {result.get('t_stat', result.get('u_stat'))}\", styles[\"Normal\"]))\n",
    "        stat_analysis.append(Paragraph(f\"P-value: {result['p_value']}\", styles[\"Normal\"]))\n",
    "        stat_analysis.append(Paragraph(f\"Interpretation: {result['interpretation']}\", styles[\"Normal\"]))\n",
    "        stat_analysis.append(Spacer(1, 12))\n",
    "        stat_analysis.append(PageBreak())\n",
    "        \n",
    "        # Include image only if metric does not start with 'W'\n",
    "        if not metric.startswith(\"W\") and metric in metric_image:\n",
    "            \n",
    "            image_path = Path(protocol_image_location) /metric_image[metric]\n",
    "            img = get_metric_image(image_path)\n",
    "            stat_analysis.append(img)\n",
    "            caption_text = f\"Figure {figure_counter}: Metric {metric}\"\n",
    "            figure_counter += 1\n",
    "            caption_style = ParagraphStyle(name=\"CenteredCaption\", parent=styles[\"BodyText\"], alignment=1)\n",
    "            stat_analysis.append(Paragraph(caption_text, caption_style))\n",
    "        \n",
    "        stat_analysis.append(Spacer(1, 12))\n",
    "        stat_analysis.append(PageBreak())\n",
    "    \n",
    "    return stat_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eb332-0c98-424b-9dd8-c7361893355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Table, TableStyle\n",
    "from reportlab.lib import colors\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dataframe_to_pdf_table(df):\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame to a ReportLab Table with Jupyter-like styling.\n",
    "    Automatically adjusts column widths based on content.\n",
    "    \"\"\"\n",
    "    table_1_col = [\"A1\", \"W2\", \"W3\", \"W4\", \"W5\"]\n",
    "    table_2_col = [\"W6\", \"W7\", \"W9\", \"W10\", \"W13\"]\n",
    "\n",
    "    df1 = df[table_1_col]\n",
    "    df2 = df[table_2_col]\n",
    "\n",
    "    info = []\n",
    "    dataframes = [df1, df2]\n",
    "\n",
    "    for df in dataframes:\n",
    "        \n",
    "        # Format numbers in the DataFrame to 3 decimal places\n",
    "        df = df.round(3)\n",
    "    \n",
    "        # Convert DataFrame to list of lists (including column headers)\n",
    "        data = [df.columns.to_list()] + df.values.tolist()\n",
    "\n",
    "        # Auto-calculate column widths based on max text length\n",
    "        col_widths = [max(len(str(val)) for val in df[col]) * 5 for col in df.columns]\n",
    "\n",
    "        # Define table style without vertical black lines\n",
    "        style = TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),  # Header row background\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),  # Header row text color\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),  # Header font\n",
    "            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),  # Body font\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 6),  # Padding for header\n",
    "            ('BACKGROUND', (0, 1), (-1, -1), colors.whitesmoke),  # Light gray background for body\n",
    "            ('LINEBELOW', (0, 0), (-1, 0), 1, colors.black),  # Line below header\n",
    "            ('LINEBELOW', (0, -1), (-1, -1), 1, colors.black),  # Line below last row\n",
    "            ('BOX', (0, 0), (-1, -1), 1, colors.black),  # Outer border\n",
    "        ])\n",
    "\n",
    "        # Create table with dynamic column widths\n",
    "        table = Table(data, colWidths=col_widths)\n",
    "        table.setStyle(style)\n",
    "        info.append(table)\n",
    "\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f830c6-798a-47d7-bd4c-9ba3f058a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclusion(df):\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = [Paragraph(\"Comparison with Zubov et al. claims\", styles[\"Heading3\"]), Spacer(1, 12)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    claims = [Paragraph(\"Claim 1\", styles[\"Heading4\"]), Spacer(1, 12),\n",
    "                Paragraph(\"\"\"\n",
    "                The new species is very close to C. resplendens and has only few morphological\n",
    "    differences from it. Clypeus of C. kalinini sp.n. is slightly longer t han in C. resplendens\n",
    "                \"\"\", styles[\"Italic\"]), Spacer(1, 12),\n",
    "                Paragraph(\"\"\" Head's vertical length- canthuses-width ratio, W2, \n",
    "               does not show a statistically significant difference. Whereas,\n",
    "               A2, the distance between sutures; and A3, distances between canthuses, are both \n",
    "               statistically significant. These can be used as alternatives to W2.\n",
    "                \"\"\", styles[\"Normal\"]), Spacer(1, 12),\n",
    "                Paragraph(\"Claim 2\", styles[\"Heading4\"]), Spacer(1, 12),\n",
    "                Paragraph(\"\"\"\n",
    "                Pronotum in C. kalinini sp.n. is slightly longer in relation to its width than in C. resplendens , its sides have smaller\n",
    "    angles, whereas in C. resplendens the sides of pronotum are rounded.\n",
    "                \"\"\", styles[\"Italic\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\"\" \n",
    "               None of the pronotum's vertical length - horizontal width ratios (Metrics W5,W6,W7) showed a significant difference between species.\n",
    "                \"\"\", styles[\"Normal\"]), Spacer(1, 12),\n",
    "               Paragraph(\"Claim 3\", styles[\"Heading4\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\"\"\n",
    "                Mesosternal process shiny, short\n",
    "                er and wider than in C. resplendens, where the process is long and narrow and its\n",
    "                apical half is greenish golden (Fig. 6 8).\n",
    "                \"\"\", styles[\"Italic\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\"\"\n",
    "                There is a significant difference between the absolute vertical length values\n",
    "                between the two species (Metric D2, figure 23).\n",
    "                There is no significant differences in their widths (Metrics D1 and D3). \n",
    "                There is a significant difference between species on its vertical distance between\n",
    "                the tip of its mesosternal process and the lower point of the dark curve in the\n",
    "                middle of it. \n",
    "                \"\"\", styles[\"Normal\"]), Spacer(1, 12),\n",
    "               Paragraph(\"Claim 4\", styles[\"Heading4\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\"\"\n",
    "                Prosternal plate of\n",
    "                C. kalinini sp.n. is rounded triangular and flat, in C. resplendens it is square and has a clear dent\n",
    "                \"\"\", styles[\"Italic\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\"\"\n",
    "                Albeit there is a difference between the absolute values of the foremost width of the \n",
    "                prosternal process (Metric E1, figure 29), there is no significant difference in how square \n",
    "                the prosternal plate is for each one of the species when the ratio of lengths is accounted for\n",
    "                (Metric W13, ratio between E1 and E2. Figure 51)\n",
    "                \"\"\", styles[\"Normal\"]), Spacer(1, 12),\n",
    "               \n",
    "              ]\n",
    "    claims.append(PageBreak())\n",
    "    content += claims\n",
    "    # Summary table of tests\n",
    "    \n",
    "    comparative = [Paragraph(\"Comparative table\", styles[\"Heading3\"]), Spacer(1, 12),]\n",
    "\n",
    "    content += comparative\n",
    "    content += dataframe_to_pdf_table(df)\n",
    "    \n",
    "    content.append(PageBreak())\n",
    "\n",
    "    \n",
    "    return content\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6795cc6-fc62-423b-baa9-2ab710586a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bibliography():\n",
    "    bibliography = [Paragraph(\"References\", getSampleStyleSheet()[\"Heading1\"]), Spacer(1, 12),\n",
    "                    Paragraph(\"\"\"1. Zubov, A.S.; Ivshin, N.V.; Titarenko, A. Y.; Andrianov, B.V.  (2019). Description of a new species of\n",
    "                    Chrysina Kirby, 1828 (Coleoptera:Scarabaeidae: Rutelinae) from resplendens group, based on morphological characters\n",
    "                    and mtDNA COX I molecular marker. Acta Biologica Sibirica, 5(1), 71–76.\"\"\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    #Paragraph(\"2. Author B, et al. (Year). Title of the paper. Journal Name, Volume(Issue), Page Numbers.\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 24)]\n",
    "    return bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0a8ab-a333-4f1b-ae2f-fc89e9acf137",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_results_df = pd.DataFrame(t_test_results)\n",
    "\n",
    "print(t_test_results_df.columns)\n",
    "t_test_results_df[[\"A1\",\"W2\",\"W3\",\"W4\",\"W5\",\"W6\",\"W7\",\"W9\",\"W10\",\"W13\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d3de9-9ef1-4fe9-a973-2af4c43b184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_location = \"\"\n",
    "# Create PDF report\n",
    "def create_report():\n",
    "    #filter to only kalinini and resplendens\n",
    "    measurement_df = measurement_df_2[measurement_df_2[\"species\"].isin([\"kalinini\", \"resplendens\"])]\n",
    "\n",
    "    elements = []\n",
    "    elements += front_page()\n",
    "    elements += introduction_section(information_df)\n",
    "    elements += methodology(information_df)\n",
    "    #elements += dataset_description(measurement_df_2, group_by=\"species\", figure_counter = figure_counter)\n",
    "    elements += statistical_analysis(df = measurement_df, figure_counter = figure_counter)\n",
    "    #elements += results_and_discussion(measurement_df_2)\n",
    "    #sections, sections_start_pages = create_sections()\n",
    "\n",
    "    ##elements += sections\n",
    "    elements += conclusion(df = t_test_results_df)\n",
    "    elements += create_bibliography()\n",
    "\n",
    "    # # Update table of contents with page numbers\n",
    "    # toc_style = getSampleStyleSheet()[\"Heading1\"]\n",
    "    # #toc_data = [[Paragraph(section, toc_style), str(page_num)] for section, page_num in sections_start_pages.items()]\n",
    "    # toc_data = [\"1\"]\n",
    "    # toc_table = Table(toc_data)\n",
    "    # toc_table.setStyle(TableStyle([('ALIGN', (0, 0), (-1, -1), 'CENTER')]))\n",
    "    # elements[-1] = toc_table\n",
    "    # elements += create_table_of_contents(toc_data)\n",
    "    \n",
    "    # Get current date\n",
    "    \n",
    "    \n",
    "    location = os.path.join(report_location, f\"Biometry report {current_date}.pdf\" )\n",
    "    doc = SimpleDocTemplate(location, pagesize=letter)\n",
    "    doc.build(elements)\n",
    "    print(f\"The report was saved at {location} \")\n",
    "create_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ba3e8-a19f-4885-b459-5a7585656f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb1ef2-9fe0-4b9e-b0d6-82cb172733e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee3ba6-1f11-4aac-a675-7e826c78f9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
