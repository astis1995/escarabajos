{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f814dbfe-e40f-4555-969c-058526eb7f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esteb\\cicima\\escarabajos\\gamma\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Add the current directory to the Python path\n",
    "sys.path.append(current_directory)\n",
    "print(current_directory)\n",
    "\n",
    "from spectraltools import Specimen_Collection, Spectrum, create_path_if_not_exists\n",
    "from metrics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922f2211-60c3-42b9-9e13-a88edf9da0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This section allows the user to choose their workplace location.\n",
    "This is important if the user has multiple locations and operating systems in which this \n",
    "script is run\"\"\"\n",
    "\n",
    "#select location\n",
    "working_at = \"wfh\"\n",
    "\n",
    "#Training data is used when we are already certain of species and genera for a particular sample\n",
    "training_data_is_used = False\n",
    "\n",
    "if working_at == \"colaboratory\":\n",
    "  from google.colab import drive\n",
    "  drive.mount(\"/content/drive\")\n",
    "  #base folder\n",
    "  \"\"\"Select the location for your base folder\"\"\"\n",
    "    \n",
    "  base_folder = r\"/content/drive/My Drive/CICIMA/escarabajos_files\"\n",
    "  \n",
    "elif working_at == \"wfh\":\n",
    "\n",
    "    \"\"\"Select the location of your base folder\"\"\"\n",
    "    base_folder = r\"C:\\Users\\esteb\\cicima\\escarabajos\"\n",
    "\n",
    "elif working_at == \"cicima_desktop\":\n",
    "  \n",
    "    \"\"\"Select the location of your base folder\"\"\"\n",
    "    base_folder = r\"C:\\Users\\EstebanSoto\\Jupyter\\escarabajos\"\n",
    "\n",
    "elif working_at == \"cicima_laptop\":\n",
    "    \n",
    "    \"\"\"Select the location of your base folder\"\"\"\n",
    "    base_folder = r\"/home/vinicio/escarabajos\"\n",
    "\n",
    "#define the location of the tables with information about the collections and its parent directory\n",
    "\n",
    "collection_tables_main_path =  os.path.join(base_folder, \"L1050_data\",\"collections\")\n",
    "collection_files_main_path = os.path.join(base_folder, \"L1050_data\")\n",
    "\n",
    "# Define report location\n",
    "report_location = os.path.join(base_folder, \"reports\",\"data_analysis\")\n",
    "\n",
    "#collection_descriptor = r\"CICIMAUCR and ANGSOL\" tododelete\n",
    "\n",
    "#File location and metadata location for collection 1\n",
    "angsol_collection_path = os.path.join(collection_files_main_path,\"ANGSOL\",\"average\") \n",
    "angsol_collection_metadata = os.path.join(collection_tables_main_path,\"CICIMA-beetles-general-inventory - ANGSOL.txt\") \n",
    "\n",
    "#File location and metadata location for collection 2\n",
    "cicimaucr_collection_path = os.path.join(collection_files_main_path,r\"TRA_data_CICIMA_INBUCR\",\"CICIMAUCR\",\"reflectance\")  #listo\n",
    "cicimaucr_collection_2_path = os.path.join(collection_files_main_path,r\"CICIMA-2024-01-REFLECTANCE\",\"average\")\n",
    "cicimaucr_collection_3_path = os.path.join(collection_files_main_path,r\"CICIMA-2024-03-REFLECTANCE\",\"without iris nor lens\",\"average\")\n",
    "cicimaucr_collection_4_path = os.path.join(collection_files_main_path,r\"CICIMA-2024-05-REFLECTANCE\",\"average\")\n",
    "cicima_ucr_metadata = os.path.join(collection_tables_main_path,r\"CICIMA-beetles-general-inventory - CICIMAUCR.txt\") \n",
    "\n",
    "#File location and metadata location for collection 3\n",
    "inbucr_collection_path = os.path.join(collection_files_main_path,r\"INBUCR\",\"average\") #listo\n",
    "inbucr_metadata = os.path.join(collection_tables_main_path,r\"CICIMA-beetles-general-inventory - INBUCR.txt\") \n",
    "\n",
    "#File location and metadata location for collection 4\n",
    "bioucr_collection_path = os.path.join(collection_files_main_path,r\"BIOUCR\",\"average\")  #listo\n",
    "bioucr_metadata = os.path.join(collection_tables_main_path,r\"CICIMA-beetles-general-inventory - BIOUCR.txt\") \n",
    "\n",
    "#agregated data location, here averages and std will be saved when training data and retreived when classifying spectra\n",
    "agregated_data_location = os.path.join(base_folder, \"aggregated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69b7d8f-51dd-4b86-b530-0fdf2ff98f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<spectraltools.Spectrum at 0x1f7f9a48970>,\n",
       " <spectraltools.Spectrum at 0x1f7f9a48ee0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9a48190>,\n",
       " <spectraltools.Spectrum at 0x1f7f9a4b6a0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9a4b070>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afbc40>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb970>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb640>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afbbb0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb5b0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb3a0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb820>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afbeb0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afb670>,\n",
       " <spectraltools.Spectrum at 0x1f7f9afbf70>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b109a0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b107c0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b10e50>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b10cd0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b10970>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b07970>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b106a0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b10280>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b1b220>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b1b0d0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b1b9a0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b07fd0>,\n",
       " <spectraltools.Spectrum at 0x1f7f9b1bac0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collections\n",
    "angsol_collection = Specimen_Collection(\"ANGSOL\", angsol_collection_path, angsol_collection_metadata, \"HIGH\")\n",
    "angsol_collection.set_description(\"ANGSOL collection has specimens that belong to Angel Sol√≠s. The confidence that we have about specimen identification is high.\")\n",
    "\n",
    "cicimaucr_collection = Specimen_Collection(\"CICIMAUCR1\", cicimaucr_collection_path, cicima_ucr_metadata, \"HIGH\")\n",
    "cicimaucr_collection_2 = Specimen_Collection(\"CICIMAUCR2\", cicimaucr_collection_2_path, cicima_ucr_metadata, \"HIGH\")\n",
    "cicimaucr_collection_3 = Specimen_Collection(\"CICIMAUCR3\", cicimaucr_collection_3_path, cicima_ucr_metadata, \"HIGH\")\n",
    "cicimaucr_collection_3.set_description(\"\"\"The most part of CICIMA specimens belongs to this collecttion\"\"\")\n",
    "\n",
    "cicimaucr_collection_4 = Specimen_Collection(\"CICIMAUCR4\", cicimaucr_collection_4_path, cicima_ucr_metadata, \"HIGH\")\n",
    "cicimaucr_collection_4.set_description(\"\"\"This collection has 3 kalinini specimens which were not used in training. \n",
    "                                        These are intended to be used as test subjects\"\"\")\n",
    "\n",
    "inbucr_collection = Specimen_Collection(\"INBUCR\", inbucr_collection_path, inbucr_metadata, \"MID\")\n",
    "bioucr_collection = Specimen_Collection(\"BIOUCR\", bioucr_collection_path, bioucr_metadata, \"LOW\")\n",
    "\n",
    "collection_list = [\n",
    "                    #angsol_collection,\n",
    "                    cicimaucr_collection,\n",
    "                    cicimaucr_collection_2,\n",
    "                    cicimaucr_collection_3,\n",
    "                    #inbucr_collection,\n",
    "                    #bioucr_collection,\n",
    "                    ]\n",
    "collection_names_set = set([collection.name for collection in collection_list])\n",
    "collection_names = \" \".join( sorted(collection_names_set))\n",
    "\n",
    "prediction_list = [\n",
    "                    #angsol_collection,\n",
    "                    #cicimaucr_collection,\n",
    "                    #cicimaucr_collection_2,\n",
    "                    #cicimaucr_collection_3,\n",
    "                    cicimaucr_collection_4,\n",
    "                    #inbucr_collection,\n",
    "                    #bioucr_collection,\n",
    "                    ]\n",
    "prediction_collection_names_set = set([collection.name for collection in collection_list])\n",
    "prediction_collection_names = \" \".join( sorted(collection_names_set))\n",
    "\n",
    "\n",
    "#print(collection_names)\n",
    "#date\n",
    "from datetime import datetime\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "def get_filtered_spectra(collection_list):\n",
    "\n",
    "    all_spectra = []\n",
    "    \n",
    "    for collection in collection_list:\n",
    "        all_spectra += collection.get_spectra()\n",
    "\n",
    "    all_spectra = [item for item in all_spectra if item.get_species() in [\"kalinini\", \"resplendens\", \"cupreomarginata\"]]\n",
    "    return all_spectra\n",
    "    \n",
    "def get_spectra(collection_list):\n",
    "\n",
    "    all_spectra = []\n",
    "    \n",
    "    for collection in collection_list:\n",
    "        all_spectra += collection.get_spectra()\n",
    "\n",
    "    return all_spectra  \n",
    "    \n",
    "training_spectra = get_filtered_spectra(collection_list)\n",
    "prediction_spectra  = get_spectra(prediction_list) \n",
    "\n",
    "for spectrum in prediction_spectra:\n",
    "    print(spectrum.get_species())\n",
    "\n",
    "training_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca2d18c-6d96-4c8c-92ed-d12ae453aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(lst, filler=0):\n",
    "    metrics = lst[1]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        #print(metric)\n",
    "        \n",
    "        max_length = max([len(list) for list in metrics])\n",
    "        \n",
    "        #print(max_length)\n",
    "        \n",
    "        padded_list = []\n",
    "\n",
    "        for element in metrics:\n",
    "\n",
    "            padded_sublist = element\n",
    "            \n",
    "            padded_sublist += [filler] * (max_length - len(padded_sublist))\n",
    "            padded_list.append(padded_sublist)\n",
    "            #print(padded_sublist)\n",
    "    final_list = [lst[0], np.array(padded_list), lst[2]]\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a45db8-0a26-430d-9fdc-c638f18bf2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data \n",
    "\n",
    "#scalar\n",
    "gamma_arbitrary_limits_data = feature_and_label_extractor(Gamma_Arbitrary_Limits, training_spectra)\n",
    "gamma_first_two_peaks_data = feature_and_label_extractor(Gamma_First_Two_Peaks, training_spectra)\n",
    "gamma_area_under_curve_data = feature_and_label_extractor(Gamma_Area_Under_Curve_Naive, training_spectra)\n",
    "gamma_area_under_curve_first_min_cut_data = feature_and_label_extractor(Gamma_Area_Under_Curve_First_Min_Cut, training_spectra)\n",
    "\n",
    "#vectorial\n",
    "gamma_vector_relative_reflectance_data = feature_and_label_extractor(Gamma_Vector_Relative_Reflectance, training_spectra)\n",
    "wavelength_vector_data = feature_and_label_extractor(Wavelength_Vector, training_spectra)\n",
    "critical_points_data = feature_and_label_extractor(Critical_Points, training_spectra)\n",
    "                                                  \n",
    "maximum_points_data = feature_and_label_extractor(Maximum_Points, training_spectra)\n",
    "minimum_points_data = feature_and_label_extractor(Minimum_Points, training_spectra)\n",
    "maximum_points_normalized_data = feature_and_label_extractor(Maximum_Points_Normalized, training_spectra)\n",
    "minimum_points_normalized_data = feature_and_label_extractor(Minimum_Points_Normalized, training_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0743c0b-5a80-4a88-87f8-af219a07aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CICIMAUCR0104',\n",
       "  'CICIMAUCR0105',\n",
       "  'CICIMAUCR0158',\n",
       "  'CICIMAUCR0001',\n",
       "  'CICIMAUCR0006',\n",
       "  'CICIMAUCR0008',\n",
       "  'CICIMAUCR0009',\n",
       "  'CICIMAUCR0012',\n",
       "  'CICIMAUCR0013',\n",
       "  'CICIMAUCR0014',\n",
       "  'CICIMAUCR0015',\n",
       "  'CICIMAUCR0018',\n",
       "  'CICIMAUCR0019',\n",
       "  'CICIMAUCR0020',\n",
       "  'CICIMAUCR0021',\n",
       "  'CICIMAUCR0070',\n",
       "  'CICIMAUCR0071',\n",
       "  'CICIMAUCR0097',\n",
       "  'CICIMAUCR0098',\n",
       "  'CICIMAUCR0100',\n",
       "  'CICIMAUCR0101',\n",
       "  'CICIMAUCR0104',\n",
       "  'CICIMAUCR0108',\n",
       "  'CICIMAUCR0112',\n",
       "  'CICIMAUCR0113',\n",
       "  'CICIMAUCR0116',\n",
       "  'CICIMAUCR0141',\n",
       "  'CICIMAUCR0158'],\n",
       " [[array([ 586.,  755., 1385.]), array([75.594599, 80.225793, 33.293938])],\n",
       "  [array([ 586.,  776., 1396., 1668.]),\n",
       "   array([63.605839, 82.017313, 33.658805, 27.925045])],\n",
       "  [array([ 572.,  742., 1113., 1213.]),\n",
       "   array([61.776244, 52.898355, 21.963665, 21.272537])],\n",
       "  [array([ 567.,  765., 1123., 1300., 1649., 1848.]),\n",
       "   array([65.361779, 88.156557, 67.663   , 67.7368  , 47.5637  , 43.790775])],\n",
       "  [array([ 550.,  772.,  858., 1119., 1303., 1654., 1858.]),\n",
       "   array([37.871428, 61.37373 , 52.492067, 51.588067, 49.532067, 26.7769  , 26.644867])],\n",
       "  [array([ 573.,  742.,  858., 1118., 1304.]),\n",
       "   array([57.565073, 74.750457, 52.743267, 52.9868  , 49.434433])],\n",
       "  [array([ 577.,  797.,  858., 1119., 1304., 1654., 1860.]),\n",
       "   array([69.666709, 84.574415, 70.661133, 65.221267, 61.962967, 31.235167, 31.7083  ])],\n",
       "  [array([ 546.,  804., 1119., 1298., 1658., 1753., 1860.]),\n",
       "   array([43.788362, 46.713055, 52.704367, 50.181533, 25.3587  , 20.338067, 25.5469  ])],\n",
       "  [array([ 568.,  684.,  809.,  870., 1119., 1303., 1552., 1656., 1860.]),\n",
       "   array([78.927183, 66.082296, 78.759525, 68.628633, 63.202667, 60.598   , 27.9534  , 32.246233, 32.5331  ])],\n",
       "  [array([ 577.,  858.,  917., 1117., 1301., 1656., 1857.]),\n",
       "   array([60.467787, 67.2034  , 73.7078  , 69.3332  , 64.4236  , 34.3696  , 34.105467])],\n",
       "  [array([ 578.,  692.,  795.,  858., 1119., 1304., 1555., 1654., 1858.]),\n",
       "   array([78.682421, 66.547396, 81.209474, 68.8854  , 63.3605  , 60.968267, 29.784733, 33.7103  , 33.916033])],\n",
       "  [array([ 569.,  894., 1112., 1295., 1656., 1858.]),\n",
       "   array([60.598799, 62.712325, 56.7179  , 51.78175 , 26.503475, 26.48465 ])],\n",
       "  [array([ 566.,  894., 1118., 1301., 1655., 1754., 1857.]),\n",
       "   array([59.022762, 61.529   , 63.377225, 59.60595 , 31.208625, 25.80575 , 31.2811  ])],\n",
       "  [array([ 585.,  784.,  858., 1107., 1302., 1656., 1753., 1858.]),\n",
       "   array([64.678125, 66.787822, 61.3677  , 54.7888  , 52.52872 , 29.72922 , 24.76638 , 29.57326 ])],\n",
       "  [array([ 577.,  803.,  858., 1121., 1303., 1654., 1858.]),\n",
       "   array([54.679584, 55.885959, 51.445867, 49.750833, 48.560033, 26.187667, 26.319733])],\n",
       "  [array([ 584.,  900., 1108., 1297., 1648., 1847.]),\n",
       "   array([57.416235, 80.9879  , 77.821467, 76.182033, 59.012233, 54.4288  ])],\n",
       "  [array([ 572.,  741.,  881., 1122., 1298., 1641., 1697., 1847.]),\n",
       "   array([75.083029, 81.820539, 68.704133, 71.0864  , 69.9274  , 46.0767  , 41.291833, 41.8653  ])],\n",
       "  [array([ 596.,  803.,  858., 1129., 1306., 1652., 1854.]),\n",
       "   array([62.57691 , 82.512479, 74.738767, 53.204033, 56.2633  , 40.3293  , 37.231133])],\n",
       "  [array([ 568.,  858., 1117., 1295., 1657., 1857.]),\n",
       "   array([61.440618, 61.921867, 55.568967, 50.300567, 21.296767, 21.475033])],\n",
       "  [array([ 570.,  887., 1118., 1302., 1651., 1857.]),\n",
       "   array([59.046779, 62.695667, 64.496   , 61.772267, 37.6115  , 36.493667])],\n",
       "  [array([ 585.,  741., 1117., 1304.]),\n",
       "   array([90.643824, 86.892313, 60.844733, 53.7168  ])],\n",
       "  [array([ 493.,  586.,  756.,  881., 1123., 1305., 1654., 1857.]),\n",
       "   array([34.494916, 84.065535, 83.368833, 71.811433, 68.127033, 67.133867, 39.885667, 39.461367])],\n",
       "  [array([ 582.,  690.,  820., 1119., 1302., 1653., 1857.]),\n",
       "   array([85.318426, 65.754227, 80.225809, 60.949967, 59.333567, 35.683633, 34.827833])],\n",
       "  [array([ 579.,  800., 1119., 1304., 1557., 1655., 1860.]),\n",
       "   array([86.413042, 86.556177, 74.9452  , 71.5834  , 35.2859  , 40.184267, 40.134833])],\n",
       "  [array([ 587.,  769.,  858., 1118., 1305.]),\n",
       "   array([61.504072, 79.835077, 62.561633, 55.593967, 52.172333])],\n",
       "  [array([ 581.,  790.,  859., 1122., 1299., 1653., 1856.]),\n",
       "   array([69.376085, 97.701462, 82.1661  , 67.594867, 66.780167, 39.8064  , 38.0611  ])],\n",
       "  [array([ 580.,  773.,  858., 1129., 1302., 1647., 1698., 1849.]),\n",
       "   array([74.927905, 94.569538, 75.593933, 65.8094  , 68.464533, 45.238   , 40.062033, 40.276267])],\n",
       "  [array([ 566.,  825.,  890., 1119., 1296., 1651., 1848.]),\n",
       "   array([57.159646, 60.416142, 61.155725, 64.938   , 63.194525, 46.8466  , 43.2865  ])]],\n",
       " ['resplendens',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'cupreomarginata',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'cupreomarginata']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_points_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba06b25-64e0-49cf-83fe-65fec67eee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\esteb\\cicima\\escarabajos\\aggregated_data\\metric_avg_std' already exists.\n",
      "Directory 'C:\\Users\\esteb\\cicima\\escarabajos\\aggregated_data\\metric_avg_std' already exists.\n",
      "Directory 'C:\\Users\\esteb\\cicima\\escarabajos\\aggregated_data\\metric_avg_std' already exists.\n",
      "Directory 'C:\\Users\\esteb\\cicima\\escarabajos\\aggregated_data\\metric_avg_std' already exists.\n",
      "Directory 'C:\\Users\\esteb\\cicima\\escarabajos\\aggregated_data\\metric_avg_std' already exists.\n"
     ]
    }
   ],
   "source": [
    "#Save averages and std for training data\n",
    "metrics_list = [Gamma_Arbitrary_Limits, Gamma_First_Two_Peaks, Gamma_Area_Under_Curve_Naive, Gamma_Area_Under_Curve_First_Min_Cut, \n",
    "                Gamma_Area_Under_Curve_First_Min_Cut]\n",
    "\n",
    "for metric in metrics_list:\n",
    "    save_aggregated_data(metric,training_spectra,agregated_data_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef85ed7-7afc-459d-ba90-9ff83f0e318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gamma_Arbitrary_Limits.txt', 'gamma_area_under_curve_cut_first_minimum.txt', 'Gamma_Area_Under_Curve_Naive.txt', 'Gamma_First_Two_Peaks.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Gamma_Arbitrary_Limits.txt':            species      mean       std\n",
       " 0  cupreomarginata  1.230355  0.627756\n",
       " 1         kalinini  1.413579  0.168335\n",
       " 2      resplendens  1.309400  0.283687,\n",
       " 'gamma_area_under_curve_cut_first_minimum.txt':            species      mean       std\n",
       " 0  cupreomarginata  3.756872  0.778950\n",
       " 1         kalinini  2.598407  0.468501\n",
       " 2      resplendens  2.334925  1.246243,\n",
       " 'Gamma_Area_Under_Curve_Naive.txt':            species      mean       std\n",
       " 0  cupreomarginata  2.205516  0.506670\n",
       " 1         kalinini  1.872984  0.213630\n",
       " 2      resplendens  1.934388  0.480075,\n",
       " 'Gamma_First_Two_Peaks.txt':            species      mean       std\n",
       " 0  cupreomarginata  1.029802  0.076122\n",
       " 1         kalinini  1.339818  0.118268\n",
       " 2      resplendens  1.133386  0.464311}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read averages and std\n",
    "avg_std_location = os.path.join(agregated_data_location, \"metric_avg_std\")\n",
    "dfs = read_aggregated_data(avg_std_location)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cbf28-4422-4095-af2a-5402c3d8608d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3276d2d2-3bdf-48f6-8b8f-95088968fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity index\n",
    "\n",
    "def similarity_index(spectrum, averages_df, standard_deviations_df , species):\n",
    "    def distance(x, x0, sigma_0):\n",
    "        index =  (((x - x0)**4)**(1/4))\n",
    "        #print(f\" x {x} - x0 {x0} = {(x - x0)} and index = {index}\")\n",
    "        return index\n",
    "        #def get_gamma_factor(self, spectrum):\n",
    "    #get first n peaks of the gamma\n",
    "    n = 5\n",
    "    peaklist = PeakList(spectrum)\n",
    "    peaks = peaklist.get_peaks()[0:n]\n",
    "\n",
    "    #loads species average values:\n",
    "\n",
    "    averages_df = averages_df[averages_df[\"species\"] == species]\n",
    "    average_x_df = averages_df[[\"x0\",\"x1\",\"x2\",\"x4\",\"x5\"]].values[0]\n",
    "\n",
    "    standard_deviations_df = standard_deviations_df[standard_deviations_df[\"species\"] == species]\n",
    "    standard_deviation_x_df = standard_deviations_df[[\"x0\",\"x1\",\"x2\",\"x4\",\"x5\"]].values[0]\n",
    "\n",
    "    #print(f\"averages_df: {averages_df}\")\n",
    "    #for each peak, calculate the distances to the averages x values\n",
    "    similarity_index = 0.0\n",
    "\n",
    "    for peak_i,xi_0, sigmai_0 in zip(peaks, average_x_df, standard_deviation_x_df):\n",
    "        xi = peak_i.x_value\n",
    "        similarity_index += distance(xi, xi_0, sigmai_0)\n",
    "\n",
    "    #normalize for the number of points\n",
    "    similarity_index = similarity_index/n\n",
    "    #print(f\"gamma: {gamma}\")\n",
    "    return similarity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42be5642-9c7f-4ab6-a80e-bf266f97035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data\n",
    "\n",
    "prediction_gamma_arbitrary_limits_data = feature_and_label_extractor(Gamma_Arbitrary_Limits, prediction_spectra)\n",
    "prediction_gamma_first_two_peaks_data = feature_and_label_extractor(Gamma_First_Two_Peaks, prediction_spectra)\n",
    "prediction_gamma_area_under_curve_data = feature_and_label_extractor(Gamma_Area_Under_Curve_Naive, prediction_spectra)\n",
    "prediction_gamma_area_under_curve_first_min_cut_data = feature_and_label_extractor(Gamma_Area_Under_Curve_First_Min_Cut, prediction_spectra)\n",
    "prediction_gamma_vector_relative_reflectance_data = feature_and_label_extractor(Gamma_Vector_Relative_Reflectance, prediction_spectra)\n",
    "prediction_critical_points_data = feature_and_label_extractor(Critical_Points, prediction_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c47b6-b30e-46d0-a704-8763006bae27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a690e936-3ba5-4db4-90d2-201fe5796470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CICIMAUCR0104',\n",
       "  'CICIMAUCR0105',\n",
       "  'CICIMAUCR0158',\n",
       "  'CICIMAUCR0001',\n",
       "  'CICIMAUCR0006',\n",
       "  'CICIMAUCR0008',\n",
       "  'CICIMAUCR0009',\n",
       "  'CICIMAUCR0012',\n",
       "  'CICIMAUCR0013',\n",
       "  'CICIMAUCR0014',\n",
       "  'CICIMAUCR0015',\n",
       "  'CICIMAUCR0018',\n",
       "  'CICIMAUCR0019',\n",
       "  'CICIMAUCR0020',\n",
       "  'CICIMAUCR0021',\n",
       "  'CICIMAUCR0070',\n",
       "  'CICIMAUCR0071',\n",
       "  'CICIMAUCR0097',\n",
       "  'CICIMAUCR0098',\n",
       "  'CICIMAUCR0100',\n",
       "  'CICIMAUCR0101',\n",
       "  'CICIMAUCR0104',\n",
       "  'CICIMAUCR0108',\n",
       "  'CICIMAUCR0112',\n",
       "  'CICIMAUCR0113',\n",
       "  'CICIMAUCR0116',\n",
       "  'CICIMAUCR0141',\n",
       "  'CICIMAUCR0158'],\n",
       " array([[ 586.,  755., 1385.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "        [ 586.,  776., 1396., 1668.,    0.,    0.,    0.,    0.,    0.],\n",
       "        [ 572.,  742., 1113., 1213.,    0.,    0.,    0.,    0.,    0.],\n",
       "        [ 567.,  765., 1123., 1300., 1649., 1848.,    0.,    0.,    0.],\n",
       "        [ 550.,  772.,  858., 1119., 1303., 1654., 1858.,    0.,    0.],\n",
       "        [ 573.,  742.,  858., 1118., 1304.,    0.,    0.,    0.,    0.],\n",
       "        [ 577.,  797.,  858., 1119., 1304., 1654., 1860.,    0.,    0.],\n",
       "        [ 546.,  804., 1119., 1298., 1658., 1753., 1860.,    0.,    0.],\n",
       "        [ 568.,  684.,  809.,  870., 1119., 1303., 1552., 1656., 1860.],\n",
       "        [ 577.,  858.,  917., 1117., 1301., 1656., 1857.,    0.,    0.],\n",
       "        [ 578.,  692.,  795.,  858., 1119., 1304., 1555., 1654., 1858.],\n",
       "        [ 569.,  894., 1112., 1295., 1656., 1858.,    0.,    0.,    0.],\n",
       "        [ 566.,  894., 1118., 1301., 1655., 1754., 1857.,    0.,    0.],\n",
       "        [ 585.,  784.,  858., 1107., 1302., 1656., 1753., 1858.,    0.],\n",
       "        [ 577.,  803.,  858., 1121., 1303., 1654., 1858.,    0.,    0.],\n",
       "        [ 584.,  900., 1108., 1297., 1648., 1847.,    0.,    0.,    0.],\n",
       "        [ 572.,  741.,  881., 1122., 1298., 1641., 1697., 1847.,    0.],\n",
       "        [ 596.,  803.,  858., 1129., 1306., 1652., 1854.,    0.,    0.],\n",
       "        [ 568.,  858., 1117., 1295., 1657., 1857.,    0.,    0.,    0.],\n",
       "        [ 570.,  887., 1118., 1302., 1651., 1857.,    0.,    0.,    0.],\n",
       "        [ 585.,  741., 1117., 1304.,    0.,    0.,    0.,    0.,    0.],\n",
       "        [ 493.,  586.,  756.,  881., 1123., 1305., 1654., 1857.,    0.],\n",
       "        [ 582.,  690.,  820., 1119., 1302., 1653., 1857.,    0.,    0.],\n",
       "        [ 579.,  800., 1119., 1304., 1557., 1655., 1860.,    0.,    0.],\n",
       "        [ 587.,  769.,  858., 1118., 1305.,    0.,    0.,    0.,    0.],\n",
       "        [ 581.,  790.,  859., 1122., 1299., 1653., 1856.,    0.,    0.],\n",
       "        [ 580.,  773.,  858., 1129., 1302., 1647., 1698., 1849.,    0.],\n",
       "        [ 566.,  825.,  890., 1119., 1296., 1651., 1848.,    0.,    0.]]),\n",
       " ['resplendens',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'cupreomarginata',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'kalinini',\n",
       "  'cupreomarginata',\n",
       "  'cupreomarginata',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'resplendens',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'kalinini',\n",
       "  'cupreomarginata']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(critical_points_data)\n",
    "pad_list(critical_points_data, filler = np.array([0,0]))\n",
    "pad_list(gamma_vector_relative_reflectance_data)\n",
    "data = pad_list(wavelength_vector_data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b5cce2-8547-4314-b054-22f7bbc29acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=18, releaselevel='final', serial=0)\n",
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)\n",
    "\n",
    "def replace_strings_3(lst):\n",
    "    mapping = {\"kalinini\": 0, \"resplendens\": 1, \"cupreomarginata\": 2}\n",
    "    return [mapping.get(item, item) for item in lst]\n",
    "\n",
    "def replace_species_with_categorical(df):\n",
    "    \n",
    "    df.loc[df[\"species\"]==\"kalinini\",\"species\"] = 0\n",
    "    df.loc[df[\"species\"]==\"resplendens\", \"species\"] = 1\n",
    "    df.loc[df[\"species\"]==\"cupreomarginata\", \"species\"] = 2\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "  # list_of_metrics should be one of the names shown in:\n",
    "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")\n",
    "\n",
    "def transpose_list(lst):\n",
    "    return list(zip(*lst))\n",
    "    \n",
    "def get_nth_feature(data, n):\n",
    "    feature_vector = [data[0], [x[n] for x in data[1]] , data[2]] \n",
    "    return feature_vector\n",
    "def scatter_plot_2_variables(df_1, df_2):\n",
    "\n",
    "    joint_df = pd.merge(df_1, df_2, on=[\"code\", \"species\"], how=\"inner\")\n",
    "    column_list = joint_df.columns.tolist()\n",
    "    print(column_list)\n",
    "    column_list = [x for x in column_list if x not in [\"code\", \"species\"] ]\n",
    "    print(column_list)\n",
    "    plt.figure()\n",
    "    sns.scatterplot(joint_df, x=column_list[0], y =column_list[1], hue=\"species\")\n",
    "    plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def scatter_plot_3_variables(df_1, df_2, df_3):\n",
    "    \n",
    "    joint_df = pd.merge(df_1, df_2, on=[\"code\", \"species\"], how=\"inner\")\n",
    "    joint_df = pd.merge(joint_df, df_3, on=[\"code\", \"species\"], how=\"inner\")\n",
    "    \n",
    "    column_list = joint_df.columns.tolist()\n",
    "    print(column_list)\n",
    "    column_list = [x for x in column_list if x not in [\"code\", \"species\"] ]\n",
    "    print(column_list)\n",
    "    \n",
    "    x = joint_df[column_list[0]]\n",
    "    y = joint_df[column_list[1]]\n",
    "    z = joint_df[column_list[2]]\n",
    "    species = joint_df[\"species\"]\n",
    "    \n",
    "    # Create color map\n",
    "    colors = {'kalinini': 'r', 'resplendens': 'g', 'cupreomarginata': 'b'}\n",
    "    \n",
    "    # Create figure and 3D axis\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot points with color based on the fourth dimension\n",
    "    for category in set(species):\n",
    "        indices = species == category\n",
    "        ax.scatter(x[indices], y[indices], z[indices], c=colors[category], label=category, marker='o')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(f'{column_list[0]}')\n",
    "    ax.set_ylabel(f'{column_list[1]}')\n",
    "    ax.set_zlabel(f'{column_list[2]}')\n",
    "    #ax.set_title('3D Scatter plot with species based on Fourth Dimension')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f559b3c-dca4-4724-9ce1-98d23f7df0f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Assuming y_train and y_test are your integer labels\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m train_data_labels_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m test_data_labels_one_hot \u001b[38;5;241m=\u001b[39m to_categorical(test_data_labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_data[train_data_labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\np_utils.py:73\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     71\u001b[0m n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     72\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m     75\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "#Training data. Define dataframees\n",
    "\n",
    "gal_df = pd.DataFrame(transpose_list(gamma_arbitrary_limits_data), columns =[\"code\", \"g_arbitrary_limits\", \"species\"]) \n",
    "gftp_df = pd.DataFrame(transpose_list(gamma_first_two_peaks_data), columns =[\"code\", \"g_first_2_peaks\", \"species\"])\n",
    "gaucfmc_df = pd.DataFrame(transpose_list(gamma_area_under_curve_first_min_cut_data), columns =[\"code\", \"g_area_und_curve_first_min\", \"species\"]) \n",
    "gauc_df = pd.DataFrame(transpose_list(gamma_area_under_curve_data), columns =[\"code\", \"g_area_und_curve\", \"species\"])\n",
    "\n",
    "complete_df = pd.merge(gal_df, gftp_df, on=[\"species\",\"code\"], how=\"inner\")\n",
    "complete_df = pd.merge(complete_df, gauc_df, on=[\"species\",\"code\"], how=\"inner\")\n",
    "complete_df = pd.merge(complete_df, gaucfmc_df, on=[\"species\",\"code\"], how=\"inner\")\n",
    "complete_df.drop(columns=['code'], inplace=True)\n",
    "\n",
    "complete_df = replace_species_with_categorical(complete_df)\n",
    "#complete_df.drop(columns=['species'], inplace=True)\n",
    "complete_df\n",
    "\n",
    "shuffled_df = complete_df.sample(frac=1, random_state=42)  # Random_state for reproducibility\n",
    "\n",
    "# Define the fraction of data to be used for training\n",
    "train_fraction = 0.66  # For example, 80% for training, 20% for testing\n",
    "\n",
    "# Calculate the number of rows for the training set\n",
    "train_size = int(train_fraction * len(complete_df))\n",
    "\n",
    "# Split the shuffled DataFrame into train and test sets\n",
    "train_data = shuffled_df.iloc[:train_size]\n",
    "test_data = shuffled_df.iloc[train_size:]\n",
    "\n",
    "# Split the shuffled DataFrame into features and labels\n",
    "train_data_features = train_data.drop(columns=['species'], inplace=False)\n",
    "train_data_labels =  train_data.drop(columns=['g_arbitrary_limits','g_first_2_peaks','g_area_und_curve_first_min','g_area_und_curve'], inplace=False)\n",
    "test_data_features =  test_data.drop(columns=['species'], inplace=False)\n",
    "test_data_labels =  test_data.drop(columns=['g_arbitrary_limits','g_first_2_peaks','g_area_und_curve_first_min','g_area_und_curve'], inplace=False)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming y_train and y_test are your integer labels\n",
    "train_data_labels_one_hot = to_categorical(train_data_labels, num_classes=2)\n",
    "test_data_labels_one_hot = to_categorical(test_data_labels, num_classes=2)\n",
    "\n",
    "print(train_data[train_data_labels[\"species\"]==2])\n",
    "print(train_data_features[train_data_labels[\"species\"]==0])\n",
    "#print(len(train_data))\n",
    "#print(len(test_data))\n",
    "#print(test_features)\n",
    "#print(test_labels)\n",
    "\n",
    "# Select 2\n",
    "train_data_features = train_data_features.drop(columns=['g_arbitrary_limits',\"g_area_und_curve\"], inplace=False)\n",
    "test_data_features =  test_data_features.drop(columns=['g_arbitrary_limits',\"g_area_und_curve\"], inplace=False)\n",
    "\n",
    "print(train_data_labels[train_data_labels[\"species\"]==0])\n",
    "print(train_data_labels_one_hot[train_data_labels[\"species\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af49d08-188d-4066-bb7d-c63d02c42f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_3(my_learning_rate):\n",
    "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "  \n",
    "  # All models in this course are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a one-dimensional \n",
    "  # 784-element array.\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(2,)))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "  \n",
    "  # Define a dropout regularization layer. \n",
    "  model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "\n",
    "  # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "  model.add(tf.keras.layers.Dense(units=2, activation='softmax'))     \n",
    "                           \n",
    "  # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "  #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "                      #validation_split=validation_split)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43828edf-9500-4fde-a32c-50cc773f3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.007\n",
    "epochs = 160\n",
    "batch_size = 3\n",
    "validation_split = 0.05\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model_3(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "#epochs, hist = train_model(my_model, x_train, y_train, \n",
    "                           #epochs, batch_size, validation_split)\n",
    "epochs, hist = train_model(my_model, train_data_features, train_data_labels_one_hot, \n",
    "                           epochs, batch_size, validation_split)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x=test_data_features, y=test_data_labels_one_hot, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3c3ca-d4c4-4a0e-972b-e82897d912b5",
   "metadata": {},
   "source": [
    "### Notas: \n",
    "Mejores resultados usando el valor de batch size  4 o 3, acc 0.7\n",
    " Para 5, acc baja a 0.6\n",
    " Learning rate, buenos resultados en: 0.008-0.009. Acc 0.7\n",
    "aprendizaje inestable: Cambiamos learning rate a 0.007 y epochs a 600\n",
    " Pasar regularizaci√≥n de 0 a 0.1 hace que el aprendizaje sea m√°s suave\n",
    " Pasar de 4,4 a 8,4 hace el aprendizaje mas suave\n",
    " Pasar de 4,4 a 8,6 hace el aprendizaje menos efectivo\n",
    " Pasar de 4,4 a 8,4,4 hace el aprendizaje mas suave\n",
    "aumentar el validation split de 0.1 a 0.3 reduce el acc a 0.3 0.6 0.6\n",
    "bajar el validation split 0.1 a 0.05 reduce el acc a 0.5 0.6 0.7\n",
    "dejar el val. split en 0.1 deja acc en 0.5 0.6 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2312c97-d8ab-4e53-af25-279981393f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model \n",
    "\n",
    "# Define the file path where you want to save your model\n",
    "model_file_path = 'trained_model_4_var.h5'\n",
    "\n",
    "# Save the model\n",
    "my_model.save(model_file_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39f580-834b-4d0d-8c2c-333c24046e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_file_path = 'trained_model_4_var.h5'\n",
    "loaded_model2 = tf.keras.models.load_model(model_file_path)\n",
    "\n",
    "#load prediction data\n",
    "\n",
    "#Define dataframe\n",
    "pred_gal_df = pd.DataFrame(transpose_list(prediction_gamma_arbitrary_limits_data), columns =[\"code\", \"g_arbitrary_limits\", \"real_species\"]) \n",
    "pred_gftp_df = pd.DataFrame(transpose_list(prediction_gamma_first_two_peaks_data), columns =[\"code\", \"g_first_2_peaks\", \"real_species\"])\n",
    "pred_gauc_df = pd.DataFrame(transpose_list(prediction_gamma_area_under_curve_data), columns =[\"code\", \"g_area_und_curve\", \"real_species\"])\n",
    "pred_gaucfmc_df = pd.DataFrame(transpose_list(prediction_gamma_area_under_curve_first_min_cut_data), columns =[\"code\", \"g_area_und_curve_first_min\", \"real_species\"]) \n",
    "\n",
    "\n",
    "#drop species\n",
    "\n",
    "drop_pred_gal_df = pred_gal_df.copy()\n",
    "drop_pred_gal_df.drop(columns=[ \"real_species\"], inplace=True)\n",
    "\n",
    "drop_pred_gftp_df = pred_gftp_df.copy()\n",
    "drop_pred_gftp_df.drop(columns=[ \"real_species\"], inplace=True)\n",
    "\n",
    "drop_pred_gauc_df= pred_gauc_df.copy()\n",
    "drop_pred_gauc_df.drop(columns=[ \"real_species\"], inplace=True)\n",
    "\n",
    "drop_pred_gaucfmc_df=pred_gaucfmc_df.copy()\n",
    "drop_pred_gaucfmc_df.drop(columns=[ \"real_species\"], inplace=True)\n",
    "\n",
    "\n",
    "#merge on code\n",
    "pred_complete_df = pd.merge(drop_pred_gal_df, drop_pred_gftp_df, on=[\"code\"], how=\"inner\")\n",
    "pred_complete_df = pd.merge(pred_complete_df, drop_pred_gauc_df, on=[\"code\"], how=\"inner\")\n",
    "pred_complete_df = pd.merge(pred_complete_df, drop_pred_gaucfmc_df, on=[\"code\"], how=\"inner\")\n",
    "\n",
    "no_code_pred_complete_df= pred_complete_df.copy()\n",
    "no_code_pred_complete_df.drop(columns=[ \"code\"], inplace=True)\n",
    "pred_complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff6cbd-be4d-4894-9ef5-03af5c2c90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 2\n",
    "no_code_pred_complete_df = no_code_pred_complete_df.drop(columns=['g_arbitrary_limits',\"g_area_und_curve\"], inplace=False)\n",
    "\n",
    "print(no_code_pred_complete_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e43d65-8ede-46f7-bc98-4849897ee62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_features = pd.DataFrame({name:np.array(value) for name, value in no_code_pred_complete_df.items()})\n",
    "\n",
    "print(prediction_features)\n",
    "#print(pred_complete_df)\n",
    "#convert prediction_features to tensor\n",
    "for element in prediction_features:\n",
    "    prediction_features[element] = tf.convert_to_tensor(np.array(prediction_features[element]), dtype=tf.int64) \n",
    "\n",
    "\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model2.predict(prediction_features)\n",
    "\n",
    "# Print the predictions\n",
    "#print(predictions)\n",
    "prediction_df = pd.DataFrame(predictions, columns=[\"kalinini\", \"resplendens\"])\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171b28b-aef4-4a6a-a1fe-28499358f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_prediction_data = pd.merge(pred_gal_df, pred_gftp_df , on=[\"code\",\"real_species\"], how=\"inner\")\n",
    "merged_prediction_data = pd.merge(merged_prediction_data, pred_gauc_df , on=[\"code\",\"real_species\"], how=\"inner\")\n",
    "merged_prediction_data = pd.merge(merged_prediction_data, pred_gaucfmc_df , on=[\"code\",\"real_species\"], how=\"inner\")\n",
    "merged_prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f76c03-8a45-4bb3-b1f7-d7a4bd8ee84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3ee75-6dc2-4b03-98cd-1c35389a4afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0e246-ecd9-4fb7-99c6-6b72801c7e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146bcf98-0ab6-471a-970b-30f0620140cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750d20a-f226-4be6-a2d4-a0e0f2e20125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c63b38-ab00-497e-a06a-ad5ec691969f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
