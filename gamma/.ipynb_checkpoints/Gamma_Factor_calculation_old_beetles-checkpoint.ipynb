{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209243df",
   "metadata": {
    "id": "209243df"
   },
   "source": [
    "# Gamma factor calculation script algorithm\n",
    "## Authors: Marcela Hernández and Esteban Soto\n",
    "### CICIMA UCR\n",
    "\n",
    "#### The gamma factor is the ratio between the maximum reflectance peak in the visible/UV range and the maximum reflectance peak in the IR range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21708087-4423-4261-88ba-50eb250ccee1",
   "metadata": {
    "id": "21708087-4423-4261-88ba-50eb250ccee1"
   },
   "source": [
    "conda install pandas, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdd95ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcdd95ec",
    "outputId": "7ae8e7bc-9d48-494a-efd4-6c5c4b1cbb0b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "# Add the external folder to the system path\n",
    "current_dir = os.getcwd()\n",
    "external_folder_path = os.path.abspath(os.path.join(current_dir, '../libraries'))\n",
    "sys.path.append(external_folder_path)\n",
    "\n",
    "#This line of code allow us to access data in colab\n",
    "#functionality to reload modules\n",
    "\n",
    "import importlib\n",
    "import spectraltools\n",
    "import metrics\n",
    "import datapath_selector\n",
    "\n",
    "# clear the import cache\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(spectraltools)\n",
    "importlib.reload(datapath_selector)\n",
    "# now you can import my_class and it'll be updated\n",
    "from metrics import *\n",
    "from spectraltools import *\n",
    "from datapath_selector import get_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "u3bX8KP8HMgG",
   "metadata": {
    "id": "u3bX8KP8HMgG"
   },
   "outputs": [],
   "source": [
    "#open(r\"/content/drive/My Drive/CICIMA/escarabajos_files/L1050_data\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdd996d",
   "metadata": {
    "id": "dbdd996d"
   },
   "outputs": [],
   "source": [
    "#variables\n",
    "prominence_threshold_min = 0.15\n",
    "prominence_threshold_max = 0.60\n",
    "min_height_threshold_denominator = 3.0\n",
    "max_height_threshold_denominator = 2.5\n",
    "min_distance_between_peaks = 125 #nm\n",
    "\n",
    "#amount of specimens that would overlap with other species region\n",
    "percentile_differentiation_amount = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136eb335-1c60-44da-b561-08b29ae976c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "136eb335-1c60-44da-b561-08b29ae976c5",
    "outputId": "fd427288-5c14-45c3-a3c2-b4baac1e974a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angsol_collection_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\ANGSOL\\\\average', 'angsol_collection_metadata': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\collections\\\\CICIMA-beetles-general-inventory - ANGSOL.txt', 'craic_test_path': '', 'cicimaucr_collection_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\TRA_data_CICIMA_INBUCR\\\\CICIMAUCR\\\\reflectance', 'cicimaucr_collection_2_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\CICIMA-2024-01-REFLECTANCE\\\\average', 'cicimaucr_collection_3_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\CICIMA-2024-03-REFLECTANCE\\\\without iris nor lens\\\\average', 'cicima_ucr_metadata': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\collections\\\\CICIMA-beetles-general-inventory - CICIMAUCR.txt', 'inbucr_collection_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\INBUCR\\\\average', 'inbucr_metadata': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\collections\\\\CICIMA-beetles-general-inventory - INBUCR.txt', 'bioucr_collection_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\BIOUCR\\\\average', 'bioucr_metadata': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\L1050_data\\\\collections\\\\CICIMA-beetles-general-inventory - BIOUCR.txt', 'agregated_data_avg_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\agregated_data\\\\peak_averages_krc.txt', 'agregated_data_std_dev_path': 'C:\\\\Users\\\\esteb\\\\cicima\\\\escarabajos\\\\agregated_data\\\\peak_std_krc.txt', 'report_location': '', 'database_descriptor': ''}\n",
      "[<spectraltools.Specimen_Collection object at 0x00000201DDF2E1E0>, <spectraltools.Specimen_Collection object at 0x00000201DDDFABD0>, <spectraltools.Specimen_Collection object at 0x00000201DDDAA600>, <spectraltools.Specimen_Collection object at 0x00000201DDE1D010>, <spectraltools.Specimen_Collection object at 0x00000201DDF070B0>, <spectraltools.Specimen_Collection object at 0x00000201DDF072F0>]\n",
      "ANGSOL BIOUCR CICIMAUCR1 CICIMAUCR2 CICIMAUCR3 INBUCR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ANGSOL0001',\n",
       " 'ANGSOL0002',\n",
       " 'ANGSOL0003',\n",
       " 'ANGSOL0004',\n",
       " 'ANGSOL0005',\n",
       " 'ANGSOL0006',\n",
       " 'ANGSOL0007',\n",
       " 'ANGSOL0008',\n",
       " 'ANGSOL0009',\n",
       " 'ANGSOL0010',\n",
       " 'ANGSOL0011',\n",
       " 'ANGSOL0012',\n",
       " 'ANGSOL0013',\n",
       " 'ANGSOL0014',\n",
       " 'ANGSOL0015',\n",
       " 'ANGSOL0016',\n",
       " 'ANGSOL0017',\n",
       " 'ANGSOL0018',\n",
       " 'ANGSOL0019',\n",
       " 'ANGSOL0020',\n",
       " 'ANGSOL0021',\n",
       " 'ANGSOL0022',\n",
       " 'ANGSOL0023',\n",
       " 'ANGSOL0024',\n",
       " 'ANGSOL0025',\n",
       " 'ANGSOL0026',\n",
       " 'ANGSOL0027',\n",
       " 'ANGSOL0028',\n",
       " 'ANGSOL0029',\n",
       " 'ANGSOL0030',\n",
       " 'ANGSOL0031',\n",
       " 'ANGSOL0032',\n",
       " 'ANGSOL0033',\n",
       " 'ANGSOL0034',\n",
       " 'ANGSOL0035'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load collections\n",
    "OPTIONS: cicima_laptop, colaboratory, wfh, cicima_desktop\n",
    "    \"\"\"\n",
    "collection_paths = get_paths(working_at=\"cicima_desktop\") #datapath_selector library\n",
    "print(collection_paths)\n",
    "\n",
    "angsol_collection = Specimen_Collection(\"ANGSOL\", collection_paths[\"angsol_collection_path\"] , collection_paths[\"angsol_collection_metadata\"] , \"HIGH\")\n",
    "angsol_collection.set_description(\"ANGSOL collection has specimens that belong to Angel Solís. The confidence that we have about specimen identification is high.\")\n",
    "\n",
    "cicimaucr_collection = Specimen_Collection(\"CICIMAUCR1\", collection_paths[\"cicimaucr_collection_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "cicimaucr_collection_2 = Specimen_Collection(\"CICIMAUCR2\", collection_paths[\"cicimaucr_collection_2_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "cicimaucr_collection_3 = Specimen_Collection(\"CICIMAUCR3\", collection_paths[\"cicimaucr_collection_3_path\"] , collection_paths[\"cicima_ucr_metadata\"] , \"HIGH\")\n",
    "inbucr_collection = Specimen_Collection(\"INBUCR\", collection_paths[\"inbucr_collection_path\"] , collection_paths[\"inbucr_metadata\"] , \"HIGH\")\n",
    "bioucr_collection = Specimen_Collection(\"BIOUCR\", collection_paths[\"bioucr_collection_path\"] , collection_paths[\"bioucr_metadata\"] , \"LOW\")\n",
    "\n",
    "collection_list = [\n",
    "                    angsol_collection,\n",
    "                    cicimaucr_collection,\n",
    "                    cicimaucr_collection_2,\n",
    "                    cicimaucr_collection_3,\n",
    "                    inbucr_collection,\n",
    "                    bioucr_collection,\n",
    "                    ]\n",
    "print(collection_list)\n",
    "\n",
    "collection_names_set = set([collection.name for collection in collection_list])\n",
    "collection_names = \" \".join( sorted(collection_names_set))\n",
    "print(collection_names)\n",
    "#date\n",
    "from datetime import datetime\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "collection_list[0].get_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92364731-ca1d-498a-868e-22dfa9cb419f",
   "metadata": {
    "id": "92364731-ca1d-498a-868e-22dfa9cb419f"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991a8020",
   "metadata": {
    "id": "991a8020"
   },
   "outputs": [],
   "source": [
    "def create_path_if_not_exists(path):\n",
    "        # Check if the path already exists\n",
    "        if not os.path.exists(path):\n",
    "            # Create the directory and any missing parent directories\n",
    "            os.makedirs(path)\n",
    "            print(f\"Directory '{path}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory '{path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da30b78f-5882-4478-aa68-208437a03caf",
   "metadata": {
    "id": "da30b78f-5882-4478-aa68-208437a03caf"
   },
   "outputs": [],
   "source": [
    "### Third test: Plots on demand\n",
    "#!pip install reportlab\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#styles\n",
    "def styles():\n",
    "    # Title\n",
    "    title_style = getSampleStyleSheet()[\"Title\"]\n",
    "\n",
    "    # Heading1 - Heading6\n",
    "    heading1_style = getSampleStyleSheet()[\"Heading1\"]\n",
    "    heading2_style = getSampleStyleSheet()[\"Heading2\"]\n",
    "    # You can similarly access Heading3, Heading4, Heading5, Heading6\n",
    "\n",
    "    # Normal\n",
    "    normal_style = getSampleStyleSheet()[\"Normal\"]\n",
    "\n",
    "    # Bullet\n",
    "    bullet_style = getSampleStyleSheet()[\"Bullet\"]\n",
    "\n",
    "    # BodyText\n",
    "    body_style = getSampleStyleSheet()[\"BodyText\"]\n",
    "\n",
    "    # Italic / Bold / Underline\n",
    "    italic_style = getSampleStyleSheet()[\"Italic\"]\n",
    "    bold_style = getSampleStyleSheet()[\"Bold\"]\n",
    "    underline_style = getSampleStyleSheet()[\"Underline\"]\n",
    "\n",
    "    # Code\n",
    "    code_style = getSampleStyleSheet()[\"Code\"]\n",
    "\n",
    "sections = {}\n",
    "\n",
    "def create_paragraph(text):\n",
    "    title_style = getSampleStyleSheet()[\"Title\"]\n",
    "    centered_title_style = ParagraphStyle(\n",
    "    name='CenteredTitle',\n",
    "    parent=title_style,\n",
    "    fontSize=14,\n",
    "    alignment=1  # 0 for left, 1 for center, 2 for right\n",
    "    )\n",
    "    institution = Paragraph(text, centered_title_style)\n",
    "    return institution\n",
    "\n",
    "# Create title page\n",
    "def create_title_page():\n",
    "    elements = []\n",
    "\n",
    "    # Title\n",
    "    title_style = getSampleStyleSheet()[\"Title\"]\n",
    "    title = Paragraph(\"Gamma algorithms report\", title_style)\n",
    "    elements.append(title)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Author\n",
    "    #author_style = getSampleStyleSheet()[\"Normal\"]\n",
    "    centered_title_style = ParagraphStyle(\n",
    "    name='CenteredTitle',\n",
    "    parent=title_style,\n",
    "    fontSize=14,\n",
    "    alignment=1  # 0 for left, 1 for center, 2 for right\n",
    "    )\n",
    "    #heading1_style = getSampleStyleSheet()[\"Heading3\"]\n",
    "    author = Paragraph(\"Dra. Marcela Hernández & Esteban Soto.\", centered_title_style)\n",
    "    elements.append(author)\n",
    "    elements.append(Spacer(1, 6))\n",
    "    institution = Paragraph(\"Centro de Investigación en Ciencia e Ingeniería de los Materiales\", centered_title_style)\n",
    "    elements.append(institution)\n",
    "    elements.append(create_paragraph(\"2024\"))\n",
    "    elements.append(create_paragraph(\"University of Costa Rica\"))\n",
    "    elements.append(create_paragraph(f\"{current_date}\"))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "\n",
    "    return elements\n",
    "\n",
    "# Create table of contents\n",
    "def create_table_of_contents(toc_data):\n",
    "    toc_style = getSampleStyleSheet()[\"Heading1\"]\n",
    "    toc = [Paragraph(\"Table of Contents\", toc_style), Spacer(1, 12)]\n",
    "    #toc_data = []\n",
    "    for section, page_num in sections.items():\n",
    "        toc_data.append([Paragraph(section, toc_style), str(page_num)])\n",
    "    toc_table = Table(toc_data)\n",
    "    toc_table.setStyle(TableStyle([('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                                   ('TEXTCOLOR', (0, 0), (-1, 0), colors.blue),\n",
    "                                   ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                                   ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                                   ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey)]))\n",
    "    toc.append(toc_table)\n",
    "    toc.append(PageBreak())\n",
    "    return toc\n",
    "\n",
    "\n",
    "# Create sections with headings, paragraphs, and figures\n",
    "def gamma_analysis(gamma_testbench):\n",
    "    \n",
    "    #variable definition\n",
    "    gamma = gamma_testbench.gamma_class\n",
    "    test_df = gamma_testbench.test_df\n",
    "    species_list = test_df['species'].unique().tolist()\n",
    "    boxplot_path = gamma_testbench.boxplot_path\n",
    "    boxplot_analysis = \"\"\n",
    "    conclusion_text = \"\"\n",
    "    \n",
    "    print(f\"{species_list = }\")\n",
    "    #sections\n",
    "    sections = {}\n",
    "\n",
    "    # Section 1: algorithm_descrioption\n",
    "    algorithm_description = [Paragraph(f\"Algorithm description: {gamma.name()}\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "                    Paragraph(f\"{gamma.description()}\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 24)]\n",
    "\n",
    "\n",
    "    # Section 2: Results\n",
    "    results = [Paragraph(\"Results\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "               Paragraph(\"\", getSampleStyleSheet()[\"Normal\"]),\n",
    "               Spacer(1, 24)]\n",
    "    \n",
    "    # Section 3: Species differentiation\n",
    "    \n",
    "    percentile = percentile_differentiation_amount\n",
    "    \n",
    "    def species_quartiles(test_df):\n",
    "            \n",
    "        test_average = test_df[\"gamma\"].mean()\n",
    "        test_std = test_df[\"gamma\"].std()\n",
    "        \n",
    "        first_percentile = test_df[\"gamma\"].quantile(percentile)\n",
    "        third_percentile = test_df[\"gamma\"].quantile(1 - percentile)\n",
    "        \n",
    "        return test_average, test_std, first_percentile, third_percentile\n",
    "    \n",
    "    quartile_info = pd.DataFrame([])\n",
    "    \n",
    "    #calculate quartile info for each species\n",
    "    for species in species_list:\n",
    "        #filter df\n",
    "        filtered_df = test_df[test_df[\"species\"] == species]\n",
    "        #get only that species data\n",
    "        quartile_info.loc[species, \"average\"],quartile_info.loc[species, \"std\"],quartile_info.loc[species, \"Q1\"],quartile_info.loc[species, \"Q3\"] = species_quartiles(filtered_df)\n",
    "    \n",
    "    def species_differentiation(species_list):\n",
    "        print(f\"{quartile_info}\")\n",
    "        #at the beginning every species could be differentiable\n",
    "        differentiable_species = [element for element in species_list]\n",
    "        \n",
    "        for species in species_list:\n",
    "            #But, if is a species quartiles falls inside other species quartile's range, it will be removed\n",
    "            print(f\"Current {differentiable_species=}\")\n",
    "            \n",
    "            other_species_list = [element for element in species_list if element != species]\n",
    "            \n",
    "            q1_main = quartile_info.loc[species, \"Q1\"]\n",
    "            q3_main = quartile_info.loc[species, \"Q3\"]\n",
    "            \n",
    "            for other_species in other_species_list:\n",
    "                q1_other = quartile_info.loc[other_species, \"Q1\"]\n",
    "                q3_other = quartile_info.loc[other_species, \"Q3\"]\n",
    "                \n",
    "                #if one of the ranges is between any other species range, that species will be rejected.\n",
    "                print(f\"{q1_main=} {q3_main=} {q1_other=} {q3_other=}\")\n",
    "                print(f\"Test: {( (q1_other < q1_main) & (q3_other < q1_main)) | ( (q3_main < q1_other) & (q3_main < q3_other)) =}\")\n",
    "                if  not ( (q1_other < q1_main) & (q3_other < q1_main)) | ( (q3_main < q1_other) & (q3_main < q3_other)):\n",
    "                    try:\n",
    "                        differentiable_species.remove(species)\n",
    "                    except Exception as e:\n",
    "                        print(Exception)\n",
    "                        print(\"Already deleted\")\n",
    "                    \n",
    "            #finish iterating each species\n",
    "        return differentiable_species\n",
    "    \n",
    "        \n",
    "        #This section determines if species sections overlap, if they don't, that means that one species can be differentiated. \n",
    "    \n",
    "    #Section 4. Add boxplot to report\n",
    "    results.append(Paragraph(f\"Gamma boxplot for {gamma.name()}\", getSampleStyleSheet()[\"Heading3\"]))\n",
    "    results.append(Image(boxplot_path, width=400, height=400*0.9))\n",
    "    results.append(Paragraph(boxplot_analysis, getSampleStyleSheet()[\"Normal\"]))\n",
    "    results.append(PageBreak())\n",
    "    \n",
    "    # Section 3: Differentiable species\n",
    "    differentiable_species = species_differentiation(species_list)\n",
    "    \n",
    "    print(f\" Final {differentiable_species=}\")\n",
    "    \n",
    "    if differentiable_species:\n",
    "        \n",
    "        differentiable_species_paragraph = [Paragraph(\"Differentiable species:\", getSampleStyleSheet()[\"Heading3\"]), Spacer(1, 12),\n",
    "                   Paragraph(f\"Assuming each species is distributed normally: Differentiable species are: {differentiable_species}. {(1 -percentile) * 100}% of these specimens will be found in a region in which the probability of being a specimen of other species is less than {percentile * 100} %.\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                   Spacer(1, 24)]\n",
    "        results += differentiable_species_paragraph\n",
    "    else:\n",
    "        print(f\"{differentiable_species=}\")\n",
    "        differentiable_species_paragraph = [Paragraph(\"No differentiable species could be found:\", getSampleStyleSheet()[\"Heading3\"]), Spacer(1, 12),\n",
    "                   Paragraph(f\" Assuming each species is distributed normally: There is no region in which {(1-percentile) * 100}% of the specimens of any species would not overlap with other's species central {(1 - percentile)*100} percentile of individuals. \", getSampleStyleSheet()[\"Normal\"]),\n",
    "                   Spacer(1, 24)]\n",
    "        results += differentiable_species_paragraph\n",
    "    \n",
    "    results.append(PageBreak())\n",
    "    \n",
    "   \n",
    "\n",
    "    # results.append(Paragraph(\"Exponential Function Plot\", getSampleStyleSheet()[\"Heading2\"]))\n",
    "    # results.append(Image(\"exponential_plot.png\", width=400, height=300))\n",
    "    # results.append(Spacer(1, 24))\n",
    "\n",
    "    # Section 4: Conclusion\n",
    "    conclusion = [Paragraph(\"Conclusion\", getSampleStyleSheet()[\"Heading1\"]), Spacer(1, 12),\n",
    "                  Paragraph(conclusion_text, getSampleStyleSheet()[\"Normal\"]),\n",
    "                  Spacer(1, 24)]\n",
    "\n",
    "    sections[f\"Algorithm Description: {gamma.name()}\"] = len(algorithm_description)\n",
    "    sections[\"Results\"] = len(results)\n",
    "    sections[\"Conclusion\"] = len(conclusion) + sections[\"Results\"]\n",
    "\n",
    "\n",
    "\n",
    "    return algorithm_description  + results #+ conclusion, sections\n",
    "\n",
    "# Create bibliography\n",
    "def create_bibliography():\n",
    "    bibliography = [Paragraph(\"References\", getSampleStyleSheet()[\"Heading1\"]), Spacer(1, 12),\n",
    "                    Paragraph(\"1. Author A, et al. (Year). Title of the paper. Journal Name, Volume(Issue), Page Numbers.\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Paragraph(\"2. Author B, et al. (Year). Title of the paper. Journal Name, Volume(Issue), Page Numbers.\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 24)]\n",
    "    return bibliography\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab736df-1b96-4faf-9368-fa7e4b07c061",
   "metadata": {
    "id": "3ab736df-1b96-4faf-9368-fa7e4b07c061"
   },
   "outputs": [],
   "source": [
    "def get_test_spectra(collection_list):\n",
    "    #read spectra in location_list\n",
    "    filtered_spectra = []\n",
    "\n",
    "    for index, collection in enumerate(collection_list):\n",
    "        #print(f\"location:{location}\")\n",
    "\n",
    "        spectra = read_spectra_from_folder(collection.data_folder_path, collection.metadata)\n",
    "\n",
    "        #filter spectra if needed\n",
    "\n",
    "        filtered_spectra.extend(spectra)\n",
    "        # Filter spectra to those that have species data\n",
    "        filtered_spectra = [spectrum for spectrum in filtered_spectra if spectrum.species != \"nan\"]\n",
    "        return filtered_spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c32e0-89ac-4839-bbea-51d8ea1f9054",
   "metadata": {
    "id": "886c32e0-89ac-4839-bbea-51d8ea1f9054"
   },
   "source": [
    "#### Filter Spectra\n",
    "In this section we filter out any specimen row which is different  from kalinini, cupromarginata or resplendens species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01554e72-373d-4885-b4aa-ca59897470cc",
   "metadata": {
    "id": "01554e72-373d-4885-b4aa-ca59897470cc"
   },
   "outputs": [],
   "source": [
    "def get_filtered_spectra(collection_list):\n",
    "    \"\"\"Returns the spectrum for each of the selected species: kalinini, resplendens and cupreomarginata\"\"\"\n",
    "    #read spectra in location_list\n",
    "    filtered_spectra = []\n",
    "\n",
    "    for index, collection in enumerate(collection_list):\n",
    "        \n",
    "        spectra = collection.get_spectra()\n",
    "\n",
    "        #filter spectra if needed\n",
    "\n",
    "        filtered_spectra.extend(spectra)\n",
    "\n",
    "    # Filter spectra to those that have species data\n",
    "    filtered_spectra = [spectrum for spectrum in filtered_spectra if spectrum.species != \"nan\"]\n",
    "\n",
    "    #filter to only those entries that are either  resplendens, kalinini or cupreomarginata\n",
    "    filtered_spectra = [spectrum for spectrum in filtered_spectra if ((spectrum.species == \"resplendens\") | (spectrum.species == \"kalinini\") | (spectrum.species == \"cupreomarginata\"))]\n",
    "    #print(filtered_spectra)\n",
    "\n",
    "    #calculate metadata\n",
    "\n",
    "    #How many specimens of each species are there\n",
    "    species_list = [spectrum.species for spectrum in filtered_spectra]\n",
    "    species_list_set = set(species_list)\n",
    "    species_counter = {}\n",
    "\n",
    "    for current_species in species_list_set:\n",
    "        species_i_list = [species for species in species_list if species == current_species]\n",
    "        species_counter[current_species] = len(species_i_list)\n",
    "\n",
    "\n",
    "    return filtered_spectra, species_counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4ac68-e20f-4c77-a4e6-a8d7aadb40e2",
   "metadata": {
    "id": "12a4ac68-e20f-4c77-a4e6-a8d7aadb40e2"
   },
   "source": [
    "#### Specimen Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45a943e-4bd8-4df9-b8d4-5a02d7da9ad9",
   "metadata": {
    "id": "d45a943e-4bd8-4df9-b8d4-5a02d7da9ad9"
   },
   "outputs": [],
   "source": [
    "# Create sections with headings, paragraphs, and figures\n",
    "def get_specimen_section( filtered_spectra, species_counter ):\n",
    "\n",
    "\n",
    "    def dict_to_matrix(data):\n",
    "        # Extract keys and values from the dictionary\n",
    "        keys = list(data.keys())\n",
    "        values = list(data.values())\n",
    "\n",
    "        # Create a list of rows\n",
    "        rows = [keys] + [values]\n",
    "\n",
    "        return rows\n",
    "\n",
    "    #Define sections and results\n",
    "    sections = {}\n",
    "    results =[]\n",
    "    information = []\n",
    "    \n",
    "    # Section 1: Executive Summary\n",
    "    specimen_information = []\n",
    "    exec_sum = [Paragraph(f\"Executive Summary:\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "                    Paragraph(f\"\"\"This report analyzes different algorithms focused on differentiating among Chrysina kalinini, C. resplendens and C. cupreomarginata species. These algorithms will analyze a particular spectrum and will produce a number. That index is going to be averaged and a boxplot will be made for each species.\n",
    "                    This information can be used in the future to analyze unknown spectra and make a guess of the most probable identity for a sample.\n",
    "                    \"\"\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 24)]\n",
    "    specimen_information += exec_sum\n",
    "    # Section 1: Introduction\n",
    "    \n",
    "    title = [Paragraph(f\"Specimen Information:\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "                    Paragraph(f\"The following collections were used: {collection_names} \", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Paragraph(\"Number of specimens per species:\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 24)]\n",
    "    specimen_information += title\n",
    "\n",
    "    #Create table of species:\n",
    "    #list of species\n",
    "    species_table = dict_to_matrix(species_counter)\n",
    "    #create table\n",
    "    table = Table(species_table)\n",
    "    style = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.white),\n",
    "                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
    "                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                        ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
    "\n",
    "    table.setStyle(style)\n",
    "    information.append(table)\n",
    "    #information.append(PageBreak())\n",
    "\n",
    "    #Add table with species info\n",
    "\n",
    "    sub_title = [Paragraph(f\"Relevant data:\", getSampleStyleSheet()[\"Heading3\"]), Spacer(1, 12)]\n",
    "\n",
    "    information += sub_title\n",
    "\n",
    "    #create table with specimen info\n",
    "    df_specimen_info = pd.DataFrame([], columns = [\"code\", \"genus\", \"species\", \"measuring_mode\"])\n",
    "    for index, spectrum in enumerate(filtered_spectra):\n",
    "        df_specimen_info.loc[ index, \"code\"] = spectrum.code\n",
    "        df_specimen_info.loc[ index, \"genus\"] =spectrum.genus\n",
    "        df_specimen_info.loc[ index,\"species\"] =spectrum.species\n",
    "        df_specimen_info.loc[ index, \"measuring_mode\"] = spectrum.metadata[\"measuring_mode\"]\n",
    "\n",
    "    names =[ [\"code\", \"genus\", \"species\", \"measuring_mode\"]]\n",
    "    #df_specimen_info.values\n",
    "    #list of species\n",
    "\n",
    "    specimen_info = names + df_specimen_info.values.tolist()\n",
    "    #create table\n",
    "    table2 = Table(specimen_info)\n",
    "    style = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.white),\n",
    "                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
    "                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                        ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
    "\n",
    "    table2.setStyle(style)\n",
    "    information.append(table2)\n",
    "    information.append(PageBreak())\n",
    "\n",
    "    # # Section 3: Results\n",
    "    # results = [Paragraph(\"Results\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "    #            Paragraph(\"The results obtained are as follows:\", getSampleStyleSheet()[\"Normal\"]),\n",
    "    #            Spacer(1, 24)]\n",
    "\n",
    "    # Generate plots and save images\n",
    "\n",
    "    sub_title3 = [Paragraph(f\"Spectral information :\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12)]\n",
    "\n",
    "    information += sub_title3\n",
    "\n",
    "\n",
    "\n",
    "    def get_spectra_with_info(spectra):\n",
    "        print(f\"spectra {spectra}\")\n",
    "        image_plot_list = []\n",
    "        #calculate peaks for each spectrum\n",
    "        spectral_peaks = [PeakList(spectrum) for spectrum in spectra]\n",
    "\n",
    "        print(f\"PeakList {spectral_peaks}\")\n",
    "\n",
    "        for peaklist in spectral_peaks:\n",
    "            #List with peaks\n",
    "            peak_info = peaklist.get_peaks()\n",
    "            #get plots and save images\n",
    "            ax = peaklist.plot()\n",
    "            fig = ax.figure\n",
    "            #path= report_location +\"\\\\report_images\\\\\"\n",
    "            path = os.path.join(report_location, \"report_images\")\n",
    "            create_path_if_not_exists(path)\n",
    "            print(f\"PeakList.spectrum.code  {peaklist.spectrum.code}\")\n",
    "            filename = path  + f\"{peaklist.spectrum.code} \" + f\"-{current_date}\" +\".jpeg\"\n",
    "            fig.savefig(filename)\n",
    "            pair = (filename, peak_info)\n",
    "            image_plot_list.append(pair )\n",
    "\n",
    "        return image_plot_list\n",
    "\n",
    "    spectrum_paths = get_spectra_with_info(filtered_spectra)\n",
    "    print(f\"spectrum_paths {spectrum_paths}\")\n",
    "    \n",
    "    # Add figures to report\n",
    "    counter = 1\n",
    "    for filename, peak_info in spectrum_paths:\n",
    "        information.append(Image(filename, width=400*0.7, height=300*0.6))\n",
    "        information.append(Paragraph(f\"Peaks: {peak_info}\", getSampleStyleSheet()[\"Normal\"]))\n",
    "        counter = counter + 1\n",
    "        if counter % 3 == 0:\n",
    "            information.append(PageBreak())\n",
    "    information.append(PageBreak())\n",
    "\n",
    "    # results.append(Image(boxplot_path, width=400, height=300))\n",
    "    # results.append(Paragraph(boxplot_analysis, getSampleStyleSheet()[\"Normal\"]))\n",
    "\n",
    "    # results.append(Paragraph(\"Exponential Function Plot\", getSampleStyleSheet()[\"Heading2\"]))\n",
    "    # results.append(Image(\"exponential_plot.png\", width=400, height=300))\n",
    "    # results.append(Spacer(1, 24))\n",
    "\n",
    "    # Section 4: Conclusion\n",
    "    conclusion = [Paragraph(\"Conclusion\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "                  Paragraph(\"In conclusion, the experiment demonstrates...\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                  Spacer(1, 24)]\n",
    "\n",
    "    sections[\"Specimen Information\"] = len(specimen_information)\n",
    "    sections[\"Results\"] = len(results)\n",
    "    sections[\"Conclusion\"] = len(conclusion) + sections[\"Results\"]\n",
    "\n",
    "    return specimen_information  + information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a4e16-3329-4953-9289-0d6fd8c18b7c",
   "metadata": {
    "id": "82f9acfd-87c7-4b2c-b412-d83c8b9238ff"
   },
   "source": [
    "## LOGIC\n",
    "#### Filtered Spectra and Specimen section\n",
    "This section selects the correct specimens (In this case cupreomarginata, kalinini and resplendens ones) and creates the specimen section of the report, which has information about the collections used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae18213f-2fe4-4da4-8370-79629f5529e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ae18213f-2fe4-4da4-8370-79629f5529e3",
    "outputId": "2112d3c8-05c4-496c-fb61-81efa13058d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<spectraltools.Specimen_Collection object at 0x00000201DDF2E1E0>, <spectraltools.Specimen_Collection object at 0x00000201DDDFABD0>, <spectraltools.Specimen_Collection object at 0x00000201DDDAA600>, <spectraltools.Specimen_Collection object at 0x00000201DDE1D010>, <spectraltools.Specimen_Collection object at 0x00000201DDF070B0>, <spectraltools.Specimen_Collection object at 0x00000201DDF072F0>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'read_spectra_from_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(collection_list)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#First we filter the specimens to be analyzed\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m filtered_spectra, species_counter \u001b[38;5;241m=\u001b[39m get_filtered_spectra(collection_list)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Then we create a section detailing the characteristics of each specimen.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m specimen_section \u001b[38;5;241m=\u001b[39m get_specimen_section(filtered_spectra, species_counter)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mget_filtered_spectra\u001b[1;34m(collection_list)\u001b[0m\n\u001b[0;32m      4\u001b[0m filtered_spectra \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, collection \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(collection_list):\n\u001b[1;32m----> 9\u001b[0m     spectra \u001b[38;5;241m=\u001b[39m read_spectra_from_folder(collection\u001b[38;5;241m.\u001b[39mdata_folder_path, collection\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#filter spectra if needed\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     filtered_spectra\u001b[38;5;241m.\u001b[39mextend(spectra)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_spectra_from_folder' is not defined"
     ]
    }
   ],
   "source": [
    "print(collection_list)\n",
    "#First we filter the specimens to be analyzed\n",
    "filtered_spectra, species_counter = get_filtered_spectra(collection_list)\n",
    "#Then we create a section detailing the characteristics of each specimen.\n",
    "specimen_section = get_specimen_section(filtered_spectra, species_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895c3a1-c7cc-401e-99a7-e51618ad0391",
   "metadata": {
    "id": "9895c3a1-c7cc-401e-99a7-e51618ad0391"
   },
   "source": [
    "### Gamma Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6819d-9ffc-419d-8a5d-044e95361069",
   "metadata": {
    "id": "f2a6819d-9ffc-419d-8a5d-044e95361069"
   },
   "source": [
    "### Algorithm 1: Simple gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a47ce2-3877-428b-a750-86d8909da0c7",
   "metadata": {
    "id": "48a47ce2-3877-428b-a750-86d8909da0c7"
   },
   "outputs": [],
   "source": [
    "class Gamma():\n",
    "    \"\"\"This is an abstract class that represents every gamma metric, allows it to be compared, have a description and a name.\n",
    "    This is useful when using it in the report methods \"\"\"\n",
    "    \n",
    "    def get_gamma_factor(self, spectrum):\n",
    "        gamma_factor = None\n",
    "        return gamma_factor\n",
    "\n",
    "    def __init__(self, spectrum):\n",
    "        self.spectrum = spectrum\n",
    "        self.gamma = self.get_gamma_factor(spectrum)\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return \"Gamma class\"\n",
    "\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return \"No description yet\"\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.gamma < other.gamma\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Gamma({self.gamma}) for {self.spectrum.genus} {self.spectrum.species} in {self.spectrum.filename}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f81cc",
   "metadata": {},
   "source": [
    "#### Gamma with arbitrary limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72273425-20db-4b41-91fe-7d1baa1c5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma_Arbitrary_Limits(Gamma):\n",
    "    \"\"\"This gamma metric calculates the ratio between the maximum in the IR range and the maximum in the visible range. Ranges are static.\"\"\"\n",
    "    uv_vis_min_wavelength, uv_vis_max_wavelength = 250.00, 1000.00\n",
    "    ir_min_wavelength = uv_vis_max_wavelength\n",
    "    ir_max_wavelength = 2500.00\n",
    "\n",
    "    def get_gamma_factor(self, spectrum):\n",
    "        def get_maximum_in_range(spectrum, min_wavelength, max_wavelength):\n",
    "            measuring_mode = spectrum.metadata[\"measuring_mode\"]\n",
    "            df = spectrum.data\n",
    "            max_value = df[(df[\"wavelength\"] > min_wavelength) & (df[\"wavelength\"]  < max_wavelength) ].max()\n",
    "            #print(f\"max value \\n {max_value}\")\n",
    "            wavelength, measure = max_value[\"wavelength\"], max_value[measuring_mode]\n",
    "            return wavelength, measure\n",
    "\n",
    "        uv_vis_wavelength, uv_vis_max = get_maximum_in_range(spectrum, Gamma_Arbitrary_Limits.uv_vis_min_wavelength, Gamma_Arbitrary_Limits.uv_vis_max_wavelength)\n",
    "        ir_wavelength, ir_max = get_maximum_in_range(spectrum, Gamma_Arbitrary_Limits.ir_min_wavelength, Gamma_Arbitrary_Limits.ir_max_wavelength)\n",
    "        gamma_factor = (uv_vis_max / ir_max)*1.00\n",
    "        \n",
    "        return gamma_factor\n",
    "        \n",
    "    def get_gamma_factor_improved(self, spectrum):\n",
    "        #get list of maxima and minima\n",
    "        max_i, max_x, max_y = get_maxima(spectrum)\n",
    "        #Divide second peak over first peak\n",
    "        gamma_factor = max_y[1]/max_y[0]\n",
    "        \n",
    "        return gamma_factor\n",
    "\n",
    "    def __init__(self, spectrum):\n",
    "        self.spectrum = spectrum\n",
    "        self.gamma = self.get_gamma_factor(spectrum)\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return \"Gamma_Arbitrary_Limits\"\n",
    "\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return f\"\"\"This algorithm calculates the ratio between the highest reflectance peak in the visible range (Between {Gamma_Arbitrary_Limits.uv_vis_min_wavelength} nm and {Gamma_Arbitrary_Limits.uv_vis_max_wavelength} nm)\n",
    "                and the maximum peak in the IR range up to {Gamma_Arbitrary_Limits.ir_max_wavelength} nm. Beyond {Gamma_Arbitrary_Limits.ir_max_wavelength} nm the internal structure's reflectance generates unwanted noise.\"\"\"\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.gamma < other.gamma\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Gamma({self.gamma}) for {self.spectrum.genus} {self.spectrum.species} in {self.spectrum.filename}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff3f62-5f17-45d4-b77d-c0e4502e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma_First_Two_Peaks(Gamma):\n",
    "    \"\"\"This gamma metric calculates the ratio between the maximum in the IR range and the maximum in the visible range. Ranges are static.\"\"\"\n",
    "    @staticmethod\n",
    "    def get_gamma_factor_improved( spectrum):\n",
    "        #get list of maxima and minima\n",
    "        max_i, max_x, max_y = get_maxima(spectrum)\n",
    "        #Divide second peak over first peak\n",
    "        gamma_factor = max_y[1]/max_y[0]\n",
    "\n",
    "        \n",
    "        return gamma_factor\n",
    "\n",
    "    def __init__(self, spectrum):\n",
    "        self.spectrum = spectrum\n",
    "        self.gamma = Gamma_First_Two_Peaks.get_gamma_factor_improved(spectrum)\n",
    "\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return \"Gamma_First_Two_Peaks\"\n",
    "\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return f\"\"\"This algorithm calculates the ratio between the second and first reflectance peak.\"\"\"\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.gamma < other.gamma\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Gamma({self.gamma}) for {self.spectrum.genus} {self.spectrum.species} in {self.spectrum.filename}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bbf15-c7a8-4e60-8594-13d7527d65b9",
   "metadata": {
    "id": "326bbf15-c7a8-4e60-8594-13d7527d65b9"
   },
   "source": [
    "### Gamma Testbench\n",
    "This method is used to test each gamma factor implementation to determine how well it works to differentiate among  species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115ac42",
   "metadata": {
    "id": "f115ac42"
   },
   "outputs": [],
   "source": [
    "class Gamma_Testbench():\n",
    "    \"\"\"This class tests the gamma metrics of the selected spectra and creates a boxplot for the species selected.\n",
    "    Returns the path to the boxplot image\"\"\"\n",
    "    #Calculate gammas\n",
    "    \n",
    "    def __init__(self, Gamma, filtered_spectra):\n",
    "        self.gamma_class = Gamma\n",
    "        self.spectra = filtered_spectra\n",
    "        self.test_df, self.boxplot_path = self.get_boxplot()\n",
    "        \n",
    "    def get_boxplot(self):\n",
    "        \n",
    "        filtered_spectra = self.spectra\n",
    "        Gamma = self.gamma_class\n",
    "        \n",
    "        gamma_list = []\n",
    "\n",
    "        for spectrum in filtered_spectra:\n",
    "            #print(spectrum.get_normalized_spectrum())\n",
    "            try:\n",
    "                gamma = Gamma(spectrum)\n",
    "                gamma_list.append(gamma)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        sorted(gamma_list)\n",
    "\n",
    "        gamma_df = pd.DataFrame(columns=[\"species\", \"genus\", \"gamma\", \"code\", \"filename\"])\n",
    "\n",
    "        #add specimen information to the gammas\n",
    "        for index, gamma in enumerate(gamma_list):\n",
    "            gamma_df.loc[index,\"species\"] = gamma.spectrum.species\n",
    "            gamma_df.loc[index,\"genus\"] = gamma.spectrum.genus\n",
    "            gamma_df.loc[index,\"gamma\"] = gamma.gamma\n",
    "            gamma_df.loc[index,\"code\"] = gamma.spectrum.code\n",
    "            gamma_df.loc[index,\"filename\"] = gamma.spectrum.name\n",
    "\n",
    "        #print(gamma_df)\n",
    "\n",
    "        #finally, information is presented as a boxplot and saved\n",
    "        ax = gamma_df.boxplot(column=[\"gamma\"], by=[\"species\"], ax=None, fontsize=None, rot=90, grid=True, figsize=(4*3, 4*3), layout=None, return_type=None, backend=None, showfliers=False)\n",
    "        fig = ax.figure\n",
    "        plt.title(f\" Algorithm: {Gamma.name() }. Collections: {collection_names}. \\n Gamma values for C. resplendens, C. kalinini and C. cupreomarginata.\")\n",
    "        \n",
    "        path= os.path.join(report_location, \"report_images\", \"gamma_image\")\n",
    "        create_path_if_not_exists(path)\n",
    "        filename = os.path.join(path, f\"{Gamma.name()} \"+ database_descriptor + f\"-{current_date}\" +\".jpeg\") \n",
    "        fig.savefig(filename)\n",
    "        \n",
    "        return gamma_df, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d2c61-b175-4c2b-b10b-9164fd1f69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving_averages is True only with trusty spectra\n",
    "saving_averages = True\n",
    "#This class gets the average and standard deviation per species for a particular Gamma class\n",
    "def get_gamma_avg_and_std(Gamma,filtered_spectra):\n",
    "    \n",
    "    #Calculate gammas\n",
    "    gamma_list = []\n",
    "\n",
    "    for spectrum in filtered_spectra:\n",
    "        #print(spectrum.get_normalized_spectrum())\n",
    "        try:\n",
    "            gamma = Gamma(spectrum)\n",
    "            gamma_list.append(gamma)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    #Order the list\n",
    "    sorted(gamma_list)\n",
    "    #Create a dataframe\n",
    "    gamma_df = pd.DataFrame(columns=[\"species\", \"genus\", \"gamma\", \"code\", \"filename\"])\n",
    "\n",
    "    #add specimen information to the gammas\n",
    "    for index, gamma in enumerate(gamma_list):\n",
    "        gamma_df.loc[index,\"species\"] = gamma.spectrum.species\n",
    "        gamma_df.loc[index,\"genus\"] = gamma.spectrum.genus\n",
    "        gamma_df.loc[index,\"gamma\"] = gamma.gamma\n",
    "        gamma_df.loc[index,\"code\"] = gamma.spectrum.code\n",
    "        gamma_df.loc[index,\"filename\"] = gamma.spectrum.name\n",
    "\n",
    "    #get info on df\n",
    "    grouped_stats = gamma_df.groupby('species')['gamma'].agg(['mean', 'std'])\n",
    "    grouped_stats = grouped_stats.T\n",
    "    print(grouped_stats)\n",
    "\n",
    "    #save info in a file \n",
    "    #save information\n",
    "    #path_location = agregated_data_location + \"\\\\aggregated_data\\\\gamma\"\n",
    "    path_location = os.path.join(agregated_data_location, \"aggregated_data\", \"gamma\")\n",
    "    create_path_if_not_exists(path_location)\n",
    "    path_and_filename = path_location+f'{Gamma.name()}.txt'\n",
    "    grouped_stats.to_csv( path_and_filename, index=False, sep = \"\\t\")\n",
    "    #return path\n",
    "    return path_and_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb8540-8f7f-436a-a4ee-dae7b0d61388",
   "metadata": {
    "id": "5ebb8540-8f7f-436a-a4ee-dae7b0d61388"
   },
   "source": [
    "### TEST Gamma Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ffa80-2f4f-4c82-b728-aa1086f3b82e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4d9ffa80-2f4f-4c82-b728-aa1086f3b82e",
    "outputId": "c555514e-d887-4d56-9c38-2647c638a4e9"
   },
   "outputs": [],
   "source": [
    "#Which method we are goint to test\n",
    "gamma_testbench_arbitrary_limits = Gamma_Testbench(Gamma_Arbitrary_Limits, filtered_spectra)\n",
    "#section related to that test\n",
    "simple_gamma_section_arbitrary_limits = gamma_analysis( gamma_testbench_arbitrary_limits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d358579-4226-4b33-90b4-611fd4c59d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which method are we going to test\n",
    "gamma_test = Gamma_First_Two_Peaks\n",
    "gamma_testbench_arbitrary_limits = Gamma_Testbench(gamma_test, filtered_spectra)\n",
    "#section related to that test\n",
    "simple_gamma_section_first_two_peaks = gamma_analysis( gamma_testbench_arbitrary_limits)\n",
    "#create an aggregated data path\n",
    "if training_data_is_used:\n",
    "    aggregated_data_path =get_gamma_avg_and_std(gamma_test, filtered_spectra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349cff8-c549-4e0e-b00a-852dd247b335",
   "metadata": {
    "id": "0349cff8-c549-4e0e-b00a-852dd247b335"
   },
   "source": [
    "### Peaks average and standard deviation per species:\n",
    "It calculates the average and standard deviation of each peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db462d9c-9097-45cb-9e16-edf6ad428674",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db462d9c-9097-45cb-9e16-edf6ad428674",
    "outputId": "96ab9034-f547-4e78-bda4-f6c8949d1eea"
   },
   "outputs": [],
   "source": [
    "test_spectra = filtered_spectra\n",
    "def peak_average_std_per_species(spectra):\n",
    "    peaklists = [PeakList(spectrum) for spectrum in spectra]\n",
    "    #Create a dataframe with all peaks, y peaks are normalized respect to the height of the first peak\n",
    "    specimen_peak_points = pd.DataFrame([])\n",
    "    for index, peaklist in enumerate(peaklists):\n",
    "\n",
    "        peaks = peaklist.get_peaks()\n",
    "\n",
    "        peak_0_x = peaks[0].x_value\n",
    "        peak_0_y = peaks[0].y_value\n",
    "\n",
    "        spectrum = peaklist.spectrum\n",
    "        code = spectrum.code\n",
    "        genus = spectrum.genus\n",
    "        species= spectrum.species\n",
    "        specimen_peak_points.loc[index, \"code\"] = code\n",
    "        specimen_peak_points.loc[index, \"genus\"] = genus\n",
    "        specimen_peak_points.loc[index, \"species\"] = species\n",
    "        for i in range(6):\n",
    "            label_x = f\"x{i}\"\n",
    "            label_y = f\"y{i}\"\n",
    "            specimen_peak_points.loc[index, label_x] = 0.0\n",
    "            specimen_peak_points.loc[index, label_y] = 0.0\n",
    "            \n",
    "        for i, peak in enumerate(peaks):\n",
    "            label_x = f\"x{i}\"\n",
    "            label_y = f\"y{i}\"\n",
    "            specimen_peak_points.loc[index, label_x] = peak.x_value\n",
    "            specimen_peak_points.loc[index, label_y] = peak.y_value/peak_0_y\n",
    "\n",
    "    #specimen_peak_points\n",
    "    #print(specimen_peak_points)\n",
    "    #print(f\"{peak_avg_std_df.loc[index:]}\")\n",
    "    #group values by species\n",
    "    averages_df = specimen_peak_points.groupby('species')[['x0', 'y0','x1', 'y1', 'x2', 'y2','x3', 'y3','x4', 'y4', 'x5', 'y5']].mean().reset_index()\n",
    "    standard_deviations_df = specimen_peak_points.groupby('species')[['x0', 'y0','x1', 'y1', 'x2', 'y2','x3', 'y3','x4', 'y4', 'x5', 'y5']].std().reset_index()\n",
    "\n",
    "    #save information\n",
    "    if training_data_is_used:\n",
    "        path_location = report_location + \"\\\\aggregated_data\\\\species_peaklist\\\\\"\n",
    "        create_path_if_not_exists(path_location)\n",
    "        specimen_peak_points.to_csv( path_location+'peaks_krc.txt', index=False, sep = \"\\t\")\n",
    "        averages_df.to_csv(path_location+'peak_averages_krc.txt', index=False, sep = \"\\t\")\n",
    "        standard_deviations_df.to_csv(path_location+'peak_std_krc.txt', index=False, sep = \"\\t\")\n",
    "\n",
    "    #print(averages_df)\n",
    "    #print(standard_deviations_df)\n",
    "\n",
    "    return specimen_peak_points, averages_df, standard_deviations_df\n",
    "specimen_peak_points, averages_df, standard_deviations_df = peak_average_std_per_species(filtered_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1515a3-7720-4a6e-8e56-6589856a06c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d1515a3-7720-4a6e-8e56-6589856a06c9",
    "outputId": "1d547f5e-7254-4875-87e8-219af76adc59"
   },
   "outputs": [],
   "source": [
    "#Create a function that calculates a similarity index given a spectrum\n",
    "def similarity_index(spectrum, averages_df, standard_deviations_df , species):\n",
    "    def distance(x, x0, sigma_0):\n",
    "        index =  (((x - x0)**4)**(1/4))\n",
    "        #print(f\" x {x} - x0 {x0} = {(x - x0)} and index = {index}\")\n",
    "        return index\n",
    "        #def get_gamma_factor(self, spectrum):\n",
    "    #get first n peaks of the gamma\n",
    "    n = 5\n",
    "    peaklist = PeakList(spectrum)\n",
    "    peaks = peaklist.get_peaks()[0:n]\n",
    "\n",
    "    #loads species average values:\n",
    "\n",
    "    averages_df = averages_df[averages_df[\"species\"] == species]\n",
    "    average_x_df = averages_df[[\"x0\",\"x1\",\"x2\",\"x4\",\"x5\"]].values[0]\n",
    "\n",
    "    standard_deviations_df = standard_deviations_df[standard_deviations_df[\"species\"] == species]\n",
    "    standard_deviation_x_df = standard_deviations_df[[\"x0\",\"x1\",\"x2\",\"x4\",\"x5\"]].values[0]\n",
    "\n",
    "    #print(f\"averages_df: {averages_df}\")\n",
    "    #for each peak, calculate the distances to the averages x values\n",
    "    similarity_index = 0.0\n",
    "\n",
    "    for peak_i,xi_0, sigmai_0 in zip(peaks, average_x_df, standard_deviation_x_df):\n",
    "        xi = peak_i.x_value\n",
    "        similarity_index += distance(xi, xi_0, sigmai_0)\n",
    "\n",
    "    #normalize for the number of points\n",
    "    similarity_index = similarity_index/n\n",
    "    #print(f\"gamma: {gamma}\")\n",
    "    return similarity_index\n",
    "\n",
    "specimen_peak_points, averages_df, standard_deviations_df = peak_average_std_per_species(filtered_spectra)\n",
    "\n",
    "with open(agregated_data_avg_path, encoding= \"latin1\") as f:\n",
    "    averages_df_0 = pd.read_csv(f, delimiter=\"\\t\", header=0)\n",
    "\n",
    "\n",
    "with open(agregated_data_std_path, encoding= \"latin1\") as f:\n",
    "    standard_deviations_df_0 = pd.read_csv(f, delimiter=\"\\t\", header=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_tool(correct_species, kali_si, cupr_si, resp_si):\n",
    "    my_list =  [kali_si, cupr_si, resp_si]\n",
    "    min_index = my_list.index(min(my_list))\n",
    "\n",
    "    if (min_index == 0):\n",
    "        return \"kalinini\"\n",
    "    if (min_index == 1):\n",
    "        return \"cupreomarginata\"\n",
    "    if (min_index == 2):\n",
    "        return \"resplendens\"\n",
    "\n",
    "similarity_index_text_df = pd.DataFrame([])\n",
    "for k, spectrum in enumerate(filtered_spectra):\n",
    "    kali_si = similarity_index(spectrum, averages_df_0, standard_deviations_df_0 , \"kalinini\")\n",
    "    cupr_si = similarity_index(spectrum, averages_df_0, standard_deviations_df_0 , \"cupreomarginata\")\n",
    "    resp_si = similarity_index(spectrum, averages_df_0, standard_deviations_df_0 , \"resplendens\")\n",
    "    similarity_index_text_df.loc[k,\"code\"] = spectrum.code\n",
    "    similarity_index_text_df.loc[k,\"species\"] =spectrum.species\n",
    "    similarity_index_text_df.loc[k,\"kali_si\"] = kali_si\n",
    "    similarity_index_text_df.loc[k,\"cupr_si\"] = cupr_si\n",
    "    similarity_index_text_df.loc[k,\"resp_si\"] = resp_si\n",
    "    similarity_index_text_df.loc[k,\"prediction\"] = test_tool(spectrum.species, kali_si, cupr_si, resp_si)\n",
    "    #print(f\"similarity indices for {spectrum.species}: kali {kali_si}, cupreo {cupr_si}, resp_si {resp_si}\")\n",
    "    #print(f\"Test tool: {test_tool(spectrum.species, kali_si, cupr_si, resp_si)}\")\n",
    "print(similarity_index_text_df)\n",
    "count_by_test_result = similarity_index_text_df.groupby('prediction').size().reset_index(name='count')\n",
    "print(f\"count {count_by_test_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d06a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(df, species):\n",
    "    print(f\"{species =} \\n {df=}\" )\n",
    "    \"\"\"Precision: For a given prediction, what percentage is actually that species. \"\"\"\n",
    "    #filter all predictions of that particular species\n",
    "    filtered_df = df[df[\"prediction\"] == species]\n",
    "    total_of_predictions = filtered_df[\"prediction\"].count()\n",
    "    print(f\"{total_of_predictions=}\" )\n",
    "    #Now count the amount of actual species\n",
    "    actual_species = filtered_df[filtered_df[\"species\"] == species][\"species\"].count()\n",
    "    precision = actual_species/total_of_predictions*100\n",
    "    print(f\"{precision=}\" )\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d618f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(df, species):\n",
    "    print(f\"{species =} \\n {df=}\" )\n",
    "    \"\"\"recall: For a given species, what percentage was correctly characterized. \"\"\"\n",
    "    #filter all lines of a particular species\n",
    "    filtered_df = df[df[\"species\"] == species]\n",
    "    total_of_species = filtered_df[\"species\"].count()\n",
    "    print(f\"{total_of_species=}\" )\n",
    "    #Count the amount of correct predictions\n",
    "    correct_predictions = filtered_df[filtered_df[\"prediction\"] == species][\"prediction\"].count()\n",
    "    recall = correct_predictions/total_of_species*100\n",
    "    print(f\"{recall=}\" )\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1ad27-7c7c-428a-ae63-5c669773edfb",
   "metadata": {
    "id": "5af1ad27-7c7c-428a-ae63-5c669773edfb"
   },
   "outputs": [],
   "source": [
    "# Create sections with headings, paragraphs, and figures\n",
    "def similarity_index_section(df ):\n",
    "\n",
    "    #Define sections and results\n",
    "    sections = {}\n",
    "    results =[]\n",
    "    information = []\n",
    "\n",
    "    # Section 1: Introduction\n",
    "    description = []\n",
    "    title = [Paragraph(f\"Similarity Index:\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "\n",
    "                    Paragraph(\"For each spectrum a similarity index is calculated which is the sum of the squared differences between the wavelength peak values of the unknown sample and the average wavelength peak values for each species.\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "    description += title\n",
    "\n",
    "    \n",
    "\n",
    "    #Add table with species info\n",
    "\n",
    "    sub_title = [Paragraph(f\"Test results:\", getSampleStyleSheet()[\"Heading3\"]), Spacer(1, 6),Paragraph(\"The reported(correct) species is compared with the species with the lowest similarity index (si), the final column (test_result) shows if the species coincide:\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "\n",
    "    information += sub_title\n",
    "    \n",
    "    #Amount of correct results\n",
    "\n",
    "    correct_guesses  = (df['prediction'] == df[\"species\"]).sum()\n",
    "    total_guesses = df[\"prediction\"].count()\n",
    "    success_rate = correct_guesses / total_guesses * 100\n",
    "    #accuracy, precision, recall, \n",
    "    comment_1 = [Paragraph(f\"The amount of correct guesses is {correct_guesses} out of {total_guesses}\", getSampleStyleSheet()[\"Heading3\"]), \n",
    "                           Spacer(1, 6),\n",
    "                           Paragraph(f\"The accuracy (Percentage of correct classifications out of total classifications) is {success_rate:.2f} %\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                           Spacer(1, 12)]\n",
    "\n",
    "    information += comment_1\n",
    "    \n",
    "  \n",
    "    #precision and recall\n",
    "    \n",
    "    kali_precision = calculate_precision(df, \"kalinini\")\n",
    "    kali_recall = calculate_recall(df, \"kalinini\")\n",
    "    cupreo_precision = calculate_precision(df, \"cupreomarginata\")\n",
    "    cupreo_recall= calculate_recall(df, \"cupreomarginata\")\n",
    "    resp_precision= calculate_precision(df, \"resplendens\")\n",
    "    resp_recall = calculate_recall(df, \"resplendens\")\n",
    "    \n",
    "    #commentary\n",
    "    comment_2 = [Paragraph(f\"For kalinini, precision (correct classifications out of all classifications for this species) is {kali_precision:.2f} % and recall (out of the actual specimens for this species how many were correctly classified) is {kali_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "        Paragraph(f\"For resplendens, precision is {resp_precision:.2f} % and recall is {resp_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "        Paragraph(f\"For cupreomarginata, precision is {cupreo_precision:.2f} % and recall is {cupreo_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "    information += comment_2\n",
    "    \n",
    "    for column in df.columns:\n",
    "        # Check if the column contains numeric values\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Round the values in the column to two decimal places\n",
    "            df[column] = df[column].round(decimals=3)\n",
    "            \n",
    "    #create table with test result info\n",
    "    names = df.columns.tolist()\n",
    "    #names = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",]\n",
    "    values_table =  df.values.tolist()\n",
    "\n",
    "    info = [names, *values_table]\n",
    "    print(info)\n",
    "    #info =  df.values.tolist()\n",
    "    #create table\n",
    "    table2 = Table(info)\n",
    "    style = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.white),\n",
    "                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
    "                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                        ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
    "\n",
    "    table2.setStyle(style)\n",
    "    information.append(table2)\n",
    "    information.append(PageBreak())\n",
    "\n",
    "\n",
    "    return description  + information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f53cd1-3e10-41a6-b725-7a261a552fef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34f53cd1-3e10-41a6-b725-7a261a552fef",
    "outputId": "2fd2083d-60ac-4740-fa72-3fe24e961be5"
   },
   "outputs": [],
   "source": [
    "similarity_index_section = similarity_index_section(similarity_index_text_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f726110-3665-48be-ba66-43f434ecc61b",
   "metadata": {
    "id": "3f726110-3665-48be-ba66-43f434ecc61b"
   },
   "source": [
    "### Algorithm 3: Trapezoidal integration. Naive\n",
    "This algorithm compares the area under the curve under the visible and IR region and compares them. Makes a cut at 800 nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4cfbb-dd5f-40a2-b286-4a935f1e966b",
   "metadata": {
    "id": "38b4cfbb-dd5f-40a2-b286-4a935f1e966b"
   },
   "outputs": [],
   "source": [
    "class GammaAreaUnderCurveNaive(Gamma):\n",
    "    #this is a subclass of Gamma\n",
    "    #get_gamma_factor must be redefined\n",
    "    visible_start_wavelength = 450\n",
    "    visible_end_wavelength = ir_start_wavelength = 800\n",
    "    ir_end_wavelength = 1500\n",
    "\n",
    "    def name():\n",
    "        return \"Gamma_area_under_curve_naive\"\n",
    "\n",
    "    def description():\n",
    "        return f\"This method calculates the ratio between the area under the curve for the spectrum between {GammaAreaUnderCurveNaive.visible_start_wavelength} and {GammaAreaUnderCurveNaive.visible_end_wavelength} nm (visible range) and between {GammaAreaUnderCurveNaive.ir_start_wavelength} nm and {GammaAreaUnderCurveNaive.ir_end_wavelength} nm (Infrarred range).\"\n",
    "\n",
    "\n",
    "    def get_gamma_factor(self, spectrum):\n",
    "\n",
    "        def get_area_under_curve(spectrum, start_wavelength, finish_wavelength):\n",
    "            # Subset the DataFrame to the range of interest\n",
    "            subset_df = df[(df['wavelength'] >= start_wavelength) & (df['wavelength'] <= finish_wavelength)]\n",
    "\n",
    "            # Extract the wavelengths and heights as arrays\n",
    "            wavelengths = subset_df['wavelength'].values\n",
    "            heights = subset_df[spectrum.measuring_mode].values\n",
    "\n",
    "            # Calculate the area under the curve using the trapezoidal rule\n",
    "            area_under_curve = np.trapz(heights, wavelengths)\n",
    "\n",
    "            print(\"Area under the curve:\", area_under_curve)\n",
    "            return area_under_curve\n",
    "\n",
    "        import numpy as np\n",
    "        df = spectrum.get_normalized_spectrum()\n",
    "        area_uv_visible = get_area_under_curve(spectrum, GammaAreaUnderCurveNaive.visible_start_wavelength, GammaAreaUnderCurveNaive.visible_end_wavelength)\n",
    "        area_ir = get_area_under_curve(spectrum, GammaAreaUnderCurveNaive.ir_start_wavelength, GammaAreaUnderCurveNaive.ir_end_wavelength)\n",
    "        gamma = area_uv_visible/area_ir\n",
    "        return gamma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a93b86-4688-4113-a4f6-eddba6e1910b",
   "metadata": {
    "id": "07a93b86-4688-4113-a4f6-eddba6e1910b"
   },
   "source": [
    "### Test Gamma Under Curve: Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fddba-1979-4cda-a7a3-cfe207df71b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "171fddba-1979-4cda-a7a3-cfe207df71b1",
    "outputId": "ef7f9b51-3fa4-4dcb-9339-fad85d0d458a"
   },
   "outputs": [],
   "source": [
    "#Which method we are goint to test\n",
    "gamma_test = GammaAreaUnderCurveNaive\n",
    "gamma_testbench_arbitrary_limits = Gamma_Testbench(gamma_test, filtered_spectra)\n",
    "#section related to that test\n",
    "gamma_area_under_curve_naive_section = gamma_analysis( gamma_testbench_arbitrary_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596091c8-1673-4eb7-9016-cb5d093382dd",
   "metadata": {
    "id": "596091c8-1673-4eb7-9016-cb5d093382dd"
   },
   "source": [
    "### Algorithm 4: Trapezoidal integration. Minimum detection\n",
    "This algorithm compares the area under the curve under the visible and IR region and compares them. Makes a cut at the first minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f853a-fe5e-4898-a1a6-7700159f72dc",
   "metadata": {
    "id": "c99f853a-fe5e-4898-a1a6-7700159f72dc"
   },
   "outputs": [],
   "source": [
    "def get_area_under_curve(spectrum, start_wavelength, finish_wavelength):\n",
    "            # Assuming your DataFrame is named df and has columns 'wavelength' and 'height'\n",
    "            # Let's say you have start_wavelength and finish_wavelength variables for the range you want to integrate over\n",
    "            # Subset the DataFrame to the range of interest\n",
    "            subset_df = df[(df['wavelength'] >= start_wavelength) & (df['wavelength'] <= finish_wavelength)]\n",
    "\n",
    "            # Extract the wavelengths and heights as arrays\n",
    "            wavelengths = subset_df['wavelength'].values\n",
    "            heights = subset_df[spectrum.measuring_mode].values\n",
    "\n",
    "            # Calculate the area under the curve using the trapezoidal rule\n",
    "            area_under_curve = np.trapz(heights, wavelengths)\n",
    "\n",
    "            print(\"Area under the curve:\", area_under_curve)\n",
    "            print(\"DEBUG method, delete in production\")\n",
    "            return area_under_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85f673-1733-49ed-9d3c-c7b54bf98b21",
   "metadata": {
    "id": "8e85f673-1733-49ed-9d3c-c7b54bf98b21"
   },
   "outputs": [],
   "source": [
    "class  GammaAreaFirstMinCut(Gamma):\n",
    "    #this is a subclass of Gamma\n",
    "    #get_gamma_factor must be redefined\n",
    "    visible_range_start_wavelength = 450\n",
    "    def name():\n",
    "        return \"gamma_area_under_curve_cut_first_minimum\"\n",
    "    def description():\n",
    "        return f\"This algorithm calculates the area for the visible region (starting at {GammaAreaFirstMinCut.visible_range_start_wavelength} and ending in the first minima between the maximum in the visible range and the maximum in the IR range. Then calculates the area of the IR range up to the second minumum. The ratio between these two areas is the gamma value.\"\n",
    "\n",
    "    def get_gamma_factor(self, spectrum):\n",
    "\n",
    "        def get_area_under_curve(spectrum, start_wavelength, finish_wavelength):\n",
    "            # Assuming your DataFrame is named df and has columns 'wavelength' and 'height'\n",
    "            # Let's say you have start_wavelength and finish_wavelength variables for the range you want to integrate over\n",
    "            # Subset the DataFrame to the range of interest\n",
    "            subset_df = df[(df['wavelength'] >= start_wavelength) & (df['wavelength'] <= finish_wavelength)]\n",
    "\n",
    "            # Extract the wavelengths and heights as arrays\n",
    "            wavelengths = subset_df['wavelength'].values\n",
    "            heights = subset_df[spectrum.measuring_mode].values\n",
    "\n",
    "            # Calculate the area under the curve using the trapezoidal rule\n",
    "            area_under_curve = np.trapz(heights, wavelengths)\n",
    "\n",
    "            # print(\"Area under the curve:\", area_under_curve)\n",
    "            return area_under_curve\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        #test_spectrum = filtered_spectra[0]\n",
    "        #get the highest data recorded\n",
    "        max_value = spectrum.data[spectrum.measuring_mode].max()\n",
    "        #get maxima and minima\n",
    "        x = spectrum.data[\"wavelength\"].values\n",
    "        y = spectrum.data[spectrum.measuring_mode].values\n",
    "\n",
    "        #get x and y positions of maxima and minima\n",
    "        max_i, max_xs, max_ys = get_maxima(spectrum)\n",
    "        min_i, min_xs, min_ys= get_minima(spectrum)\n",
    "        #\n",
    "\n",
    "\n",
    "        #get x locations of first and second maxima and the minimum in between\n",
    "        first_max_x = max_xs[0]\n",
    "        try:\n",
    "            second_max_x = max_xs[1]\n",
    "        except Exception as e:\n",
    "            second_max_x = x.max()\n",
    "            print(e)\n",
    "        try:\n",
    "            second_max_y = max_ys[1]\n",
    "        except Exception as e:\n",
    "            second_max_y = 0\n",
    "            print(e)\n",
    "\n",
    "        min_in_between_i = 0\n",
    "        min_in_between_x =0\n",
    "        min_in_between_y =0\n",
    "        #get the location of the minimum in between\n",
    "        for index in min_i:\n",
    "            #print(\"index\")\n",
    "            if first_max_x <= x[index] <= second_max_x:\n",
    "                min_in_between_i = index\n",
    "                min_in_between_x = x[index]\n",
    "                min_in_between_y = y[index]\n",
    "                break\n",
    "\n",
    "        # print(f\"min in bet: {min_in_between_i} {min_in_between_x} {min_in_between_y} \")\n",
    "        #second minimum\n",
    "        #get the location of the second minimum\n",
    "        min_after_second_max_i = 0\n",
    "        min_after_second_max_x = 0\n",
    "        min_after_second_max_y = 0\n",
    "        for index in min_i:\n",
    "            # print(f\" second_max_x  <= x[index] { second_max_x  <= x[index]}\")\n",
    "            if second_max_x  <= x[index]:\n",
    "                min_after_second_max_i = index\n",
    "                min_after_second_max_x = x[index]\n",
    "                min_after_second_max_y = y[index]\n",
    "                break\n",
    "\n",
    "\n",
    "        # print(f\"min after: {min_after_second_max_i} {min_after_second_max_x} {min_after_second_max_y} \")\n",
    "\n",
    "        x_values = [first_max_x, min_in_between_x, second_max_x, min_after_second_max_x]\n",
    "        y_values = [max_ys[0]/max_value, min_in_between_y/max_value, second_max_y/max_value, min_after_second_max_y/max_value]\n",
    "        #get the normalized spectrum\n",
    "        df = spectrum.get_normalized_spectrum()\n",
    "        #plot\n",
    "        x = df[\"wavelength\"].values\n",
    "        y =df[spectrum.measuring_mode].values\n",
    "\n",
    "        #modify y to have last value equal to first one\n",
    "        y_mod = y\n",
    "        y_mod[-1] = y_mod[0]\n",
    "        \n",
    "        #split x, y LEFT\n",
    "        print(f\"fmi: {min_in_between_i}\")\n",
    "        x_left = x[:min_in_between_i]\n",
    "        y_left = y[:min_in_between_i]\n",
    "        #set last one to zero for picture to be displaye properly\n",
    "        y_left[-1] = y_left[0]\n",
    "        \n",
    "\n",
    "        #split x, y RIGHT\n",
    "        #print(f\"min_after_second_max_i: {min_after_second_max_i}\")\n",
    "        x_right = x[min_in_between_i:min_after_second_max_i]\n",
    "        y_right = y[min_in_between_i:min_after_second_max_i]\n",
    "        #set last one to zero for picture to be displaye properly\n",
    "        y_right[0] = y_right[-1] = y_left[0]\n",
    "        \n",
    "        #show figure\n",
    "\n",
    "\n",
    "        area_uv_visible = get_area_under_curve(spectrum, GammaAreaFirstMinCut.visible_range_start_wavelength, min_in_between_x)\n",
    "        area_ir = get_area_under_curve(spectrum, min_in_between_x, min_after_second_max_x)\n",
    "        gamma = area_uv_visible/area_ir\n",
    "        print(f\"gamma: {gamma}\")\n",
    "        return gamma\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dea569-2255-4aaf-9978-683b3b4693a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b9dea569-2255-4aaf-9978-683b3b4693a3",
    "outputId": "28354e4f-c0d7-43eb-a3e2-ff047ce7c1d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Which method we are goint to test\n",
    "gamma_test =GammaAreaFirstMinCut\n",
    "gamma_testbench_arbitrary_limits = Gamma_Testbench(gamma_test, filtered_spectra)\n",
    "#section related to that test\n",
    "gamma_area_first_min_cut_section = gamma_analysis( gamma_testbench_arbitrary_limits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49cd19-330b-4dee-b863-528bf54d2cc0",
   "metadata": {},
   "source": [
    "### Algorithm 5: Peak ratio and wavelength index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52a991-acc6-4f6a-9953-617ce89175a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class  Peak_Ratio_And_Wavelength_Similarity_Index():\n",
    "    @staticmethod\n",
    "    def name():\n",
    "        return \"Peak_Ratio_And_Wavelength_Similarity_Index\"\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return f\"\"\" This algorithm calculates the square difference for wavelength and the square difference in gamma values and multiplies them. \n",
    "Lower values are for spectra that has similar wavelengths and similar gamma values with respect to known spectra\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def gamma_similarity_index(gamma_two_peaks_aggregate_df, species, spectrum):\n",
    "        def distance(x, x0, sigma_0):\n",
    "            index =  (((x - x0)**2))/sigma_0\n",
    "            return index\n",
    "        gamma_first_two_peaks = Gamma_First_Two_Peaks(spectrum).gamma\n",
    "         \n",
    "        #loads species average and std values. Average is row 0 , std is row 1\n",
    "    \n",
    "        average_gamma_first_two_peaks = gamma_two_peaks_aggregate_df.loc[0, species]\n",
    "        std_gamma_first_two_peaks = gamma_two_peaks_aggregate_df.loc[0, species]\n",
    "\n",
    "        #calculates similarity index\n",
    "        similarity_index = distance(gamma_first_two_peaks, average_gamma_first_two_peaks,std_gamma_first_two_peaks)\n",
    "        \n",
    "        return similarity_index\n",
    "\n",
    "    def __init__( self, spectrum):\n",
    "        self.spectrum = spectrum\n",
    "        \n",
    "    def get_indices_df(self):\n",
    "        spectrum = self.spectrum\n",
    "        gamma = 0\n",
    "        #Reads the file with aggregated data for each species\n",
    "        #aggregated_data_gamma_two_peaks = agregated_data_location + \"\\\\aggregated_data\\\\gammaGamma_First_Two_Peaks.txt\"\n",
    "        aggregated_data_gamma_two_peaks = os.path.join(agregated_data_location, \"aggregated_data\",\"gammaGamma_First_Two_Peaks.txt\")\n",
    "        #read gamma averages per species\n",
    "        gamma_two_peaks_aggregate_df = pd.read_csv(aggregated_data_gamma_two_peaks, delimiter=\"\\t\")\n",
    "        \n",
    "        \n",
    "        #read peak averages and std\n",
    "        peak_averages_df = pd.read_csv(agregated_data_avg_path, delimiter = \"\\t\")\n",
    "        peak_std_df = pd.read_csv(agregated_data_std_path, delimiter = \"\\t\")\n",
    "\n",
    "        #An empty dataframe with species info and gamma and wavelength square differences will be created\n",
    "\n",
    "        indices_df = pd.DataFrame([])\n",
    "        #species_list\n",
    "        species_list = gamma_two_peaks_aggregate_df.columns\n",
    "        for species in species_list:\n",
    "            #gamma is calculated\n",
    "            indices_df.loc[species,\"gamma_similarity_index\"] = gamma_similarity_index_value = Peak_Ratio_And_Wavelength_Similarity_Index.gamma_similarity_index(gamma_two_peaks_aggregate_df, species, spectrum)\n",
    "            \n",
    "            \n",
    "            #square difference is calculated\n",
    "            peak_similarity_index_value= similarity_index(spectrum, peak_averages_df, peak_std_df , species)\n",
    "            indices_df.loc[species,\"peak_similarity_index\"] = peak_similarity_index_value\n",
    "\n",
    "            \n",
    "            #total\n",
    "            indices_df.loc[species,\"product\"] = gamma_similarity_index_value*peak_similarity_index_value\n",
    "            \n",
    "        return indices_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398db420-38ab-4656-9989-ef549672b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame([])\n",
    "for index, spectrum in enumerate(filtered_spectra):\n",
    "    test_df.loc[index, \"code\"] = spectrum.code\n",
    "    test_df.loc[index, \"species\"] = spectrum.species\n",
    "    #get index df for each species\n",
    "    index_df = Peak_Ratio_And_Wavelength_Similarity_Index(spectrum).get_indices_df()\n",
    "    #print(index_df)\n",
    "    test_df.loc[index, \"cupreomarginata\"] = index_df.loc[\"cupreomarginata\", \"product\"]\n",
    "    test_df.loc[index, \"kalinini\"] = index_df.loc[\"kalinini\", \"product\"]\n",
    "    test_df.loc[index, \"resplendens\"] = index_df.loc[\"resplendens\", \"product\"]\n",
    "    #get minimum value\n",
    "    \n",
    "\n",
    "test_df[\"prediction\"]  = test_df[['cupreomarginata', 'kalinini', 'resplendens']].idxmin(axis=1)\n",
    "\n",
    "print(test_df)\n",
    "# gamma_test =Peak_Ratio_And_Wavelength_Index\n",
    "# bp_path =gamma_testbench(gamma_test, filtered_spectra)\n",
    "# print(f\"type {type(bp_path)} bp_path\")\n",
    "# gamma_area_first_min_cut_section = gamma_analysis( gamma_test, bp_path  , \"\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacb8a6-ccea-4ea9-8ee2-a1a3a29c065a",
   "metadata": {},
   "source": [
    "#### Peak_Ratio_And_Wavelength_Similarity_Index section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14328c2-ff68-4791-849f-4d70ad7b9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SECTION\n",
    "def Peak_Ratio_And_Wavelength_Similarity_Index_section(df ):\n",
    "    \n",
    "    #Define sections and results\n",
    "    sections = {}\n",
    "    results =[]\n",
    "    information = []\n",
    "\n",
    "    # Section 1: Introduction\n",
    "    description = []\n",
    "    title = [Paragraph(f\"{Peak_Ratio_And_Wavelength_Similarity_Index.name()}:\", getSampleStyleSheet()[\"Heading2\"]), Spacer(1, 12),\n",
    "\n",
    "                    Paragraph(f\"{Peak_Ratio_And_Wavelength_Similarity_Index.description()}\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "    description += title\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #Add table with species info\n",
    "\n",
    "    sub_title = [Paragraph(f\"Test results:\", getSampleStyleSheet()[\"Normal\"]), Spacer(1, 6),Paragraph(\"The reported(correct) species is compared with the species with the lowest similarity index (si), the final column (test_result) shows if the species coincide:\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "    \n",
    "    information += sub_title\n",
    "    \n",
    "    #Amount of correct results\n",
    "\n",
    "    correct_guesses  = (df['species'] == df['prediction']).sum()\n",
    "    total_guesses = df[\"prediction\"].count()\n",
    "    success_rate = correct_guesses / total_guesses * 100\n",
    "    \n",
    "    comment_1 = [Paragraph(f\"The amount of correct guesses is {correct_guesses} out of {total_guesses}\", getSampleStyleSheet()[\"Heading3\"]), \n",
    "                           Spacer(1, 6),\n",
    "                           Paragraph(f\"The accuracy (Percentage of correct classifications out of total classifications) is {success_rate:.2f} %\", getSampleStyleSheet()[\"Normal\"]),\n",
    "                           Spacer(1, 12)]\n",
    "\n",
    "    information += comment_1\n",
    "    \n",
    "    #precision and recall\n",
    "    \n",
    "    kali_precision = calculate_precision(df, \"kalinini\")\n",
    "    kali_recall = calculate_recall(df, \"kalinini\")\n",
    "    cupreo_precision = calculate_precision(df, \"cupreomarginata\")\n",
    "    cupreo_recall= calculate_recall(df, \"cupreomarginata\")\n",
    "    resp_precision= calculate_precision(df, \"resplendens\")\n",
    "    resp_recall = calculate_recall(df, \"resplendens\") #\n",
    "    \n",
    "    #commentary\n",
    "    comment_2 = [Paragraph(f\"For kalinini, precision (correct classifications out of all classifications for this species) is {kali_precision:.2f} % and recall (out of the actual specimens for this species how many were correctly classified) is {kali_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "        Paragraph(f\"For resplendens, precision is {resp_precision:.2f} % and recall is {resp_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "        Paragraph(f\"For cupreomarginata, precision is {cupreo_precision:.2f} % and recall is {cupreo_recall:.2f} %.\", \n",
    "                           getSampleStyleSheet()[\"Normal\"]),\n",
    "                    Spacer(1, 12)]\n",
    "    information += comment_2\n",
    "                  \n",
    "    #create table with test result info\n",
    "    \n",
    "    #round column values\n",
    "    for column in df.columns:\n",
    "        # Check if the column contains numeric values\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Round the values in the column to two decimal places\n",
    "            df[column] = df[column].round(decimals=3)\n",
    "    #convert columns to list\n",
    "    names = df.columns.tolist()\n",
    "    \n",
    "    values_table =  df.values.tolist()\n",
    "\n",
    "    info = [names, *values_table]\n",
    "    #print(info)\n",
    "    #info =  df.values.tolist()\n",
    "    #create table\n",
    "    table2 = Table(info)\n",
    "    style = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.white),\n",
    "                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
    "                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                        ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                        ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
    "\n",
    "    table2.setStyle(style)\n",
    "    information.append(table2)\n",
    "    information.append(PageBreak())\n",
    "\n",
    "\n",
    "    return description  + information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819ee8b-7d8a-4038-b98f-9bcf044ba619",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_ratio_and_wavelength_similarity_index_section= Peak_Ratio_And_Wavelength_Similarity_Index_section(test_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28ab59-313a-4881-b3be-4eafe1e1715b",
   "metadata": {},
   "source": [
    "### Create Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b8fb5-7729-4da8-a7fb-6327632a477c",
   "metadata": {
    "id": "e43b8fb5-7729-4da8-a7fb-6327632a477c"
   },
   "outputs": [],
   "source": [
    "# Create PDF report\n",
    "def create_report():\n",
    "    elements = create_title_page()\n",
    "    #sections, sections_start_pages = create_sections()\n",
    "    elements += specimen_section\n",
    "    elements += simple_gamma_section_arbitrary_limits \n",
    "    elements += simple_gamma_section_first_two_peaks\n",
    "    elements += gamma_area_under_curve_naive_section\n",
    "    elements += gamma_area_first_min_cut_section\n",
    "    elements += similarity_index_section\n",
    "    elements += peak_ratio_and_wavelength_similarity_index_section\n",
    "    #elements += create_table_of_contents()\n",
    "\n",
    "    ##elements += sections\n",
    "    elements += create_bibliography()\n",
    "\n",
    "    # # Update table of contents with page numbers\n",
    "    # toc_style = getSampleStyleSheet()[\"Heading1\"]\n",
    "    # #toc_data = [[Paragraph(section, toc_style), str(page_num)] for section, page_num in sections_start_pages.items()]\n",
    "    # toc_data = [\"1\"]\n",
    "    # toc_table = Table(toc_data)\n",
    "    # toc_table.setStyle(TableStyle([('ALIGN', (0, 0), (-1, -1), 'CENTER')]))\n",
    "    # elements[-1] = toc_table\n",
    "    # elements += create_table_of_contents(toc_data)\n",
    "    \n",
    "    location = os.path.join(report_location, f\"gamma analysis {collection_names} {current_date}.pdf\" )\n",
    "    doc = SimpleDocTemplate(location, pagesize=letter)\n",
    "    doc.build(elements)\n",
    "    print(f\"The report was saved at {location} \")\n",
    "create_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622247f-a46d-45f3-aaaf-669dbd204544",
   "metadata": {
    "id": "6622247f-a46d-45f3-aaaf-669dbd204544"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ee149-e8f4-4f17-86ee-3ebcf520f3c2",
   "metadata": {
    "id": "bc8ee149-e8f4-4f17-86ee-3ebcf520f3c2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa20f64-4922-424a-b687-7335e6a47894",
   "metadata": {
    "id": "3aa20f64-4922-424a-b687-7335e6a47894"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b02159-5ef8-4c3a-abea-639ac9f75436",
   "metadata": {
    "id": "76b02159-5ef8-4c3a-abea-639ac9f75436"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62561209-c6e7-46c1-8b0d-9e0c6022cbfb",
   "metadata": {
    "id": "62561209-c6e7-46c1-8b0d-9e0c6022cbfb"
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27bc33-2e13-4574-a760-222809d14668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
